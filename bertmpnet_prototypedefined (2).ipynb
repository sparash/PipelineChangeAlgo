{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52de6ee-f6a8-4f9b-ad75-d6ae1619d082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers library available for BERT embeddings\n",
      "Warning: pyahocorasick not available. Using fallback implementation.\n",
      "Using device: cpu\n",
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from Levenshtein import jaro_winkler, ratio as levenshtein_ratio\n",
    "import textdistance\n",
    "from fuzzywuzzy import fuzz\n",
    "import jellyfish\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    transformers_available = True\n",
    "    print(\"Transformers library available for BERT embeddings\")\n",
    "except ImportError:\n",
    "    transformers_available = False\n",
    "    print(\"Warning: transformers library not available. Will use TF-IDF fallback.\")\n",
    "\n",
    "# Try to import pyahocorasick with fallback\n",
    "try:\n",
    "    import pyahocorasick\n",
    "    aho_corasick_available = True\n",
    "    print(\"pyahocorasick is available\")\n",
    "except ImportError:\n",
    "    print(\"Warning: pyahocorasick not available. Using fallback implementation.\")\n",
    "    aho_corasick_available = False\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4c49a8-68b7-4faf-b471-a8c3d90393f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Enhanced BERT Embedder with MPNet Model\n",
    "\n",
    "class EnhancedBERTEmbedder:\n",
    "    \"\"\"\n",
    "    Enhanced BERT embedder using the more powerful MPNet model for better semantic understanding.\n",
    "    Implements advanced pooling strategies, merchant category adaptation, and batching for efficiency.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='sentence-transformers/all-mpnet-base-v2', pooling_strategy='mean', device=None):\n",
    "        \"\"\"\n",
    "        Initialize enhanced BERT embedder with specified pre-trained model and pooling strategy.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Name of the pre-trained BERT model to use\n",
    "            pooling_strategy (str): Pooling strategy ('mean', 'cls', or 'max')\n",
    "            device: Device to run the model on (cuda or cpu)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.pooling_strategy = pooling_strategy\n",
    "        self.max_sequence_length = 512  # BERT's limit\n",
    "        \n",
    "        if device is None:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        self.initialized = False\n",
    "        self.category_adapted = False  # Renamed from domain_adapted\n",
    "        self.category_embeddings = {}  # Storage for category-specific embeddings\n",
    "        \n",
    "        # Initialize pre-trained model if transformers available\n",
    "        if transformers_available:\n",
    "            try:\n",
    "                print(f\"Loading enhanced BERT model '{model_name}'...\")\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "                self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "                self.model.eval()  # Set to evaluation mode\n",
    "                self.initialized = True\n",
    "                print(f\"Enhanced BERT model loaded successfully on {self.device}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error initializing BERT model: {e}\")\n",
    "                self.initialized = False\n",
    "        \n",
    "        # Initialize TF-IDF fallback if BERT not available\n",
    "        if not self.initialized:\n",
    "            # Using character n-grams for better handling of typos and abbreviations\n",
    "            self.tfidf_vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 4))\n",
    "            self.tfidf_fitted = False\n",
    "            print(\"Using TF-IDF fallback for embeddings\")\n",
    "    \n",
    "    def _mean_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"\n",
    "        Mean pooling - take average of all token embeddings\n",
    "        \"\"\"\n",
    "        token_embeddings = model_output[0]  # First element contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    def _cls_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"\n",
    "        CLS pooling - use the [CLS] token embedding\n",
    "        \"\"\"\n",
    "        return model_output[0][:, 0]\n",
    "    \n",
    "    def _max_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"\n",
    "        Max pooling - take max of all token embeddings\n",
    "        \"\"\"\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        token_embeddings[input_mask_expanded == 0] = -1e9  # Set padding tokens to large negative value\n",
    "        return torch.max(token_embeddings, 1)[0]\n",
    "    \n",
    "    def _get_pooled_embeddings(self, model_output, attention_mask):\n",
    "        \"\"\"\n",
    "        Apply the selected pooling strategy\n",
    "        \"\"\"\n",
    "        if self.pooling_strategy == 'mean':\n",
    "            return self._mean_pooling(model_output, attention_mask)\n",
    "        elif self.pooling_strategy == 'cls':\n",
    "            return self._cls_pooling(model_output, attention_mask)\n",
    "        elif self.pooling_strategy == 'max':\n",
    "            return self._max_pooling(model_output, attention_mask)\n",
    "        else:\n",
    "            # Default to mean pooling\n",
    "            return self._mean_pooling(model_output, attention_mask)\n",
    "    \n",
    "    def fit(self, texts):\n",
    "        \"\"\"\n",
    "        Fit the TF-IDF vectorizer on a corpus of texts (only needed for TF-IDF fallback)\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            # Fit TF-IDF vectorizer\n",
    "            self.tfidf_vectorizer.fit(texts)\n",
    "            self.tfidf_fitted = True\n",
    "            print(\"TF-IDF vectorizer fitted on corpus\")\n",
    "    \n",
    "    def adapt_to_merchant_category(self, merchant_data_df):\n",
    "        \"\"\"\n",
    "        Adapt the embedder to specific merchant categories using example data\n",
    "        \n",
    "        Args:\n",
    "            merchant_data_df: DataFrame containing merchant data with DBAName, RawTransactionName,\n",
    "                             DBA_Merchant_Category, and RawTransaction_Merchant_Category columns\n",
    "        \n",
    "        Returns:\n",
    "            bool: Whether adaptation was successful\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            print(\"Cannot adapt to merchant category: BERT model not initialized\")\n",
    "            return False\n",
    "            \n",
    "        try:\n",
    "            # Extract unique merchant categories\n",
    "            dba_categories = merchant_data_df['DBA_Merchant_Category'].dropna().unique()\n",
    "            raw_categories = merchant_data_df['RawTransaction_Merchant_Category'].dropna().unique()\n",
    "            all_categories = np.unique(np.concatenate([dba_categories, raw_categories]))\n",
    "            \n",
    "            print(f\"Adapting to {len(all_categories)} merchant categories...\")\n",
    "            \n",
    "            # Create category embeddings by averaging examples from each category\n",
    "            for category in all_categories:\n",
    "                # Get examples of this category (from either DBA or RawTransaction)\n",
    "                dba_examples = merchant_data_df[merchant_data_df['DBA_Merchant_Category'] == category]['DBAName'].dropna().tolist()\n",
    "                raw_examples = merchant_data_df[merchant_data_df['RawTransaction_Merchant_Category'] == category]['RawTransactionName'].dropna().tolist()\n",
    "                \n",
    "                # Combine examples, ensuring we don't have too many\n",
    "                examples = (dba_examples + raw_examples)[:100]  # Limit to 100 examples per category\n",
    "                \n",
    "                if examples:\n",
    "                    # Get embeddings and compute average\n",
    "                    embeddings = self.encode(examples)\n",
    "                    category_embedding = np.mean(embeddings, axis=0)\n",
    "                    self.category_embeddings[category] = category_embedding\n",
    "            \n",
    "            self.category_adapted = True\n",
    "            print(f\"Successfully adapted to {len(self.category_embeddings)} merchant categories\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error adapting to merchant categories: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def encode(self, texts, batch_size=32, show_progress=False, merchant_category=None):\n",
    "        \"\"\"\n",
    "        Encode texts into embeddings using the pre-trained model,\n",
    "        optionally considering merchant category information\n",
    "        \n",
    "        Args:\n",
    "            texts: List of texts or single text\n",
    "            batch_size: Batch size for processing\n",
    "            show_progress: Whether to show progress\n",
    "            merchant_category: Optional merchant category to influence encoding\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Embeddings for the texts\n",
    "        \"\"\"\n",
    "        # Handle single text input\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        \n",
    "        # Return empty array for empty input\n",
    "        if len(texts) == 0:\n",
    "            return np.array([])\n",
    "        \n",
    "        # Use pre-trained BERT if available\n",
    "        if self.initialized:\n",
    "            # Process in batches\n",
    "            all_embeddings = []\n",
    "            \n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                if show_progress and i % (batch_size * 10) == 0:\n",
    "                    print(f\"Processing batch {i//batch_size + 1}/{(len(texts)//batch_size) + 1}\")\n",
    "                \n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                \n",
    "                # Tokenize\n",
    "                encoded_input = self.tokenizer(\n",
    "                    batch_texts, \n",
    "                    padding=True, \n",
    "                    truncation=True, \n",
    "                    max_length=self.max_sequence_length,\n",
    "                    return_tensors='pt'\n",
    "                ).to(self.device)\n",
    "                \n",
    "                # Compute token embeddings\n",
    "                with torch.no_grad():\n",
    "                    model_output = self.model(**encoded_input)\n",
    "                    batch_embeddings = self._get_pooled_embeddings(model_output, encoded_input['attention_mask'])\n",
    "                    all_embeddings.append(batch_embeddings.cpu().numpy())\n",
    "            \n",
    "            embeddings = np.vstack(all_embeddings)\n",
    "            \n",
    "            # Apply merchant category adaptation if available\n",
    "            if self.category_adapted and merchant_category and merchant_category in self.category_embeddings:\n",
    "                # Blend with category embedding (subtle influence)\n",
    "                category_embedding = self.category_embeddings[merchant_category]\n",
    "                alpha = 0.1  # Blend factor - subtle influence\n",
    "                embeddings = (1 - alpha) * embeddings + alpha * category_embedding\n",
    "                \n",
    "                # Re-normalize\n",
    "                embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "            \n",
    "            return embeddings\n",
    "        \n",
    "        else:\n",
    "            # Use TF-IDF fallback\n",
    "            if not self.tfidf_fitted:\n",
    "                self.fit(texts)\n",
    "            \n",
    "            return self.tfidf_vectorizer.transform(texts).toarray()\n",
    "    \n",
    "    def compute_similarity(self, text1, text2, merchant_category1=None, merchant_category2=None):\n",
    "        \"\"\"\n",
    "        Compute cosine similarity between two texts using the pre-trained model,\n",
    "        optionally considering merchant category information\n",
    "        \n",
    "        Args:\n",
    "            text1: First text\n",
    "            text2: Second text\n",
    "            merchant_category1: Merchant category for first text\n",
    "            merchant_category2: Merchant category for second text\n",
    "            \n",
    "        Returns:\n",
    "            float: Cosine similarity score\n",
    "        \"\"\"\n",
    "        # Get embeddings for both texts, considering merchant categories\n",
    "        emb1 = self.encode(text1, merchant_category=merchant_category1)\n",
    "        emb2 = self.encode(text2, merchant_category=merchant_category2)\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        return np.sum(emb1 * emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae4f9ea-b1b1-46da-b14d-26a8bb3270d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Enhanced Merchant Matcher Core Class\n",
    "\n",
    "class EnhancedMerchantMatcher:\n",
    "    \"\"\"\n",
    "    Enhanced matcher with improved pattern recognition for merchant name matching.\n",
    "    Uses multiple similarity algorithms and merchant category-specific patterns.\n",
    "    \"\"\"\n",
    "    def __init__(self, bert_embedder=None):\n",
    "        \"\"\"\n",
    "        Initialize with enhanced BERT embedder.\n",
    "        \n",
    "        Args:\n",
    "            bert_embedder: Enhanced BERT embedder instance\n",
    "        \"\"\"\n",
    "        # Initialize enhanced BERT embedder\n",
    "        self.bert_embedder = bert_embedder\n",
    "        if self.bert_embedder is None and transformers_available:\n",
    "            self.bert_embedder = EnhancedBERTEmbedder()\n",
    "        \n",
    "        # Initialize TF-IDF vectorizer\n",
    "        self.tfidf_vectorizer = TfidfVectorizer()\n",
    "        \n",
    "        # Initialize trie for approximate matching\n",
    "        self.trie = None\n",
    "        \n",
    "        # Initialize Aho-Corasick automaton only if available\n",
    "        if aho_corasick_available:\n",
    "            self.automaton = pyahocorasick.Automaton()\n",
    "        else:\n",
    "            self.automaton = None\n",
    "        \n",
    "        # Define abbreviation dictionary - comprehensive industry knowledge \n",
    "        self.abbreviations = self._get_abbreviation_dictionary()\n",
    "        \n",
    "        # Merchant category-specific abbreviations \n",
    "        self.merchant_category_abbreviations = self._get_merchant_category_abbreviations()\n",
    "        \n",
    "        # Stop words to remove during preprocessing\n",
    "        self.stopwords = self._get_stopwords()\n",
    "        \n",
    "        # Merchant category-specific stopwords \n",
    "        self.merchant_category_stopwords = self._get_merchant_category_stopwords()\n",
    "        \n",
    "        # Add base weights as a class attribute\n",
    "        self.base_weights = {\n",
    "            'jaro_winkler': 0.10,\n",
    "            'damerau_levenshtein': 0.05,\n",
    "            'tfidf_cosine': 0.05,\n",
    "            'jaccard_bigram': 0.05,\n",
    "            'soundex': 0.05,\n",
    "            'token_sort_ratio': 0.10,\n",
    "            'contains_ratio': 0.10,\n",
    "            'fuzzy_levenshtein': 0.05,\n",
    "            'trie_approximate': 0.10,\n",
    "            'bert_similarity': 0.15,\n",
    "            'aho_corasick': 0.05,\n",
    "            'DBAName_formation': 0.15\n",
    "        }\n",
    "        \n",
    "        # Add common DBANames reference\n",
    "        self.common_dbanames = COMMON_DBANameS\n",
    "    \n",
    "    def _get_abbreviation_dictionary(self):\n",
    "        \"\"\"Get comprehensive abbreviation dictionary\"\"\"\n",
    "        return {\n",
    "            # Banking & Financial Institutions\n",
    "            'bofa': 'bank of america', 'b of a': 'bank of america',\n",
    "            'boa': 'bank of america', 'bac': 'bank of america',\n",
    "            'jpm': 'jpmorgan chase', 'jpm chase': 'jpmorgan chase',\n",
    "            'wf': 'wells fargo', 'wfb': 'wells fargo bank',\n",
    "            'citi': 'citibank', 'citi bank': 'citibank',\n",
    "            'gs': 'goldman sachs', 'ms': 'morgan stanley',\n",
    "            'db': 'deutsche bank', 'hsbc': 'hongkong and shanghai banking corporation',\n",
    "            'amex': 'american express', 'usb': 'us bank', 'rbc': 'royal bank of canada',\n",
    "            'pnc': 'pnc financial services', 'td': 'toronto dominion bank',\n",
    "            'bny': 'bank of new york', 'bnyc': 'bank of new york mellon',\n",
    "            'cba': 'commonwealth bank of australia', 'nab': 'national australia bank',\n",
    "            'rba': 'reserve bank of australia', 'westpac': 'western pacific bank',\n",
    "            \n",
    "            # Fast Food & Restaurant Chains\n",
    "            'mcd': 'mcdonalds', 'mcds': 'mcdonalds', 'md': 'mcdonalds',\n",
    "            'bk': 'burger king', 'kfc': 'kentucky fried chicken',\n",
    "            'sbux': 'starbucks', 'sb': 'starbucks',\n",
    "            'tb': 'taco bell', 'wen': 'wendys',\n",
    "            'dq': 'dairy queen', 'ph': 'pizza hut',\n",
    "            'dnkn': 'dunkin donuts', 'cfa': 'chick fil a',\n",
    "            'cmg': 'chipotle mexican grill', 'ihop': 'international house of pancakes',\n",
    "            'tgi': 'tgi fridays', 'tgif': 'tgi fridays',\n",
    "            \n",
    "            # Tech Companies\n",
    "            'msft': 'microsoft', 'aapl': 'apple', 'goog': 'google',\n",
    "            'googl': 'google', 'amzn': 'amazon', 'fb': 'facebook',\n",
    "            'meta': 'meta platforms', 'nflx': 'netflix', 'tsla': 'tesla',\n",
    "            'ibm': 'international business machines', 'csco': 'cisco systems',\n",
    "            'orcl': 'oracle', 'intc': 'intel', 'amd': 'advanced micro devices',\n",
    "            'nvda': 'nvidia', 'adbe': 'adobe', 'crm': 'salesforce',\n",
    "            \n",
    "            # Automotive\n",
    "            'tm': 'toyota motor', 'toyof': 'toyota', 'toyota': 'toyota corporation',\n",
    "            'f': 'ford motor company', 'gm': 'general motors',\n",
    "            'hmc': 'honda motor company', 'hndaf': 'honda',\n",
    "            'nsany': 'nissan', 'bmwyy': 'bmw', 'vwagy': 'volkswagen',\n",
    "            \n",
    "            # Retail companies\n",
    "            'wmt': 'walmart', 'tgt': 'target', 'cost': 'costco',\n",
    "            'hd': 'home depot', 'low': 'lowes', 'bby': 'best buy',\n",
    "            'ebay': 'ebay', 'dg': 'dollar general', 'dltr': 'dollar tree',\n",
    "            \n",
    "            # Government & Organizations\n",
    "            'dhs': 'department of homeland security',\n",
    "            'dod': 'department of defense', 'dos': 'department of state',\n",
    "            'epa': 'environmental protection agency', 'fbi': 'federal bureau of investigation',\n",
    "            'cia': 'central intelligence agency', 'irs': 'internal revenue service',\n",
    "            'fda': 'food and drug administration', 'sec': 'securities and exchange commission',\n",
    "            'usps': 'united states postal service', 'doi': 'department of interior',\n",
    "            'fed': 'federal reserve', 'who': 'world health organization',\n",
    "            'un': 'united nations', 'nato': 'north atlantic treaty organization',\n",
    "            \n",
    "            # Common abbreviations\n",
    "            'j&j': 'johnson & johnson', 'jj': 'johnson johnson', \n",
    "            'jnj': 'johnson and johnson', '7-11': '7-eleven', \n",
    "            '711': '7-eleven', 'intl': 'international',\n",
    "            'corp': 'corporation', 'inc': 'incorporated',\n",
    "            \n",
    "            # Address components\n",
    "            'rd': 'road', 'st': 'street', 'ave': 'avenue', \n",
    "            'blvd': 'boulevard', 'ctr': 'center', 'ln': 'lane', \n",
    "            'dr': 'drive', 'pl': 'place', 'ct': 'court',\n",
    "            'hwy': 'highway', 'pkwy': 'parkway', 'sq': 'square'\n",
    "        }\n",
    "    \n",
    "    def _get_merchant_category_abbreviations(self):\n",
    "        \"\"\"Get merchant category-specific abbreviation dictionaries \"\"\"\n",
    "        return {\n",
    "            'Medical': {\n",
    "                'dr': 'doctor', 'hosp': 'hospital', 'med': 'medical',\n",
    "                'clin': 'clinic', 'pharm': 'pharmacy', 'lab': 'laboratory',\n",
    "                'dept': 'department', 'ctr': 'center', 'inst': 'institute',\n",
    "                'er': 'emergency room', 'icu': 'intensive care unit',\n",
    "                'ob': 'obstetrics', 'gyn': 'gynecology', 'peds': 'pediatrics',\n",
    "                'ortho': 'orthopedics', 'onc': 'oncology', 'neuro': 'neurology'\n",
    "            },\n",
    "            'Government': {\n",
    "                'govt': 'government', 'dept': 'department', 'admin': 'administration',\n",
    "                'auth': 'authority', 'fed': 'federal', 'natl': 'national',\n",
    "                'comm': 'commission', 'sec': 'secretary', 'org': 'organization',\n",
    "                'div': 'division', 'bur': 'bureau', 'off': 'office',\n",
    "                'min': 'ministry', 'reg': 'regional', 'dist': 'district',\n",
    "                'cncl': 'council', 'cmte': 'committee', 'subcmte': 'subcommittee'\n",
    "            },\n",
    "            'Education': {\n",
    "                'univ': 'university', 'coll': 'college', 'acad': 'academy',\n",
    "                'elem': 'elementary', 'sch': 'school', 'inst': 'institute',\n",
    "                'dept': 'department', 'lib': 'library', 'lab': 'laboratory',\n",
    "                'fac': 'faculty', 'prof': 'professor', 'assoc': 'associate',\n",
    "                'asst': 'assistant', 'adm': 'administration', 'stdnt': 'student',\n",
    "                'grad': 'graduate', 'undergrad': 'undergraduate'\n",
    "            },\n",
    "            'Financial': {\n",
    "                'fin': 'financial', 'svcs': 'services', 'mgmt': 'management',\n",
    "                'assoc': 'associates', 'intl': 'international', 'grp': 'group',\n",
    "                'corp': 'corporation', 'cap': 'capital', 'inv': 'investment',\n",
    "                'asset': 'asset management', 'sec': 'securities', 'adv': 'advisors',\n",
    "                'tr': 'trust', 'port': 'portfolio', 'acct': 'account',\n",
    "                'bal': 'balance', 'stmt': 'statement', 'equ': 'equity'\n",
    "            },\n",
    "            'Restaurant': {\n",
    "                'rest': 'restaurant', 'cafe': 'cafeteria', 'grill': 'grillery',\n",
    "                'brew': 'brewery', 'bar': 'bar and grill', 'bbq': 'barbecue',\n",
    "                'deli': 'delicatessen', 'stk': 'steakhouse', 'bf': 'breakfast',\n",
    "                'din': 'dinner', 'chs': 'cheese', 'ckn': 'chicken'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _get_stopwords(self):\n",
    "        \"\"\"Get general stopwords for preprocessing\"\"\"\n",
    "        return {\n",
    "            'inc', 'llc', 'co', 'ltd', 'corp', 'plc', 'na', 'the', \n",
    "            'and', 'of', 'for', 'in', 'a', 'an', 'by', 'to', 'at',\n",
    "            'corporation', 'incorporated', 'company', 'limited',\n",
    "            'with', 'from', 'as', 'on', 'group', 'services'\n",
    "        }\n",
    "    \n",
    "    def _get_merchant_category_stopwords(self):\n",
    "        \"\"\"Get merchant category-specific stopwords (renamed from _get_domain_stopwords)\"\"\"\n",
    "        return {\n",
    "            'Medical': {'center', 'healthcare', 'medical', 'health', 'care', 'services', 'clinic', 'hospital'},\n",
    "            'Government': {'department', 'office', 'agency', 'bureau', 'division', 'authority', 'administration'},\n",
    "            'Education': {'university', 'college', 'school', 'institute', 'academy', 'education', 'learning'},\n",
    "            'Financial': {'financial', 'services', 'management', 'capital', 'investment', 'banking', 'advisor'},\n",
    "            'Restaurant': {'restaurant', 'cafe', 'diner', 'eatery', 'grill', 'kitchen', 'bar', 'house'}\n",
    "        }\n",
    "    \n",
    "    def enhanced_preprocessing(self, text, merchant_category=None):\n",
    "        \"\"\"\n",
    "        Enhanced preprocessing with better handling of merchant-specific patterns\n",
    "        \n",
    "        Args:\n",
    "            text (str): Text to preprocess\n",
    "            merchant_category (str, optional): Merchant category for specialized processing\n",
    "        \n",
    "        Returns:\n",
    "            str: Preprocessed text\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Better handling of punctuation - preserve periods in DBANames\n",
    "        # and apostrophes in business names (e.g., McDonald's)\n",
    "        text = re.sub(r'([^a-z0-9\\'\\.\\&\\-])', ' ', text)\n",
    "        \n",
    "        # Special handling for business name apostrophes\n",
    "        text = re.sub(r'\\'s\\b', 's', text)  # Convert McDonald's to McDonalds\n",
    "        \n",
    "        # Expand common business suffixes\n",
    "        business_suffixes = {\n",
    "            r'\\bco\\b': 'company',\n",
    "            r'\\binc\\b': '',  # Remove Inc entirely\n",
    "            r'\\bltd\\b': 'limited',\n",
    "            r'\\bllc\\b': '',  # Remove LLC entirely\n",
    "            r'\\bcorp\\b': 'corporation',\n",
    "            r'\\bcorporation\\b': '',  # Remove when processing full names for matching\n",
    "            r'\\blimited\\b': '',      # Remove when processing full names for matching\n",
    "            r'\\bcompany\\b': '',      # Remove when processing full names for matching\n",
    "        }\n",
    "        \n",
    "        for suffix, replacement in business_suffixes.items():\n",
    "            text = re.sub(suffix, replacement, text)\n",
    "        \n",
    "        # Replace abbreviations\n",
    "        words = text.split()\n",
    "        \n",
    "        # Apply general abbreviation expansion\n",
    "        words = [self.abbreviations.get(word, word) for word in words]\n",
    "        \n",
    "        # Apply merchant category-specific abbreviation expansion if merchant_category is provided\n",
    "        if merchant_category and merchant_category in self.merchant_category_abbreviations:\n",
    "            words = [self.merchant_category_abbreviations[merchant_category].get(word, word) for word in words]\n",
    "        \n",
    "        # Enhanced handling for McDonalds variations\n",
    "        if any('mc' in word.lower() for word in words):\n",
    "            words = ['mcdonalds' if word.lower() in ['mcd', 'mcds', 'mcdon'] else word for word in words]\n",
    "        \n",
    "        # Remove general stopwords\n",
    "        words = [word for word in words if word not in self.stopwords]\n",
    "        \n",
    "        # Remove merchant category-specific stopwords if merchant_category is provided\n",
    "        if merchant_category and merchant_category in self.merchant_category_stopwords:\n",
    "            words = [word for word in words if word not in self.merchant_category_stopwords[merchant_category]]\n",
    "        \n",
    "        # Rejoin words and remove extra spaces\n",
    "        text = ' '.join(words)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def preprocess_pair(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"Preprocess DBAName and RawTransactionName with their respective merchant categories\"\"\"\n",
    "        DBAName_clean = self.enhanced_preprocessing(DBAName, DBA_Merchant_Category)\n",
    "        RawTransactionName_clean = self.enhanced_preprocessing(RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        return DBAName_clean, RawTransactionName_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380b58a2-5ff5-46ec-9cd9-c0de0f7c2ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Similarity Methods for Merchant Matcher\n",
    "\n",
    "class EnhancedMerchantMatcherWithSimilarity(EnhancedMerchantMatcher):\n",
    "    \"\"\"Adding similarity methods to the EnhancedMerchantMatcher class\"\"\"\n",
    "    \n",
    "    def jaro_winkler_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Calculate Jaro-Winkler similarity with enhanced preprocessing\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "            DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "            RawTransactionName (str): The full name to match against\n",
    "            RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "            \n",
    "        Returns:\n",
    "            float: Jaro-Winkler similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        return jaro_winkler(DBAName_clean, RawTransactionName_clean)\n",
    "    \n",
    "    def damerau_levenshtein_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Calculate Damerau-Levenshtein similarity, better for handling transpositions\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: Damerau-Levenshtein similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate Damerau-Levenshtein distance\n",
    "        max_len = max(len(DBAName_clean), len(RawTransactionName_clean))\n",
    "        if max_len == 0:\n",
    "            return 0\n",
    "        \n",
    "        distance = textdistance.damerau_levenshtein.distance(DBAName_clean, RawTransactionName_clean)\n",
    "        similarity = 1 - (distance / max_len)\n",
    "        return max(0, similarity)  # Ensure non-negative\n",
    "    \n",
    "    def tfidf_cosine_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Calculate TF-IDF Cosine similarity for keyword matching\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: TF-IDF cosine similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Fit and transform with TF-IDF\n",
    "        try:\n",
    "            tfidf_matrix = self.tfidf_vectorizer.fit_transform([DBAName_clean, RawTransactionName_clean])\n",
    "            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "            return float(max(0, similarity))  # Ensure non-negative\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def jaccard_bigram_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Calculate Jaccard Bigram similarity for character overlaps\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: Jaccard bigram similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Create bigrams\n",
    "        def get_bigrams(text):\n",
    "            return [text[i:i+2] for i in range(len(text)-1)]\n",
    "        \n",
    "        DBAName_bigrams = set(get_bigrams(DBAName_clean))\n",
    "        RawTransactionName_bigrams = set(get_bigrams(RawTransactionName_clean))\n",
    "        \n",
    "        # Calculate Jaccard similarity\n",
    "        union_size = len(DBAName_bigrams.union(RawTransactionName_bigrams))\n",
    "        if union_size == 0:\n",
    "            return 0\n",
    "        \n",
    "        intersection_size = len(DBAName_bigrams.intersection(RawTransactionName_bigrams))\n",
    "        return intersection_size / union_size\n",
    "    \n",
    "    def soundex_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Calculate phonetic similarity using Soundex algorithm.\n",
    "        Especially useful for similar-sounding business names.\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: Phonetic similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # If either string is empty, return 0\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0.0\n",
    "        \n",
    "        # Get the soundex codes for both strings\n",
    "        try:\n",
    "            # For multi-word strings, get soundex for each word\n",
    "            DBAName_words = DBAName_clean.split()\n",
    "            RawTransactionName_words = RawTransactionName_clean.split()\n",
    "            \n",
    "            # Get soundex codes for each word\n",
    "            DBAName_codes = [jellyfish.soundex(word) for word in DBAName_words if len(word) > 1]\n",
    "            RawTransactionName_codes = [jellyfish.soundex(word) for word in RawTransactionName_words if len(word) > 1]\n",
    "            \n",
    "            # Calculate matches between codes\n",
    "            matches = 0\n",
    "            total = max(len(DBAName_codes), len(RawTransactionName_codes))\n",
    "            \n",
    "            if total == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            # Count matched codes\n",
    "            for code in DBAName_codes:\n",
    "                if code in RawTransactionName_codes:\n",
    "                    matches += 1\n",
    "                    # Remove the matched code to avoid double counting\n",
    "                    RawTransactionName_codes.remove(code)\n",
    "            \n",
    "            return matches / total\n",
    "        except:\n",
    "            # Fallback if there's an error with the soundex calculation\n",
    "            return 0.0\n",
    "    \n",
    "    def token_sort_ratio_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Calculate Token Sort Ratio using fuzzywuzzy.\n",
    "        Handles word order differences well.\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: Token sort ratio similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate Token Sort Ratio\n",
    "        ratio = fuzz.token_sort_ratio(DBAName, RawTransactionName) / 100\n",
    "        return ratio\n",
    "    \n",
    "    def contains_ratio_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Check if DBAName is contained in full name or vice versa\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: Containment similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Check if DBAName is contained in full name\n",
    "        if DBAName_clean in RawTransactionName_clean:\n",
    "            return 1\n",
    "        \n",
    "        # Check if full name is contained in DBAName\n",
    "        if RawTransactionName_clean in DBAName_clean:\n",
    "            return 0.9\n",
    "        \n",
    "        # Check for partial containment\n",
    "        DBAName_chars = list(DBAName_clean)\n",
    "        RawTransactionName_chars = list(RawTransactionName_clean)\n",
    "        \n",
    "        matches = 0\n",
    "        for char in DBAName_chars:\n",
    "            if char in RawTransactionName_chars:\n",
    "                matches += 1\n",
    "                RawTransactionName_chars.remove(char)  # Remove matched char\n",
    "        \n",
    "        return matches / len(DBAName_chars) if len(DBAName_chars) > 0 else 0\n",
    "    \n",
    "    def fuzzy_levenshtein_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Calculate fuzzy Levenshtein ratio for typo tolerance\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: Fuzzy Levenshtein similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate Levenshtein ratio (which is already normalized)\n",
    "        similarity = levenshtein_ratio(DBAName_clean, RawTransactionName_clean)\n",
    "        return float(similarity)\n",
    "    def trie_approximate_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Use approximate matching for DBAName formation detection\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: Trie approximate similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Extract first letters from each word in full name\n",
    "        words = RawTransactionName_clean.split()\n",
    "        if not words:\n",
    "            return 0\n",
    "        \n",
    "        first_letters = ''.join([word[0] for word in words if word])\n",
    "        \n",
    "        # Check if DBAName matches first letters\n",
    "        if DBAName_clean.lower() == first_letters.lower():\n",
    "            return 1\n",
    "        \n",
    "        # Calculate similarity for approximate matching\n",
    "        max_len = max(len(DBAName_clean), len(first_letters))\n",
    "        if max_len == 0:\n",
    "            return 0\n",
    "        \n",
    "        distance = levenshtein_distance(DBAName_clean.lower(), first_letters.lower())\n",
    "        similarity = 1 - (distance / max_len)\n",
    "        return max(0, similarity)\n",
    "    \n",
    "    def aho_corasick_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Use Aho-Corasick algorithm for pattern matching\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: Aho-Corasick similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        \n",
    "        if not aho_corasick_available:\n",
    "            # Fallback implementation when pyahocorasick is not available\n",
    "            matches = 0\n",
    "            remaining_text = RawTransactionName_clean\n",
    "            for c in DBAName_clean:\n",
    "                if c in remaining_text:\n",
    "                    matches += 1\n",
    "                    # Remove matched character to prevent duplicate counting\n",
    "                    idx = remaining_text.find(c)\n",
    "                    remaining_text = remaining_text[:idx] + remaining_text[idx+1:]\n",
    "            \n",
    "            return min(1.0, matches / len(DBAName_clean)) if len(DBAName_clean) > 0 else 0\n",
    "        \n",
    "        # Build automaton\n",
    "        automaton = pyahocorasick.Automaton()\n",
    "        for i, c in enumerate(DBAName_clean):\n",
    "            automaton.add_word(c, (i, c))\n",
    "        automaton.make_automaton()\n",
    "        \n",
    "        # Find matches\n",
    "        matches = 0\n",
    "        for _, (_, c) in automaton.iter(RawTransactionName_clean):\n",
    "            matches += 1\n",
    "        \n",
    "        # Calculate score\n",
    "        if len(DBAName_clean) == 0:\n",
    "            return 0\n",
    "        \n",
    "        return min(1.0, matches / len(DBAName_clean))\n",
    "    \n",
    "    def bert_similarity(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Calculate semantic similarity using BERT embeddings\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: BERT similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        # If BERT embedder is not initialized, return 0\n",
    "        if self.bert_embedder is None:\n",
    "            return 0\n",
    "        \n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        \n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            # Get embeddings from pre-trained model\n",
    "            emb1 = self.bert_embedder.encode(DBAName_clean)\n",
    "            emb2 = self.bert_embedder.encode(RawTransactionName_clean)\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            dot_product = np.sum(emb1 * emb2)\n",
    "            norm1 = np.linalg.norm(emb1)\n",
    "            norm2 = np.linalg.norm(emb2)\n",
    "            \n",
    "            similarity = dot_product / (norm1 * norm2 + 1e-8)\n",
    "            return float(similarity)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in BERT similarity calculation: {e}\")\n",
    "            return 0\n",
    "    \n",
    "    def DBAName_formation_score(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Calculate how well the DBAName is formed from the full name\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: DBAName formation score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        # Check if strings are empty\n",
    "        if not DBAName_clean or not RawTransactionName_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Extract first letters from each word in full name\n",
    "        words = RawTransactionName_clean.split()\n",
    "        if not words:\n",
    "            return 0\n",
    "        \n",
    "        # Standard DBAName formation - first letter of each word\n",
    "        first_letters = ''.join([word[0] for word in words if word])\n",
    "        \n",
    "        # If exact match, return 1\n",
    "        if DBAName_clean.lower() == first_letters.lower():\n",
    "            return 1\n",
    "        \n",
    "        # Check partial match\n",
    "        DBAName_chars = list(DBAName_clean.lower())\n",
    "        first_letters_chars = list(first_letters.lower())\n",
    "        \n",
    "        matches = 0\n",
    "        for char in DBAName_chars:\n",
    "            if char in first_letters_chars:\n",
    "                matches += 1\n",
    "                first_letters_chars.remove(char)  # Remove matched char\n",
    "        \n",
    "        if len(DBAName_chars) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate partial match score\n",
    "        return matches / len(DBAName_chars)\n",
    "    \n",
    "    def enhanced_DBAName_formation_score(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Enhanced DBAName formation score with special handling for common patterns\n",
    "        particularly optimized for business names with prefixes like \"Mc\".\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            float: Enhanced DBAName formation score between 0 and 1\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        \n",
    "        # Basic cleanup\n",
    "        DBAName = DBAName_clean.lower()\n",
    "        RawTransactionName = RawTransactionName_clean.lower()\n",
    "        \n",
    "        # Special case for \"Mc\" prefixes (common in restaurant names)\n",
    "        if RawTransactionName.startswith('mc') and len(DBAName) >= 1 and DBAName[0] == 'm':\n",
    "            # McDonalds -> MCD pattern\n",
    "            modified_RawTransactionName = RawTransactionName[2:]  # Remove \"mc\"\n",
    "            remaining_chars = DBAName[1:]  # Remove \"m\"\n",
    "            \n",
    "            # For \"MCD\" -> \"McDonalds\" pattern\n",
    "            if remaining_chars and len(modified_RawTransactionName) > 0:\n",
    "                # Check if remaining chars match consonants in the name\n",
    "                consonants = ''.join([c for c in modified_RawTransactionName if c not in 'aeiou'])\n",
    "                if remaining_chars in consonants:\n",
    "                    return 0.95\n",
    "                \n",
    "                # Check if first few consonants match remaining chars\n",
    "                first_consonants = ''.join([c for c in modified_RawTransactionName[:len(remaining_chars)*2] \n",
    "                                          if c not in 'aeiou'])\n",
    "                if remaining_chars in first_consonants:\n",
    "                    return 0.90\n",
    "                \n",
    "                # Check first letters after \"Mc\"\n",
    "                words = modified_RawTransactionName.split()\n",
    "                if words:\n",
    "                    first_letters = ''.join([word[0] for word in words if word])\n",
    "                    if remaining_chars in first_letters:\n",
    "                        return 0.90\n",
    "                    \n",
    "                    # Check if remaining chars appear in sequence in the words\n",
    "                    current_word_position = 0\n",
    "                    chars_found = 0\n",
    "                    for char in remaining_chars:\n",
    "                        for i in range(current_word_position, len(words)):\n",
    "                            if char in words[i]:\n",
    "                                chars_found += 1\n",
    "                                current_word_position = i + 1\n",
    "                                break\n",
    "                    \n",
    "                    if chars_found == len(remaining_chars):\n",
    "                        return 0.85\n",
    "            \n",
    "            # Even if not a perfect match, it's still a good score for Mc prefix\n",
    "            return 0.80\n",
    "        \n",
    "        # Check for brand name with location pattern (Toyota Corporation -> Western Toyota)\n",
    "        common_brands = ['toyota', 'ford', 'honda', 'bmw', 'walmart', 'target', 'starbucks']\n",
    "        location_prefixes = ['north', 'south', 'east', 'west', 'western', 'eastern', 'central']\n",
    "        \n",
    "        # Extract the key brand name (if present)\n",
    "        brand_match = None\n",
    "        for brand in common_brands:\n",
    "            if brand in DBAName.lower():\n",
    "                brand_match = brand\n",
    "                break\n",
    "            if brand in RawTransactionName.lower():\n",
    "                brand_match = brand\n",
    "                break\n",
    "        \n",
    "        if brand_match:\n",
    "            # Check if one name has the brand with a location prefix/suffix and the other has just the brand\n",
    "            has_location_prefix = any(prefix in DBAName.lower() or prefix in RawTransactionName.lower() \n",
    "                                     for prefix in location_prefixes)\n",
    "            \n",
    "            if has_location_prefix:\n",
    "                # If both contain the brand name but one has location prefix\n",
    "                if brand_match in DBAName.lower() and brand_match in RawTransactionName.lower():\n",
    "                    return 0.92\n",
    "        \n",
    "        # Standard DBAName formation - first letter of each word\n",
    "        words = RawTransactionName.split()\n",
    "        if not words:\n",
    "            return 0\n",
    "        \n",
    "        # Get first letters\n",
    "        first_letters = ''.join([word[0] for word in words if word])\n",
    "        \n",
    "        # If exact match, return high score\n",
    "        if DBAName == first_letters:\n",
    "            return 1.0\n",
    "        \n",
    "        # Check for consonant-based DBAName (common in business DBANames)\n",
    "        consonants = ''.join([c for c in RawTransactionName if c not in 'aeiou' and c.isalpha()])\n",
    "        consonant_match = 0.0\n",
    "        if len(DBAName) <= len(consonants):\n",
    "            # Check for sequential consonant match\n",
    "            DBAName_position = 0\n",
    "            for i, c in enumerate(consonants):\n",
    "                if DBAName_position < len(DBAName) and c == DBAName[DBAName_position]:\n",
    "                    DBAName_position += 1\n",
    "            \n",
    "            consonant_sequential_match = DBAName_position / len(DBAName) if len(DBAName) > 0 else 0\n",
    "            \n",
    "            # Check for any consonant match\n",
    "            matches = 0\n",
    "            consonants_copy = consonants\n",
    "            for char in DBAName:\n",
    "                if char in consonants_copy:\n",
    "                    matches += 1\n",
    "                    consonants_copy = consonants_copy.replace(char, '', 1)\n",
    "            \n",
    "            consonant_any_match = matches / len(DBAName) if len(DBAName) > 0 else 0\n",
    "            \n",
    "            # Take the better score\n",
    "            consonant_match = max(consonant_sequential_match, consonant_any_match)\n",
    "            \n",
    "            # Give higher scores for strong consonant matches\n",
    "            if consonant_match > 0.7:\n",
    "                return max(0.85, consonant_match)\n",
    "        \n",
    "        # Calculate ordered match score\n",
    "        ordered_match = 0\n",
    "        last_found_index = -1\n",
    "        RawTransactionName_chars = list(RawTransactionName)\n",
    "        \n",
    "        for char in DBAName:\n",
    "            found = False\n",
    "            for i in range(last_found_index + 1, len(RawTransactionName_chars)):\n",
    "                if char == RawTransactionName_chars[i]:\n",
    "                    ordered_match += 1\n",
    "                    last_found_index = i\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            # If we couldn't find the character in order, try looking anywhere\n",
    "            if not found:\n",
    "                for i in range(len(RawTransactionName_chars)):\n",
    "                    if i != last_found_index and char == RawTransactionName_chars[i]:\n",
    "                        ordered_match += 0.5  # Half credit for out-of-order match\n",
    "                        RawTransactionName_chars[i] = '_'  # Mark as used\n",
    "                        break\n",
    "        \n",
    "        ordered_match_score = ordered_match / len(DBAName) if len(DBAName) > 0 else 0\n",
    "        \n",
    "        # Return the best score from different matching strategies\n",
    "        return max(\n",
    "            ordered_match_score * 0.9,  # Ordered match is good but not perfect\n",
    "            consonant_match * 0.9,      # Consonant match is also valuable\n",
    "            0.4                         # Minimum score to prevent too low values\n",
    "        )\n",
    "    \n",
    "    def detect_complex_business_patterns(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Detect complex business name patterns that might be missed by basic algorithms\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of detected patterns with confidence scores\n",
    "        \"\"\"\n",
    "        DBAName_clean, RawTransactionName_clean = self.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        DBAName = DBAName_clean.lower()\n",
    "        RawTransactionName = RawTransactionName_clean.lower()\n",
    "        \n",
    "        patterns = {}\n",
    "        \n",
    "        # Government agency pattern (Dept of X <-> X Department)\n",
    "        agency_terms = ['department', 'dept', 'ministry', 'office', 'bureau', 'administration', 'agency']\n",
    "        has_agency_DBAName = any(term in DBAName for term in agency_terms)\n",
    "        has_agency_full = any(term in RawTransactionName for term in agency_terms)\n",
    "        \n",
    "        if has_agency_DBAName or has_agency_full:\n",
    "            # Check for inverted department structure pattern (common in government)\n",
    "            # e.g., \"Department of Treasury\" vs \"Treasury Department\"\n",
    "            words_DBAName = DBAName.split()\n",
    "            words_full = RawTransactionName.split()\n",
    "            \n",
    "            # Find agency term positions\n",
    "            agency_pos_a = -1\n",
    "            agency_pos_f = -1\n",
    "            \n",
    "            for term in agency_terms:\n",
    "                if agency_pos_a == -1 and any(term in word for word in words_DBAName):\n",
    "                    agency_pos_a = next((i for i, word in enumerate(words_DBAName) if term in word), -1)\n",
    "                if agency_pos_f == -1 and any(term in word for word in words_full):\n",
    "                    agency_pos_f = next((i for i, word in enumerate(words_full) if term in word), -1)\n",
    "                    \n",
    "            if agency_pos_a != -1 and agency_pos_f != -1:\n",
    "                # One at beginning, one at end (inverted structure)\n",
    "                if (agency_pos_a == 0 and agency_pos_f == len(words_full) - 1) or \\\n",
    "                   (agency_pos_f == 0 and agency_pos_a == len(words_DBAName) - 1):\n",
    "                    patterns['inverted_agency_structure'] = 1.0\n",
    "                else:\n",
    "                    patterns['similar_agency_structure'] = 0.7\n",
    "        \n",
    "        # Financial institution pattern\n",
    "        bank_terms = ['bank', 'credit union', 'financial', 'savings', 'investment', 'trust']\n",
    "        has_bank_DBAName = any(term in DBAName for term in bank_terms)\n",
    "        has_bank_full = any(term in RawTransactionName for term in bank_terms)\n",
    "        \n",
    "        if has_bank_DBAName or has_bank_full:\n",
    "            # Check for Bank of X vs X Bank pattern\n",
    "            if ('bank of' in DBAName and 'bank' in RawTransactionName and 'of' not in RawTransactionName) or \\\n",
    "               ('bank of' in RawTransactionName and 'bank' in DBAName and 'of' not in DBAName):\n",
    "                patterns['bank_name_inversion'] = 1.0\n",
    "        \n",
    "        # Abbreviation with ampersand pattern\n",
    "        if '&' in RawTransactionName or 'and' in RawTransactionName:\n",
    "            # Check if DBAName contains first letters of parts around ampersand\n",
    "            parts = re.split(r'\\s+&\\s+|\\s+and\\s+', RawTransactionName)\n",
    "            if len(parts) >= 2:\n",
    "                first_letters = ''.join(part[0] for part in parts if part)\n",
    "                if DBAName == first_letters:\n",
    "                    patterns['ampersand_DBAName'] = 1.0\n",
    "                elif all(letter in DBAName for letter in first_letters):\n",
    "                    patterns['partial_ampersand_DBAName'] = 0.8\n",
    "        \n",
    "        # Multi-word business name with DBAName\n",
    "        words_full = [w for w in RawTransactionName.split() if len(w) > 3]  # Only consider significant words\n",
    "        if len(words_full) >= 3 and len(DBAName) >= 2:\n",
    "            # Check if DBAName consists of first letters of significant words\n",
    "            first_letters = ''.join(word[0] for word in words_full)\n",
    "            if DBAName in first_letters:\n",
    "                patterns['multiword_business_DBAName'] = 0.9\n",
    "        \n",
    "        # Regional/branch variation of business\n",
    "        location_prefixes = ['north', 'south', 'east', 'west', 'central', 'metro', 'city', \n",
    "                            'downtown', 'regional', 'national', 'global', 'local']\n",
    "        \n",
    "        has_location_a = any(prefix in DBAName.split() for prefix in location_prefixes)\n",
    "        has_location_f = any(prefix in RawTransactionName.split() for prefix in location_prefixes)\n",
    "        \n",
    "        if has_location_a != has_location_f:  # One has location, other doesn't\n",
    "            # Remove location terms and compare the rest\n",
    "            a_words = [w for w in DBAName.split() if w not in location_prefixes]\n",
    "            f_words = [w for w in RawTransactionName.split() if w not in location_prefixes]\n",
    "            \n",
    "            # If remaining content is similar\n",
    "            a_text = ' '.join(a_words)\n",
    "            f_text = ' '.join(f_words)\n",
    "            \n",
    "            if a_text in f_text or f_text in a_text:\n",
    "                patterns['regional_branch_variation'] = 1.0\n",
    "            elif len(a_text) > 3 and len(f_text) > 3 and (a_text[:3] == f_text[:3]):\n",
    "                patterns['potential_branch_variation'] = 0.7\n",
    "        \n",
    "        return patterns\n",
    "    \n",
    "    def get_all_similarity_scores(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Calculate all similarity scores at once for efficiency\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "        DBA_Merchant_Category (str): Merchant category for the DBAName\n",
    "        RawTransactionName (str): The full name to match against\n",
    "        RawTransaction_Merchant_Category (str, optional): Merchant category for the RawTransactionName\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of algorithm name to score\n",
    "        \"\"\"\n",
    "        # Return empty dictionary if either DBAName or RawTransactionName is None\n",
    "        if DBAName is None or RawTransactionName is None:\n",
    "            return {}\n",
    "        \n",
    "        # Calculate all similarity scores\n",
    "        scores = {\n",
    "            'jaro_winkler': self.jaro_winkler_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'damerau_levenshtein': self.damerau_levenshtein_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'tfidf_cosine': self.tfidf_cosine_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'jaccard_bigram': self.jaccard_bigram_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'soundex': self.soundex_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'token_sort_ratio': self.token_sort_ratio_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'contains_ratio': self.contains_ratio_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'fuzzy_levenshtein': self.fuzzy_levenshtein_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'trie_approximate': self.trie_approximate_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'aho_corasick': self.aho_corasick_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'DBAName_formation': self.DBAName_formation_score(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "            'enhanced_DBAName_formation': self.enhanced_DBAName_formation_score(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        }\n",
    "        \n",
    "        # Add BERT similarity if available\n",
    "        if self.bert_embedder is not None:\n",
    "            scores['bert_similarity'] = self.bert_similarity(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        \n",
    "        # Add pattern detection scores\n",
    "        pattern_results = self.detect_complex_business_patterns(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        for pattern, score in pattern_results.items():\n",
    "            scores[f'pattern_{pattern}'] = score\n",
    "        \n",
    "        return scores\n",
    "\n",
    "    def get_dynamic_weights(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Get dynamically adjusted weights based on merchant name and category characteristics\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName or short name\n",
    "            DBA_Merchant_Category (str): Category for the DBA\n",
    "            RawTransactionName (str): The full merchant name\n",
    "            RawTransaction_Merchant_Category (str, optional): Category for the raw transaction\n",
    "                \n",
    "        Returns:\n",
    "            dict: Dictionary of dynamically adjusted algorithm weights\n",
    "        \"\"\"\n",
    "        # Start with base weights defined in the class\n",
    "        weights = self.base_weights.copy()\n",
    "        \n",
    "        # Adjust weights based on name characteristics\n",
    "        DBAName_len = len(DBAName) if isinstance(DBAName, str) else 0\n",
    "        RawTransactionName_len = len(RawTransactionName) if isinstance(RawTransactionName, str) else 0\n",
    "        \n",
    "        # Define primary_category based on DBA_Merchant_Category (THIS IS THE FIX)\n",
    "        primary_category = DBA_Merchant_Category if DBA_Merchant_Category is not None else \"Unknown\"\n",
    "        \n",
    "        # For very short DBANames (2-3 chars), boost DBAName formation importance\n",
    "        if 2 <= DBAName_len <= 3:\n",
    "            weights['DBAName_formation'] = 0.25\n",
    "            weights['enhanced_DBAName_formation'] = 0.20\n",
    "            weights['bert_similarity'] = 0.15\n",
    "            weights['contains_ratio'] = 0.15\n",
    "            \n",
    "        # For longer DBANames, focus more on semantic similarity\n",
    "        elif DBAName_len >= 4:\n",
    "            weights['bert_similarity'] = 0.25\n",
    "            weights['token_sort_ratio'] = 0.15\n",
    "            \n",
    "        # For very long full names, semantic understanding becomes more important\n",
    "        if RawTransactionName_len > 30:\n",
    "            weights['bert_similarity'] = 0.30\n",
    "            weights['tfidf_cosine'] = 0.15\n",
    "            \n",
    "        # If full name contains \"Bank\" or related terms, boost specific algorithms\n",
    "        if isinstance(RawTransactionName, str) and re.search(r'\\b(bank|credit|financial|capital)\\b', RawTransactionName.lower()):\n",
    "            weights['bert_similarity'] = 0.25\n",
    "            weights['DBAName_formation'] = 0.20\n",
    "            \n",
    "        # If full name contains location indicators (east, west, north, south)\n",
    "        if isinstance(RawTransactionName, str) and re.search(r'\\b(east|west|north|south|central)\\b', RawTransactionName.lower()):\n",
    "            weights['token_sort_ratio'] = 0.20\n",
    "            weights['bert_similarity'] = 0.25\n",
    "            \n",
    "        # Category-specific adjustments - using the primary category (now properly defined)\n",
    "        if primary_category == 'Restaurant':\n",
    "            weights['bert_similarity'] = 0.25\n",
    "            weights['fuzzy_levenshtein'] = 0.15\n",
    "        elif primary_category == 'Banking':\n",
    "            weights['DBAName_formation'] = 0.25\n",
    "            weights['enhanced_DBAName_formation'] = 0.25\n",
    "            weights['bert_similarity'] = 0.20\n",
    "        elif primary_category == 'Government':\n",
    "            weights['bert_similarity'] = 0.25\n",
    "            weights['DBAName_formation'] = 0.20\n",
    "            weights['token_sort_ratio'] = 0.15\n",
    "        elif primary_category == 'Medical':\n",
    "            weights['soundex'] = 0.15\n",
    "            weights['bert_similarity'] = 0.25\n",
    "        elif primary_category == 'Automotive':\n",
    "            weights['contains_ratio'] = 0.15\n",
    "            weights['token_sort_ratio'] = 0.15\n",
    "            weights['bert_similarity'] = 0.20\n",
    "        \n",
    "        # Special case: if categories differ significantly, increase semantic scores\n",
    "        if RawTransaction_Merchant_Category and RawTransaction_Merchant_Category != DBA_Merchant_Category:\n",
    "            category_similarity = self.calculate_category_similarity(DBA_Merchant_Category, RawTransaction_Merchant_Category)\n",
    "            if category_similarity < 0.5:  # Categories are quite different\n",
    "                weights['bert_similarity'] = max(weights.get('bert_similarity', 0.15) * 1.3, 0.30)  # Increase semantic understanding\n",
    "        \n",
    "        # If enhanced DBAName formation is available, use it instead of standard DBAName formation\n",
    "        if 'enhanced_DBAName_formation' not in weights and 'DBAName_formation' in weights:\n",
    "            weights['enhanced_DBAName_formation'] = weights['DBAName_formation']\n",
    "            weights['DBAName_formation'] = weights['DBAName_formation'] * 0.5  # Reduce standard weight\n",
    "        \n",
    "        # Normalize weights to sum to 1\n",
    "        weight_sum = sum(weights.values())\n",
    "        return {k: v/weight_sum for k, v in weights.items()}\n",
    "\n",
    "    def _adjust_weights(self, weight_adjustments):\n",
    "        \"\"\"\n",
    "        Adjust algorithm weights based on performance data\n",
    "        \n",
    "        Args:\n",
    "            weight_adjustments (dict): Dictionary of algorithm name to weight adjustment\n",
    "        \"\"\"\n",
    "        # Apply adjustments to the base weights\n",
    "        for algo, adjustment in weight_adjustments.items():\n",
    "            if algo in self.base_weights:\n",
    "                self.base_weights[algo] += adjustment\n",
    "        \n",
    "        # Normalize weights to sum to 1\n",
    "        weight_sum = sum(self.base_weights.values())\n",
    "        self.base_weights = {k: v/weight_sum for k, v in self.base_weights.items()}\n",
    "        \n",
    "        print(\"Weights adjusted successfully:\")\n",
    "        for algo, weight in sorted(self.base_weights.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "            print(f\"  {algo}: {weight:.4f}\")\n",
    "\n",
    "    def calculate_category_similarity(self, category1, category2):\n",
    "        \"\"\"\n",
    "        Calculate similarity between merchant categories\n",
    "        \"\"\"\n",
    "        # Case 1: Exact match\n",
    "        if category1 == category2:\n",
    "            return 1.0\n",
    "        \n",
    "        # Case 2: Categories are in the same parent category\n",
    "        parent_categories = {\n",
    "            'Financial': ['Banking', 'Insurance', 'Investment', 'Financial Services'],\n",
    "            'Food': ['Restaurant', 'Cafe', 'Fast Food', 'Dining'],\n",
    "            'Government': ['Federal Agency', 'Government', 'Public Sector']\n",
    "            # Add more parent categories as needed\n",
    "        }\n",
    "        \n",
    "        # Check if categories belong to the same parent category\n",
    "        for parent, subcategories in parent_categories.items():\n",
    "            if category1 in subcategories and category2 in subcategories:\n",
    "                return 0.8  # High similarity but not exact match\n",
    "        \n",
    "        # Case 3: Use BERT to calculate semantic similarity of categories\n",
    "        if self.bert_embedder is not None:\n",
    "            try:\n",
    "                category_similarity = self.bert_embedder.compute_similarity(category1, category2)\n",
    "                return category_similarity\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Default case: categories are different\n",
    "        return 0.0\n",
    "    \n",
    "    def compute_contextual_score(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category):\n",
    "        \"\"\"\n",
    "        Enhanced scoring that enforces category-based constraints:\n",
    "        - If categories match exactly: score can exceed 0.75 based on name similarity\n",
    "        - If categories don't match: score is capped at 0.75 regardless of name similarity\n",
    "        \n",
    "        Within these constraints, name similarity determines the specific score.\n",
    "        \"\"\"\n",
    "        # Calculate base weighted score using name similarity algorithms\n",
    "        weighted_score = self.compute_weighted_score(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        \n",
    "        # Check for exact category match\n",
    "        categories_match = (DBA_Merchant_Category == RawTransaction_Merchant_Category)\n",
    "        \n",
    "        # Get all algorithm scores for pattern boosting\n",
    "        all_scores = self.get_all_similarity_scores(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        \n",
    "        # Apply pattern-based boosting (same as original function)\n",
    "        pattern_boost = 1.0\n",
    "        for algo, score in all_scores.items():\n",
    "            if algo.startswith('pattern_') and score > 0:\n",
    "                # Different boost factors for different patterns\n",
    "                if 'inverted_agency_structure' in algo:\n",
    "                    pattern_boost += 0.35  # 35% boost for inverted agency structure\n",
    "                elif 'bank_name_inversion' in algo:\n",
    "                    pattern_boost += 0.35  # 35% boost for bank name inversion\n",
    "                elif 'ampersand_DBAName' in algo:\n",
    "                    pattern_boost += 0.30  # 30% boost for ampersand DBAName\n",
    "                elif 'multiword_business_DBAName' in algo:\n",
    "                    pattern_boost += 0.25  # 25% boost for multiword business DBAName\n",
    "                elif 'regional_branch_variation' in algo:\n",
    "                    pattern_boost += 0.35  # 35% boost for regional branch variation\n",
    "                elif 'partial' in algo:\n",
    "                    pattern_boost += 0.20  # 20% boost for partial patterns\n",
    "                else:\n",
    "                    pattern_boost += 0.15  # 15% boost for other patterns\n",
    "        \n",
    "        # Apply special boost for McDonalds patterns and other special cases\n",
    "        # (keeping original code here)\n",
    "        if (('mc' in DBAName.lower() and 'donald' in RawTransactionName.lower()) or \n",
    "            ('mc' in RawTransactionName.lower() and 'donald' in DBAName.lower())):\n",
    "            pattern_boost += 0.40  # 40% boost for McDonalds patterns\n",
    "        \n",
    "        # Apply the pattern boost, cap at 1.6 (60% boost max)\n",
    "        boosted_score = min(1.0, weighted_score * min(pattern_boost, 1.6))\n",
    "        \n",
    "        # Apply category-based constraints according to business rule\n",
    "        if categories_match:\n",
    "            # If categories match exactly and name similarity is good (score > 0.60),\n",
    "            # ensure score is at least 0.75\n",
    "            if boosted_score > 0.60:\n",
    "                final_score = max(0.75, boosted_score)\n",
    "            else:\n",
    "                # Categories match but names are too dissimilar, keep original score\n",
    "                final_score = boosted_score\n",
    "        else:\n",
    "            # If categories don't match, cap the score at 0.75 regardless of name similarity\n",
    "            final_score = min(0.75, boosted_score)\n",
    "        \n",
    "        return final_score\n",
    "    \n",
    "    def compute_weighted_score(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category=None):\n",
    "        \"\"\"\n",
    "        Compute weighted similarity score using domain-specific weights\n",
    "        \n",
    "        Args:\n",
    "            DBAName (str): The DBAName to match\n",
    "            DBA_Merchant_Category (str): Category for the DBA\n",
    "            RawTransactionName (str): The full name to match against\n",
    "            RawTransaction_Merchant_Category (str, optional): Category for the raw transaction\n",
    "            \n",
    "        Returns:\n",
    "            float: Weighted similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        # Get all similarity scores\n",
    "        all_scores = self.get_all_similarity_scores(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        \n",
    "        # Get dynamic weights based on name characteristics\n",
    "        weights = self.get_dynamic_weights(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        \n",
    "        # Calculate weighted score\n",
    "        weighted_score = 0.0\n",
    "        weights_used = 0.0\n",
    "        \n",
    "        for algo, score in all_scores.items():\n",
    "            if algo in weights:\n",
    "                weighted_score += weights[algo] * score\n",
    "                weights_used += weights[algo]\n",
    "        \n",
    "        # Handle case where some algorithms are missing\n",
    "        if weights_used > 0:\n",
    "            # Normalize by weights actually used\n",
    "            weighted_score /= weights_used\n",
    "        \n",
    "        return weighted_score\n",
    "    \n",
    "    def compute_enhanced_score(self, DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category):\n",
    "        \"\"\"Modified signature to include both categories\"\"\"\n",
    "        return self.compute_contextual_score(DBAName, DBA_Merchant_Category, \n",
    "                                            RawTransactionName, RawTransaction_Merchant_Category)\n",
    "# Define dictionary of common DBANames for well-known brands\n",
    "COMMON_DBANameS = {\n",
    "    # Restaurant chains\n",
    "    'MCD': 'McDonalds',\n",
    "    'MD': 'McDonalds',\n",
    "    'MCDs': 'McDonalds',\n",
    "    'MCDS': 'McDonalds',\n",
    "    'BK': 'Burger King',\n",
    "    'KFC': 'Kentucky Fried Chicken',\n",
    "    'SB': 'Starbucks',\n",
    "    'SBUX': 'Starbucks',\n",
    "    'TB': 'Taco Bell',\n",
    "    'WEN': 'Wendys',\n",
    "    'DQ': 'Dairy Queen',\n",
    "    'PH': 'Pizza Hut',\n",
    "    'DNKN': 'Dunkin Donuts',\n",
    "    'CFA': 'Chick-fil-A',\n",
    "    'CMG': 'Chipotle Mexican Grill',\n",
    "    \n",
    "    # Banking and Financial institutions\n",
    "    'BAC': 'Bank of America',\n",
    "    'BOFA': 'Bank of America',\n",
    "    'JPM': 'JPMorgan Chase',\n",
    "    'WFC': 'Wells Fargo',\n",
    "    'C': 'Citigroup',\n",
    "    'GS': 'Goldman Sachs',\n",
    "    'MS': 'Morgan Stanley',\n",
    "    'AXP': 'American Express',\n",
    "    'HSBC': 'Hongkong and Shanghai Banking Corporation',\n",
    "    'RBA': 'Reserve Bank of Australia',\n",
    "    'CBA': 'Commonwealth Bank of Australia',\n",
    "    \n",
    "    # Technology companies\n",
    "    'MSFT': 'Microsoft',\n",
    "    'AAPL': 'Apple',\n",
    "    'GOOGL': 'Google',\n",
    "    'GOOG': 'Google',\n",
    "    'AMZN': 'Amazon',\n",
    "    'FB': 'Facebook',\n",
    "    'META': 'Meta Platforms',\n",
    "    'NFLX': 'Netflix',\n",
    "    'TSLA': 'Tesla',\n",
    "    \n",
    "    # Automotive companies\n",
    "    'TM': 'Toyota Motor',\n",
    "    'TOYOF': 'Toyota',\n",
    "    'TOYOTA': 'Toyota Corporation',\n",
    "    'F': 'Ford',\n",
    "    'GM': 'General Motors',\n",
    "    'HMC': 'Honda Motor Company',\n",
    "    'HNDAF': 'Honda',\n",
    "    'NSANY': 'Nissan',\n",
    "    'BMWYY': 'BMW',\n",
    "    'VWAGY': 'Volkswagen',\n",
    "    \n",
    "    # Retail companies\n",
    "    'WMT': 'Walmart',\n",
    "    'TGT': 'Target',\n",
    "    'COST': 'Costco',\n",
    "    'HD': 'Home Depot',\n",
    "    'LOW': 'Lowes',\n",
    "    'BBY': 'Best Buy',\n",
    "    'EBAY': 'eBay',\n",
    "    'DG': 'Dollar General',\n",
    "    'DLTR': 'Dollar Tree',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c96d1f-0361-4640-9fe5-6ca92dae5958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data Loading and Processing Functions\n",
    "\n",
    "def load_merchant_data(file_path=\"Acronym_extramcc.xlsx\"):\n",
    "    \"\"\"\n",
    "    Load merchant data from Excel file, with fallback to sample data if file not found\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file containing merchant data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Pandas DataFrame with merchant data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Display basic information\n",
    "        print(f\"Loaded {len(df)} merchant entries from {file_path}\")\n",
    "        print(f\"Columns: {df.columns.tolist()}\")\n",
    "        print(f\"\\nSample data:\")\n",
    "        print(df.head(3))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading merchant data: {e}\")\n",
    "        print(\"Using sample data instead...\")\n",
    "        \n",
    "        # Create a sample dataframe with diverse examples from multiple domains\n",
    "        sample_data = {\n",
    "            'DBAName': [\n",
    "                # Banking examples\n",
    "                'BoA Bank', 'CBA', 'RBA', 'JPM', 'HSBC',\n",
    "                # Restaurant examples\n",
    "                'MCD', 'StarBucks', 'BK', 'KFC', 'TB',\n",
    "                # Automotive examples\n",
    "                'Western Toyota', 'Mosman Toyota', 'GM', 'BMW', 'Ford Motor',\n",
    "                # Technology examples\n",
    "                'MSFT', 'GOOGL', 'AMZN', 'AAPL', 'IBM',\n",
    "                # Retail examples\n",
    "                'WMT', 'Wal-Mart', 'Target', 'TGT', 'HD',\n",
    "                # Government examples\n",
    "                'EPA', 'DOJ', 'Dept of Defense', 'Treasury Dept', 'IRS',\n",
    "                # Others\n",
    "                'BHP', 'Seven Eleven', 'JnJ', 'AMP', 'AFL'\n",
    "            ],\n",
    "            'RawTransactionName': [\n",
    "                # Banking examples\n",
    "                'Bank of America', 'Commonwealth Bank of Australia', 'Reserve Bank of Australia',\n",
    "                'JPMorgan Chase', 'Hongkong and Shanghai Banking Corporation',\n",
    "                # Restaurant examples\n",
    "                'McDonalds', 'Starbucks Coffee', 'Burger King', 'Kentucky Fried Chicken', 'Taco Bell',\n",
    "                # Automotive examples\n",
    "                'Toyota Corporation', 'Toyota Corporation', 'General Motors',\n",
    "                'Bayerische Motoren Werke', 'Ford Motor Company',\n",
    "                # Technology examples\n",
    "                'Microsoft Corporation', 'Google Inc', 'Amazon.com Inc', 'Apple Inc',\n",
    "                'International Business Machines',\n",
    "                # Retail examples\n",
    "                'Walmart Inc', 'Walmart Supercenter', 'Target Corporation', 'Target Stores', 'Home Depot',\n",
    "                # Government examples\n",
    "                'Environmental Protection Agency', 'Department of Justice',\n",
    "                'Department of Defense', 'Department of the Treasury', 'Internal Revenue Service',\n",
    "                # Others\n",
    "                'Broken Hill Proprietary Company', '7-Eleven', 'Johnson & Johnson',\n",
    "                'Australian Mutual Provident Society', 'Australian Football League'\n",
    "            ],\n",
    "            'Merchant_Category': [\n",
    "                # Banking examples\n",
    "                'Banking', 'Banking', 'Banking', 'Banking', 'Banking',\n",
    "                # Restaurant examples\n",
    "                'Restaurant', 'Restaurant', 'Restaurant', 'Restaurant', 'Restaurant',\n",
    "                # Automotive examples\n",
    "                'Automotive', 'Automotive', 'Automotive', 'Automotive', 'Automotive',\n",
    "                # Technology examples\n",
    "                'Technology', 'Technology', 'Technology', 'Technology', 'Technology',\n",
    "                # Retail examples\n",
    "                'Retail', 'Supermart', 'Retail', 'Retail', 'Retail',\n",
    "                # Government examples\n",
    "                'Government', 'Government', 'Government', 'Government', 'Government',\n",
    "                # Others\n",
    "                'Financial', 'Clothing', 'Misc Speciality', 'Government', 'Sports'\n",
    "            ]\n",
    "        }\n",
    "        df = pd.DataFrame(sample_data)\n",
    "        print(df)\n",
    "        return df\n",
    "\n",
    "def standardize_column_names(df):\n",
    "    \"\"\"\n",
    "    Standardize column names to ensure consistency\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Map of possible column names to standardized names\n",
    "    column_mappings = {\n",
    "        'Full Name': 'RawTransactionName',\n",
    "        'fullname': 'RawTransactionName',\n",
    "        'full name': 'RawTransactionName',\n",
    "        'Merchant Category': 'RawTransaction_Merchant_Category',\n",
    "        'merchant_category': 'RawTransaction_Merchant_Category',\n",
    "        'Category': 'RawTransaction_Merchant_Category',\n",
    "        'category': 'RawTransaction_Merchant_Category',\n",
    "        'merchant category': 'RawTransaction_Merchant_Category',\n",
    "        'DBAName': 'DBAName',\n",
    "        'Abbreviation': 'DBAName',\n",
    "        'ShortName': 'DBAName',\n",
    "        'Short_Name': 'DBAName',\n",
    "        'short_name': 'DBAName',\n",
    "        'short name': 'DBAName',\n",
    "        # Add DBA_Merchant_Category mappings\n",
    "        'DBA Category': 'DBA_Merchant_Category',\n",
    "        'DBA_Category': 'DBA_Merchant_Category',\n",
    "        'dba category': 'DBA_Merchant_Category',\n",
    "        'dba_category': 'DBA_Merchant_Category',\n",
    "        'DBA Merchant Category': 'DBA_Merchant_Category',\n",
    "        'DBAMerchantCategory': 'DBA_Merchant_Category'\n",
    "    }\n",
    "    \n",
    "    # Apply mapping\n",
    "    for old_name, new_name in column_mappings.items():\n",
    "        if old_name in df_copy.columns:\n",
    "            df_copy.rename(columns={old_name: new_name}, inplace=True)\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    required_columns = ['DBAName', 'RawTransactionName']\n",
    "    missing_columns = [col for col in required_columns if col not in df_copy.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Required columns {missing_columns} not found in the DataFrame\")\n",
    "    \n",
    "    # Ensure RawTransaction_Merchant_Category exists\n",
    "    if 'RawTransaction_Merchant_Category' not in df_copy.columns:\n",
    "        print(\"Warning: 'RawTransaction_Merchant_Category' column not found. Adding with default value 'Unknown'.\")\n",
    "        df_copy['RawTransaction_Merchant_Category'] = 'Unknown'\n",
    "    \n",
    "    # Ensure DBA_Merchant_Category exists\n",
    "    if 'DBA_Merchant_Category' not in df_copy.columns:\n",
    "        df_copy['DBA_Merchant_Category'] = df_copy['RawTransaction_Merchant_Category']\n",
    "    \n",
    "    # Remove the redundant Merchant_Category if it exists\n",
    "    if 'Merchant_Category' in df_copy.columns:\n",
    "        df_copy.drop(columns=['Merchant_Category'], inplace=True)\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def preprocess_merchant_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess merchant data for matching\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Preprocessed DataFrame\n",
    "    \"\"\"\n",
    "    # Standardize column names\n",
    "    df = standardize_column_names(df)\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    df_processed['DBAName'] = df_processed['DBAName'].fillna('').astype(str)\n",
    "    df_processed['RawTransactionName'] = df_processed['RawTransactionName'].fillna('').astype(str)\n",
    "    \n",
    "    # Remove rows with empty DBANames or full names\n",
    "    orig_rows = len(df_processed)\n",
    "    df_processed = df_processed[(df_processed['DBAName'].str.strip() != '') & \n",
    "                                (df_processed['RawTransactionName'].str.strip() != '')]\n",
    "    \n",
    "    if len(df_processed) < orig_rows:\n",
    "        print(f\"Removed {orig_rows - len(df_processed)} rows with empty DBANames or full names\")\n",
    "    \n",
    "    # Map categories to standard merchant categories (renamed from standard_domains)\n",
    "    standard_merchant_categories = {\n",
    "        'Restaurant': ['restaurant', 'food', 'dining', 'cafe', 'coffee', 'fast food'],\n",
    "        'Banking': ['banking', 'bank', 'financial institution', 'credit union'],\n",
    "        'Retail': ['retail', 'store', 'shop', 'department store', 'supermarket', 'grocery'],\n",
    "        'Technology': ['technology', 'tech', 'software', 'hardware', 'electronics', 'computer'],\n",
    "        'Automotive': ['automotive', 'auto', 'car', 'vehicle', 'dealership'],\n",
    "        'Medical': ['medical', 'health', 'healthcare', 'hospital', 'clinic', 'pharmacy'],\n",
    "        'Government': ['government', 'gov', 'agency', 'federal', 'state', 'municipal'],\n",
    "        'Education': ['education', 'school', 'university', 'college', 'academic'],\n",
    "        'Financial': ['financial', 'finance', 'investment', 'insurance', 'wealth management']\n",
    "    }\n",
    "    \n",
    "    def map_to_standard_merchant_category(category):\n",
    "        \"\"\"\n",
    "        Map input category to a standardized merchant category based on keywords\n",
    "        \n",
    "        Args:\n",
    "            category (str): Input category name\n",
    "            \n",
    "        Returns:\n",
    "            str: Standardized merchant category name or original if no match\n",
    "        \"\"\"\n",
    "        category_lower = category.lower()\n",
    "        for merchant_category, keywords in standard_merchant_categories.items():\n",
    "            if any(keyword in category_lower for keyword in keywords):\n",
    "                return merchant_category\n",
    "        return category  # Return original if no match\n",
    "    \n",
    "    # Apply merchant category mapping if Merchant_Category exists\n",
    "    if 'Merchant_Category' in df_processed.columns:\n",
    "        df_processed['Merchant_Category'] = df_processed['Merchant_Category'].apply(map_to_standard_merchant_category)\n",
    "    \n",
    "    # If DBA_Merchant_Category exists, apply the same standardization\n",
    "    if 'DBA_Merchant_Category' in df_processed.columns:\n",
    "        df_processed['DBA_Merchant_Category'] = df_processed['DBA_Merchant_Category'].apply(map_to_standard_merchant_category)\n",
    "    \n",
    "    # If RawTransaction_Merchant_Category exists, update Merchant_Category\n",
    "    if 'RawTransaction_Merchant_Category' in df_processed.columns:\n",
    "        df_processed['Merchant_Category'] = df_processed['RawTransaction_Merchant_Category']\n",
    "    \n",
    "    # Print category distribution\n",
    "    print(\"Category distribution after preprocessing:\")\n",
    "    if 'Merchant_Category' in df_processed.columns:\n",
    "        print(df_processed['Merchant_Category'].value_counts().head(10))\n",
    "    \n",
    "    return df_processed\n",
    "# IMPORTANT: This function should NOT be indented under any other function\n",
    "def process_merchant_data(merchant_df, merchant_matcher):\n",
    "    \"\"\"\n",
    "    Process merchant data with separate categories for DBA and RawTransaction\n",
    "    \"\"\"\n",
    "    # Initialize results DataFrame\n",
    "    results_df = merchant_df.copy()\n",
    "    results_df['Basic_Score'] = 0.0\n",
    "    results_df['Enhanced_Score'] = 0.0\n",
    "    \n",
    "    # Define the batch size and start time for progress tracking\n",
    "    batch_size = 20  # Default batch size for progress reporting\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process each merchant entry\n",
    "    for idx, row in results_df.iterrows():\n",
    "        DBAName = row['DBAName']\n",
    "        DBA_Merchant_Category = row['DBA_Merchant_Category']\n",
    "        RawTransactionName = row['RawTransactionName']\n",
    "        RawTransaction_Merchant_Category = row['Merchant_Category']\n",
    "        \n",
    "        # Compute similarity scores\n",
    "        try:\n",
    "            basic_score = merchant_matcher.compute_weighted_score(\n",
    "                DBAName, DBA_Merchant_Category, \n",
    "                RawTransactionName, RawTransaction_Merchant_Category\n",
    "            )\n",
    "            \n",
    "            enhanced_score = merchant_matcher.compute_enhanced_score(\n",
    "                DBAName, DBA_Merchant_Category,\n",
    "                RawTransactionName, RawTransaction_Merchant_Category\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "            basic_score = 0.0\n",
    "            enhanced_score = 0.0\n",
    "        \n",
    "        # Store scores\n",
    "        results_df.at[idx, 'Basic_Score'] = basic_score\n",
    "        results_df.at[idx, 'Enhanced_Score'] = enhanced_score\n",
    "        \n",
    "        # Show progress\n",
    "        if idx % batch_size == 0 or idx == len(results_df) - 1:\n",
    "            progress = (idx + 1) / len(results_df) * 100\n",
    "            elapsed = time.time() - start_time\n",
    "            remaining = elapsed / (idx + 1) * (len(results_df) - idx - 1) if idx > 0 else 0\n",
    "            print(f\"Progress: {progress:.1f}% ({idx+1}/{len(results_df)}) - \"\n",
    "                  f\"Elapsed: {elapsed:.1f}s - Est. remaining: {remaining:.1f}s\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Processing completed in {total_time:.2f} seconds\")\n",
    "    \n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "874c9bd1-f35c-4369-bf15-384537ef96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Match Categorization and Analysis Functions\n",
    "\n",
    "def add_match_categories(results_df, thresholds=None):\n",
    "    \"\"\"\n",
    "    Add match categories based on thresholds\n",
    "    \n",
    "    Args:\n",
    "        results_df (DataFrame): Results DataFrame with similarity scores\n",
    "        thresholds (dict): Thresholds for categorization\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with match categories\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = {\n",
    "            'Exact Match': 0.95,\n",
    "            'Strong Match': 0.85,\n",
    "            'Probable Match': 0.75,\n",
    "            'Possible Match': 0.65,\n",
    "            'Weak Match': 0.50,\n",
    "            'No Match': 0.0\n",
    "        }\n",
    "    \n",
    "    df = results_df.copy()\n",
    "    \n",
    "    # Add category column based on Enhanced_Score\n",
    "    df['Match_Category'] = 'No Match'\n",
    "    \n",
    "    # Apply thresholds in reverse order (highest first)\n",
    "    for category, threshold in sorted(thresholds.items(), key=lambda x: x[1], reverse=True):\n",
    "        df.loc[df['Enhanced_Score'] >= threshold, 'Match_Category'] = category\n",
    "    \n",
    "    # Print distribution of match categories\n",
    "    print(\"\\nMatch category distribution:\")\n",
    "    category_counts = df['Match_Category'].value_counts().sort_index()\n",
    "    for category, count in category_counts.items():\n",
    "        percentage = count / len(df) * 100\n",
    "        print(f\"  {category}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def analyze_merchant_results(results_df, sample_size=5):\n",
    "    \"\"\"\n",
    "    Analyze merchant matching results and print detailed information\n",
    "    \n",
    "    Args:\n",
    "        results_df (DataFrame): Results DataFrame with similarity scores\n",
    "        sample_size (int): Number of samples to show for each category\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis results\n",
    "    \"\"\"\n",
    "    # Add match categories\n",
    "    categorized_df = add_match_categories(results_df)\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    mean_basic = categorized_df['Basic_Score'].mean()\n",
    "    mean_enhanced = categorized_df['Enhanced_Score'].mean()\n",
    "    improvement = (mean_enhanced - mean_basic) / mean_basic * 100 if mean_basic > 0 else 0\n",
    "    \n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"  Average Basic Score: {mean_basic:.4f}\")\n",
    "    print(f\"  Average Enhanced Score: {mean_enhanced:.4f}\")\n",
    "    print(f\"  Overall Improvement: {improvement:.2f}%\")\n",
    "    \n",
    "    # Print samples for each category\n",
    "    categories = categorized_df['Match_Category'].unique()\n",
    "    print(\"\\nSample matches by category:\")\n",
    "    \n",
    "    for category in sorted(categories, key=lambda x: thresholds.get(x, 0), reverse=True):\n",
    "        cat_df = categorized_df[categorized_df['Match_Category'] == category]\n",
    "        cat_samples = min(sample_size, len(cat_df))\n",
    "        \n",
    "        if cat_samples > 0:\n",
    "            print(f\"\\n{category} ({len(cat_df)} entries):\")\n",
    "            samples = cat_df.sample(cat_samples) if cat_samples < len(cat_df) else cat_df\n",
    "            \n",
    "            for _, row in samples.iterrows():\n",
    "                print(f\"  {row['DBAName']} <-> {row['RawTransactionName']} \"\n",
    "                      f\"(Category: {row['Merchant_Category']}, Score: {row['Enhanced_Score']:.4f})\")\n",
    "    \n",
    "    # Analyze by merchant category\n",
    "    print(\"\\nPerformance by Merchant Category:\")\n",
    "    \n",
    "    category_stats = {}\n",
    "    for category in categorized_df['Merchant_Category'].unique():\n",
    "        cat_df = categorized_df[categorized_df['Merchant_Category'] == category]\n",
    "        \n",
    "        basic_mean = cat_df['Basic_Score'].mean()\n",
    "        enhanced_mean = cat_df['Enhanced_Score'].mean()\n",
    "        cat_improvement = (enhanced_mean - basic_mean) / basic_mean * 100 if basic_mean > 0 else 0\n",
    "        \n",
    "        category_stats[category] = {\n",
    "            'count': len(cat_df),\n",
    "            'basic_mean': basic_mean,\n",
    "            'enhanced_mean': enhanced_mean,\n",
    "            'improvement': cat_improvement\n",
    "        }\n",
    "        \n",
    "        print(f\"  {category} ({len(cat_df)} entries):\")\n",
    "        print(f\"    Basic Score: {basic_mean:.4f}\")\n",
    "        print(f\"    Enhanced Score: {enhanced_mean:.4f}\")\n",
    "        print(f\"    Improvement: {cat_improvement:.2f}%\")\n",
    "    \n",
    "    # Identify most improved matches\n",
    "    categorized_df['Improvement'] = categorized_df['Enhanced_Score'] - categorized_df['Basic_Score']\n",
    "    most_improved = categorized_df.nlargest(sample_size, 'Improvement')\n",
    "    \n",
    "    print(\"\\nMost improved matches:\")\n",
    "    for _, row in most_improved.iterrows():\n",
    "        improvement = row['Improvement']\n",
    "        improvement_pct = improvement / row['Basic_Score'] * 100 if row['Basic_Score'] > 0 else float('inf')\n",
    "        \n",
    "        print(f\"  {row['DBAName']} <-> {row['RawTransactionName']} \"\n",
    "              f\"(Category: {row['Merchant_Category']})\")\n",
    "        print(f\"    Basic: {row['Basic_Score']:.4f}, Enhanced: {row['Enhanced_Score']:.4f}, \"\n",
    "              f\"Improvement: {improvement:.4f} ({improvement_pct:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'overall_stats': {\n",
    "            'mean_basic': mean_basic,\n",
    "            'mean_enhanced': mean_enhanced,\n",
    "            'improvement': improvement\n",
    "        },\n",
    "        'category_stats': category_stats\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67d491c4-30f6-4aa0-8023-1b4dbd571d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 7: Pipeline Execution functions\n",
    "\n",
    "def run_merchant_matching_pipeline(input_file, output_file=None, perform_merchant_category_adaptation=True):\n",
    "    \"\"\"\n",
    "    Run the complete merchant matching pipeline with enhanced models\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input file\n",
    "        output_file (str, optional): Path to save results\n",
    "        perform_merchant_category_adaptation (bool): Whether to perform merchant category adaptation\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Results DataFrame\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Running enhanced merchant matching pipeline...\")\n",
    "    print(f\"Input file: {input_file}\")\n",
    "    \n",
    "    # Step 1: Load merchant data\n",
    "    print(\"\\nStep 1: Loading merchant data...\")\n",
    "    try:\n",
    "        merchant_df = pd.read_excel(input_file)\n",
    "        print(f\"Successfully loaded {len(merchant_df)} records from {input_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {input_file}: {e}\")\n",
    "        print(\"Using sample data instead...\")\n",
    "        merchant_df = load_merchant_data(None)\n",
    "    \n",
    "    # Step 2: Preprocess merchant data\n",
    "    print(\"\\nStep 2: Preprocessing merchant data...\")\n",
    "    processed_df = preprocess_merchant_data(merchant_df)\n",
    "    \n",
    "    # Step 3: Initialize the enhanced matcher (already done in previous cells)\n",
    "    print(\"\\nStep 3: Setting up enhanced matcher with MPNet model...\")\n",
    "    # Use the pre-initialized merchant_matcher from Cell 6\n",
    "    \n",
    "    # Step 4: Perform merchant category adaptation if requested\n",
    "    if perform_merchant_category_adaptation and hasattr(merchant_matcher.bert_embedder, 'adapt_to_merchant_category'):\n",
    "        print(\"\\nStep 4: Performing merchant category adaptation for merchant names...\")\n",
    "        try:\n",
    "            # Use a subset of high-confidence matches for adaptation\n",
    "            adaptation_df = processed_df.sample(min(500, len(processed_df)))\n",
    "            merchant_matcher.bert_embedder.adapt_to_merchant_category(adaptation_df)\n",
    "            print(\"Merchant category adaptation completed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Merchant category adaptation failed: {e}\")\n",
    "            print(\"Continuing without merchant category adaptation...\")\n",
    "    else:\n",
    "        print(\"\\nStep 4: Skipping merchant category adaptation...\")\n",
    "    \n",
    "    # Step 5: Process merchant data and compute similarity scores\n",
    "    print(\"\\nStep 5: Computing similarity scores...\")\n",
    "    results_df = process_merchant_data(processed_df, merchant_matcher)\n",
    "    \n",
    "    # Step 6: Add match categories based on thresholds\n",
    "    print(\"\\nStep 6: Categorizing matches based on threshold...\")\n",
    "    categorized_df = add_match_categories(results_df, thresholds)\n",
    "    \n",
    "    # Step 7: Analyze results\n",
    "    print(\"\\nStep 7: Analyzing matching results...\")\n",
    "    analysis_results = analyze_merchant_results(categorized_df)\n",
    "    \n",
    "    # Step 8: Save results if output file is provided\n",
    "    if output_file:\n",
    "        print(f\"\\nStep 8: Saving results to {output_file}...\")\n",
    "        try:\n",
    "            categorized_df.to_excel(output_file, index=False)\n",
    "            print(f\"Results successfully saved to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results: {e}\")\n",
    "    else:\n",
    "        print(\"\\nStep 8: Skipping results saving (no output file specified)\")\n",
    "    \n",
    "    # Calculate and print timing information\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nPipeline completed in {total_time:.2f} seconds\")\n",
    "    print(f\"Processed {len(categorized_df)} merchant entries\")\n",
    "    print(f\"Average processing time per entry: {total_time/len(categorized_df):.4f} seconds\")\n",
    "    \n",
    "    return categorized_df\n",
    "\n",
    "def process_DBAName_file_and_export_results(input_file=\"Acronym_extramcc.xlsx\", \n",
    "                                           output_file=\"DBAName_Matching_Results.xlsx\"):\n",
    "    \"\"\"\n",
    "    Process the Acronym_extramcc.xlsx file and export comprehensive matching results\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to Acronym_extramcc.xlsx file\n",
    "        output_file (str): Path for the output Excel file with results\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Processed results with all matching scores\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Loading and processing data from {input_file}...\")\n",
    "    \n",
    "    # Step 1: Load the data from Acronym_extramcc.xlsx\n",
    "    try:\n",
    "        merchant_df = pd.read_excel(input_file)\n",
    "        print(f\"Successfully loaded {len(merchant_df)} records from {input_file}\")\n",
    "        print(f\"Columns found: {merchant_df.columns.tolist()}\")\n",
    "        print(f\"\\nSample data (first 3 rows):\")\n",
    "        print(merchant_df.head(3))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {input_file}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Preprocess the data\n",
    "    print(\"\\nPreprocessing merchant data...\")\n",
    "    processed_df = preprocess_merchant_data(merchant_df)\n",
    "    \n",
    "    # Step 3: Process with merchant matcher to get similarity scores\n",
    "    print(\"\\nCalculating similarity scores using enhanced merchant matcher...\")\n",
    "    results_df = process_merchant_data(processed_df, merchant_matcher)\n",
    "    \n",
    "    # Step 4: Add match categories based on score thresholds\n",
    "    print(\"\\nCategorizing matches based on thresholds...\")\n",
    "    categorized_df = add_match_categories(results_df, thresholds)\n",
    "    \n",
    "    # Step 5: Export the results\n",
    "    print(f\"\\nExporting results to {output_file}...\")\n",
    "    \n",
    "    try:\n",
    "        # Create a writer for Excel output\n",
    "        with pd.ExcelWriter(output_file) as writer:\n",
    "            # Sheet 1: Main results with all scores\n",
    "            categorized_df.to_excel(writer, sheet_name=\"Matching_Results\", index=False)\n",
    "            \n",
    "            # Sheet 2: Summary statistics\n",
    "            category_counts = categorized_df['Match_Category'].value_counts().reset_index()\n",
    "            category_counts.columns = ['Match_Category', 'Count']\n",
    "            category_counts['Percentage'] = (category_counts['Count'] / len(categorized_df) * 100).round(2)\n",
    "            \n",
    "            # Sort by threshold order\n",
    "            category_order = list(thresholds.keys())\n",
    "            category_counts['Order'] = category_counts['Match_Category'].map({cat: i for i, cat in enumerate(category_order)})\n",
    "            category_counts = category_counts.sort_values('Order').drop('Order', axis=1)\n",
    "            \n",
    "            category_counts.to_excel(writer, sheet_name=\"Category_Summary\", index=False)\n",
    "            \n",
    "            # Sheet 3: Algorithm scores analysis\n",
    "            # For each merchant pair, get all individual algorithm scores\n",
    "            analysis_rows = []\n",
    "            \n",
    "            # Sample 50 entries (or all if fewer) for detailed algorithm analysis\n",
    "            sample_size = min(50, len(categorized_df))\n",
    "            sampled_df = categorized_df.sample(sample_size)\n",
    "            \n",
    "            for idx, row in sampled_df.iterrows():\n",
    "                DBAName = row['DBAName']\n",
    "                # Get merchant category data from the row\n",
    "                dba_category = row['DBA_Merchant_Category']\n",
    "                RawTransactionName = row['RawTransactionName']\n",
    "                raw_category = row['Merchant_Category']\n",
    "                \n",
    "                # Get all algorithm scores - NOTE: No reference to 'domain' here\n",
    "                all_scores = merchant_matcher.get_all_similarity_scores(\n",
    "                    DBAName, \n",
    "                    dba_category,     # Use the DBA category from the row \n",
    "                    RawTransactionName, \n",
    "                    raw_category      # Use the raw transaction category from the row\n",
    "                )\n",
    "                \n",
    "                # Add basic row info - avoid using 'domain'\n",
    "                score_row = {\n",
    "                    'DBAName': DBAName,\n",
    "                    'DBA_Category': dba_category,\n",
    "                    'RawTransactionName': RawTransactionName,\n",
    "                    'Raw_Category': raw_category,\n",
    "                    'Enhanced_Score': row['Enhanced_Score'],\n",
    "                    'Match_Category': row['Match_Category']\n",
    "                }\n",
    "                \n",
    "                # Add individual algorithm scores\n",
    "                for algo, score in all_scores.items():\n",
    "                    score_row[algo] = score\n",
    "                \n",
    "                analysis_rows.append(score_row)\n",
    "            \n",
    "            # Create algorithm analysis DataFrame\n",
    "            if analysis_rows:\n",
    "                algo_df = pd.DataFrame(analysis_rows)\n",
    "                algo_df.to_excel(writer, sheet_name=\"Algorithm_Analysis\", index=False)\n",
    "            \n",
    "            # Auto-adjust column widths for all sheets\n",
    "            for sheet_name in writer.sheets:\n",
    "                worksheet = writer.sheets[sheet_name]\n",
    "                for i, col in enumerate(categorized_df.columns):\n",
    "                    # Find the maximum length in the column\n",
    "                    max_len = max(\n",
    "                        categorized_df[col].astype(str).map(len).max(),  # max data length\n",
    "                        len(str(col))  # column name length\n",
    "                    ) + 2  # adding a little extra space\n",
    "                    \n",
    "                    # Set the column width\n",
    "                    worksheet.set_column(i, i, max_len)\n",
    "                    \n",
    "        print(f\"Results successfully exported to {output_file}\")\n",
    "        print(f\"\\nSummary of exported data:\")\n",
    "        print(f\"   Total merchant entries: {len(categorized_df)}\")\n",
    "        \n",
    "        # Display category distribution\n",
    "        print(\"\\nMatch Category Distribution:\")\n",
    "        for _, row in category_counts.iterrows():\n",
    "            print(f\"   {row['Match_Category']}: {row['Count']} entries ({row['Percentage']}%)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting results: {e}\")\n",
    "        return categorized_df\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"\\nTotal processing time: {processing_time:.2f} seconds\")\n",
    "    \n",
    "    return categorized_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de6099b0-6797-425d-8d6d-8d6619cd4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Interactive Merchant Name Matching\n",
    "\n",
    "def interactive_merchant_matcher(merchant_matcher, examples=None, top_n=3):\n",
    "    \"\"\"\n",
    "    Interactive matcher for testing merchant name matching with detailed explanations\n",
    "    \n",
    "    Args:\n",
    "        merchant_matcher: Enhanced merchant matcher instance\n",
    "        examples (list, optional): List of example pairs to suggest\n",
    "        top_n (int): Number of algorithm scores to show\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if examples is None:\n",
    "        examples = [\n",
    "            ('BoA', 'Bank of America'),\n",
    "            ('MCD', 'McDonalds'),\n",
    "            ('WMT', 'Walmart Inc'),\n",
    "            ('AMZN', 'Amazon.com'),\n",
    "            ('StarBucks', 'Starbucks Coffee Company'),\n",
    "            ('Western Toyota', 'Toyota Corporation')\n",
    "        ]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"Interactive Merchant Name Matcher\".center(80))\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nThis tool helps you test the enhanced merchant matching algorithm.\")\n",
    "    print(\"Enter two merchant names to compare, or type 'quit' to exit.\")\n",
    "    print(\"\\nExample pairs you can try:\")\n",
    "    for i, (DBAName, RawTransactionName) in enumerate(examples):\n",
    "        print(f\"  {i+1}. '{DBAName}' <-> '{RawTransactionName}'\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"Enter merchant names to compare (or 'quit' to exit):\")\n",
    "        \n",
    "        # Get DBAName input\n",
    "        DBAName = input(\"DBAName or Short Name: \").strip()\n",
    "        if DBAName.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        # Get full name input\n",
    "        RawTransactionName = input(\"Full Name: \").strip()\n",
    "        if RawTransactionName.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        # Get DBA merchant category input\n",
    "        DBA_Merchant_Category = input(\"DBA Merchant Category (e.g., Banking, Restaurant): \").strip()\n",
    "        if not DBA_Merchant_Category:\n",
    "            DBA_Merchant_Category = None\n",
    "        \n",
    "        # Get RawTransaction merchant category input\n",
    "        RawTransaction_Merchant_Category = input(\"RawTransaction Merchant Category (optional): \").strip()\n",
    "        if not RawTransaction_Merchant_Category:\n",
    "            RawTransaction_Merchant_Category = DBA_Merchant_Category\n",
    "        \n",
    "        # Compute similarity scores using both merchant categories\n",
    "        print(\"\\nComputing similarity scores...\")\n",
    "        all_scores = merchant_matcher.get_all_similarity_scores(\n",
    "            DBAName, DBA_Merchant_Category, \n",
    "            RawTransactionName, RawTransaction_Merchant_Category\n",
    "        )\n",
    "        weighted_score = merchant_matcher.compute_weighted_score(\n",
    "            DBAName, DBA_Merchant_Category, \n",
    "            RawTransactionName, RawTransaction_Merchant_Category\n",
    "        )\n",
    "        enhanced_score = merchant_matcher.compute_enhanced_score(\n",
    "            DBAName, DBA_Merchant_Category, \n",
    "            RawTransactionName, RawTransaction_Merchant_Category\n",
    "        )\n",
    "        \n",
    "        # Determine match category\n",
    "        match_category = \"No Match\"\n",
    "        for category, threshold in sorted(thresholds.items(), key=lambda x: x[1], reverse=True):\n",
    "            if enhanced_score >= threshold:\n",
    "                match_category = category\n",
    "                break\n",
    "        \n",
    "        # Show preprocessing results\n",
    "        DBAName_clean, RawTransactionName_clean = merchant_matcher.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        \n",
    "        print(\"\\nResults:\")\n",
    "        print(f\"  Preprocessed DBAName: '{DBAName_clean}'\")\n",
    "        print(f\"  Preprocessed Full Name: '{RawTransactionName_clean}'\")\n",
    "        print(f\"  Weighted Score: {weighted_score:.4f}\")\n",
    "        print(f\"  Enhanced Score: {enhanced_score:.4f}\")\n",
    "        print(f\"  Match Category: {match_category}\")\n",
    "        \n",
    "        # Show detected business patterns\n",
    "        patterns = merchant_matcher.detect_complex_business_patterns(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        if patterns:\n",
    "            print(\"\\nDetected Business Patterns:\")\n",
    "            for pattern, score in patterns.items():\n",
    "                print(f\"   {pattern.replace('_', ' ').title()}: {score:.4f}\")\n",
    "        \n",
    "        # Show top individual algorithm scores\n",
    "        print(\"\\nTop Individual Algorithm Scores:\")\n",
    "        top_scores = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        for algo, score in top_scores:\n",
    "            print(f\"   {algo.replace('_', ' ').title()}: {score:.4f}\")\n",
    "        \n",
    "        # Show weights used\n",
    "        weights = merchant_matcher.get_dynamic_weights(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "        print(\"\\nTop Algorithm Weights:\")\n",
    "        top_weights = sorted(weights.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        for algo, weight in top_weights:\n",
    "            print(f\"   {algo.replace('_', ' ').title()}: {weight:.4f}\")\n",
    "        \n",
    "        # Provide explanation for the score\n",
    "        print(\"\\nExplanation:\")\n",
    "        if enhanced_score >= 0.95:\n",
    "            print(\"  This is an EXACT MATCH with very high confidence.\")\n",
    "        elif enhanced_score >= 0.85:\n",
    "            print(\"  This is a STRONG MATCH. The names are highly similar.\")\n",
    "        elif enhanced_score >= 0.75:\n",
    "            print(\"  This is a PROBABLE MATCH. The names are quite similar.\")\n",
    "        elif enhanced_score >= 0.65:\n",
    "            print(\"  This is a POSSIBLE MATCH. The names have significant similarity.\")\n",
    "        elif enhanced_score >= 0.50:\n",
    "            print(\"  This is a WEAK MATCH. The names have some similarity but should be reviewed.\")\n",
    "        else:\n",
    "            print(\"  This is likely NOT A MATCH. The names are too dissimilar.\")\n",
    "        \n",
    "        # Explain key factors\n",
    "        if patterns:\n",
    "            pattern_names = [p.replace('_', ' ').title() for p in patterns.keys()]\n",
    "            print(f\"  Key factors: Detected {', '.join(pattern_names)}.\")\n",
    "        \n",
    "        if 'bert_similarity' in all_scores and all_scores['bert_similarity'] > 0.8:\n",
    "            print(f\"  High semantic understanding: The names have similar meanings.\")\n",
    "        \n",
    "        if 'enhanced_DBAName_formation' in all_scores and all_scores['enhanced_DBAName_formation'] > 0.8:\n",
    "            print(f\"  Strong DBAName formation: The short form is a good DBAName of the full name.\")\n",
    "        \n",
    "        # Ask if the user wants to try another pair\n",
    "        continue_choice = input(\"\\nTry another pair? (y/n): \").strip().lower()\n",
    "        if continue_choice != 'y':\n",
    "            break\n",
    "    \n",
    "    print(\"\\nThank you for using the Interactive Merchant Name Matcher!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bec527e-d3dc-43c1-9a78-71e0e80d0026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Batch Processing Functions\n",
    "\n",
    "def adapt_for_pyspark(spark=None):\n",
    "    \"\"\"\n",
    "    Create PySpark UDFs and pipeline components for large-scale processing\n",
    "    \n",
    "    Args:\n",
    "        spark: SparkSession instance (optional)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing PySpark UDFs and pipeline components\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from pyspark.sql import SparkSession\n",
    "        from pyspark.sql.functions import udf, col\n",
    "        from pyspark.sql.types import DoubleType, StringType, StructType, StructField, ArrayType\n",
    "        pyspark_available = True\n",
    "    except ImportError:\n",
    "        pyspark_available = False\n",
    "        print(\"Warning: PySpark not available. Returning dummy implementation.\")\n",
    "        return {\"error\": \"PySpark not available\"}\n",
    "    \n",
    "    # Create SparkSession if not provided\n",
    "    if spark is None and pyspark_available:\n",
    "        try:\n",
    "            spark = SparkSession.builder \\\n",
    "                .appName(\"MerchantMatcherPipeline\") \\\n",
    "                .getOrCreate()\n",
    "            print(f\"Created Spark session: {spark.version}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create Spark session: {e}\")\n",
    "            pyspark_available = False\n",
    "    \n",
    "    if not pyspark_available:\n",
    "        return {\"error\": \"PySpark not available or failed to initialize\"}\n",
    "    \n",
    "    # Create UDFs for preprocessing and scoring\n",
    "    preprocessing_udf = udf(\n",
    "        lambda DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category: \n",
    "        merchant_matcher.preprocess_pair(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category),\n",
    "        StructType([\n",
    "            StructField(\"DBAName_clean\", StringType(), True),\n",
    "            StructField(\"RawTransactionName_clean\", StringType(), True)\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    weighted_score_udf = udf(\n",
    "        lambda DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category: \n",
    "        float(merchant_matcher.compute_weighted_score(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)), \n",
    "        DoubleType()\n",
    "    )\n",
    "    \n",
    "    enhanced_score_udf = udf(\n",
    "        lambda DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category: \n",
    "        float(merchant_matcher.compute_enhanced_score(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)), \n",
    "        DoubleType()\n",
    "    )\n",
    "    \n",
    "    match_category_udf = udf(\n",
    "        lambda score: next((cat for cat, thresh in sorted(thresholds.items(), key=lambda x: x[1], reverse=True) \n",
    "                         if score >= thresh), \"No Match\"),\n",
    "        StringType()\n",
    "    )\n",
    "    \n",
    "    # Define a pipeline function\n",
    "    def process_merchant_spark_df(df, DBAName_col=\"DBAName\", RawTransactionName_col=\"RawTransactionName\", \n",
    "                             DBA_Category_col=\"DBA_Merchant_Category\", RawTransaction_Category_col=\"Merchant_Category\"):\n",
    "        \"\"\"\n",
    "        Process merchant data using PySpark\n",
    "        \n",
    "        Args:\n",
    "            df: Spark DataFrame with merchant data\n",
    "            DBAName_col: Column name for DBAName/short name\n",
    "            RawTransactionName_col: Column name for full name\n",
    "            DBA_Category_col: Column name for DBA merchant category\n",
    "            RawTransaction_Category_col: Column name for raw transaction merchant category\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Spark DataFrame with results\n",
    "        \"\"\"\n",
    "        # Handle null values\n",
    "        df = df.na.fill(\"\", [DBAName_col, RawTransactionName_col])\n",
    "        df = df.na.fill(\"Unknown\", [DBA_Category_col, RawTransaction_Category_col])\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        df = df.withColumn(\n",
    "            \"preprocessed\", \n",
    "            preprocessing_udf(col(DBAName_col), col(DBA_Category_col), \n",
    "                              col(RawTransactionName_col), col(RawTransaction_Category_col))\n",
    "        )\n",
    "        \n",
    "        # Calculate scores using both category columns\n",
    "        df = df.withColumn(\n",
    "            \"Weighted_Score\", \n",
    "            weighted_score_udf(col(DBAName_col), col(DBA_Category_col), \n",
    "                              col(RawTransactionName_col), col(RawTransaction_Category_col))\n",
    "        )\n",
    "        \n",
    "        df = df.withColumn(\n",
    "            \"Enhanced_Score\", \n",
    "            enhanced_score_udf(col(DBAName_col), col(DBA_Category_col), \n",
    "                              col(RawTransactionName_col), col(RawTransaction_Category_col))\n",
    "        )\n",
    "        \n",
    "        # Add match category\n",
    "        df = df.withColumn(\n",
    "            \"Match_Category\",\n",
    "            match_category_udf(col(\"Enhanced_Score\"))\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Create a function to batch process a large DataFrame\n",
    "    def batch_process_merchant_data(df, batch_size=10000):\n",
    "        \"\"\"\n",
    "        Process a large merchant dataset in batches to avoid memory issues\n",
    "        \n",
    "        Args:\n",
    "            df: Spark DataFrame with merchant data\n",
    "            batch_size: Size of batches to process\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Spark DataFrame with results\n",
    "        \"\"\"\n",
    "        # Count total records\n",
    "        total_records = df.count()\n",
    "        print(f\"Processing {total_records} records in batches of {batch_size}\")\n",
    "        \n",
    "        # Process in batches\n",
    "        results = []\n",
    "        for i in range(0, total_records, batch_size):\n",
    "            # Take a batch\n",
    "            batch_df = df.limit(batch_size).offset(i)\n",
    "            \n",
    "            # Process batch\n",
    "            processed_batch = process_merchant_spark_df(batch_df)\n",
    "            \n",
    "            # Collect results (careful with large datasets)\n",
    "            batch_results = processed_batch.collect()\n",
    "            results.extend(batch_results)\n",
    "            \n",
    "            # Log progress\n",
    "            processed_so_far = min(i + batch_size, total_records)\n",
    "            print(f\"Processed {processed_so_far}/{total_records} records ({processed_so_far/total_records*100:.1f}%)\")\n",
    "        \n",
    "        # Convert results back to Spark DataFrame\n",
    "        results_df = spark.createDataFrame(results)\n",
    "        return results_df\n",
    "    \n",
    "    return {\n",
    "        \"spark_session\": spark,\n",
    "        \"preprocessing_udf\": preprocessing_udf,\n",
    "        \"weighted_score_udf\": weighted_score_udf,\n",
    "        \"enhanced_score_udf\": enhanced_score_udf,\n",
    "        \"match_category_udf\": match_category_udf,\n",
    "        \"process_merchant_spark_df\": process_merchant_spark_df,\n",
    "        \"batch_process_merchant_data\": batch_process_merchant_data\n",
    "    }\n",
    "\n",
    "def batch_process_file(input_file, output_file, batch_size=10000, use_spark=False):\n",
    "    \"\"\"\n",
    "    Process a large merchant dataset file in batches\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to input file (Excel or CSV)\n",
    "        output_file: Path to output file\n",
    "        batch_size: Size of batches to process\n",
    "        use_spark: Whether to use PySpark for processing\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processing statistics\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Batch processing merchant data from {input_file}\")\n",
    "    \n",
    "    # Determine file type\n",
    "    is_excel = input_file.lower().endswith(('.xlsx', '.xls'))\n",
    "    is_csv = input_file.lower().endswith('.csv')\n",
    "    \n",
    "    if not (is_excel or is_csv):\n",
    "        raise ValueError(\"Input file must be Excel (.xlsx/.xls) or CSV (.csv)\")\n",
    "    \n",
    "    # Process with PySpark if requested\n",
    "    if use_spark:\n",
    "        try:\n",
    "            from pyspark.sql import SparkSession\n",
    "            \n",
    "            # Initialize Spark session\n",
    "            spark = SparkSession.builder \\\n",
    "                .appName(\"MerchantMatcherBatchProcessing\") \\\n",
    "                .getOrCreate()\n",
    "            \n",
    "            # Read input file\n",
    "            if is_excel:\n",
    "                df = spark.read.format(\"com.crealytics.spark.excel\") \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .load(input_file)\n",
    "            else:  # CSV\n",
    "                df = spark.read.option(\"header\", \"true\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .csv(input_file)\n",
    "            \n",
    "            # Get PySpark components\n",
    "            spark_components = adapt_for_pyspark(spark)\n",
    "            \n",
    "            # Process data\n",
    "            results_df = spark_components[\"batch_process_merchant_data\"](df, batch_size)\n",
    "            \n",
    "            # Save results\n",
    "            if output_file.lower().endswith('.csv'):\n",
    "                results_df.write.option(\"header\", \"true\").csv(output_file)\n",
    "            else:\n",
    "                # Convert to pandas for Excel output\n",
    "                pd_df = results_df.toPandas()\n",
    "                pd_df.to_excel(output_file, index=False)\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            return {\n",
    "                \"input_file\": input_file,\n",
    "                \"output_file\": output_file,\n",
    "                \"records_processed\": results_df.count(),\n",
    "                \"processing_time\": processing_time,\n",
    "                \"records_per_second\": results_df.count() / processing_time\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing with PySpark: {e}\")\n",
    "            print(\"Falling back to pandas processing...\")\n",
    "            use_spark = False\n",
    "    \n",
    "    # Process with pandas\n",
    "    if not use_spark:\n",
    "        # Read input file\n",
    "        if is_excel:\n",
    "            # Read in chunks if Excel file is large\n",
    "            try:\n",
    "                df = pd.read_excel(input_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading entire Excel file: {e}\")\n",
    "                print(\"Trying to read with limited rows...\")\n",
    "                df = pd.read_excel(input_file, nrows=1000000)  # Limit to 1M rows\n",
    "        else:  # CSV\n",
    "            # Use chunking for CSV\n",
    "            chunks = []\n",
    "            chunk_size = min(batch_size, 100000)  # Default chunk size\n",
    "            \n",
    "            for chunk in pd.read_csv(input_file, chunksize=chunk_size):\n",
    "                chunks.append(chunk)\n",
    "                print(f\"Read chunk with {len(chunk)} rows\")\n",
    "            \n",
    "            df = pd.concat(chunks)\n",
    "        \n",
    "        # Preprocess data\n",
    "        processed_df = preprocess_merchant_data(df)\n",
    "        \n",
    "        # Process in batches\n",
    "        total_rows = len(processed_df)\n",
    "        results = []\n",
    "        \n",
    "        for start_idx in range(0, total_rows, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, total_rows)\n",
    "            batch = processed_df.iloc[start_idx:end_idx]\n",
    "            \n",
    "            print(f\"Processing batch {start_idx//batch_size + 1}/{(total_rows-1)//batch_size + 1} \"\n",
    "                  f\"({start_idx}-{end_idx})\")\n",
    "            \n",
    "            # Process batch\n",
    "            batch_results = process_merchant_data(batch, merchant_matcher)\n",
    "            results.append(batch_results)\n",
    "            \n",
    "            # Log progress\n",
    "            processed_so_far = end_idx\n",
    "            print(f\"Processed {processed_so_far}/{total_rows} records ({processed_so_far/total_rows*100:.1f}%)\")\n",
    "        \n",
    "        # Combine results\n",
    "        results_df = pd.concat(results)\n",
    "        \n",
    "        # Add match categories\n",
    "        results_df = add_match_categories(results_df, thresholds)\n",
    "        \n",
    "        # Save results\n",
    "        if output_file.lower().endswith('.csv'):\n",
    "            results_df.to_csv(output_file, index=False)\n",
    "        else:\n",
    "            results_df.to_excel(output_file, index=False)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        return {\n",
    "            \"input_file\": input_file,\n",
    "            \"output_file\": output_file,\n",
    "            \"records_processed\": len(results_df),\n",
    "            \"processing_time\": processing_time,\n",
    "            \"records_per_second\": len(results_df) / processing_time\n",
    "        }\n",
    "\n",
    "print(\"Batch processing functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ef6c46b-20ed-4938-8d1c-4e9605a71a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation and testing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Evaluation and Testing Functions\n",
    "\n",
    "def evaluate_merchant_matcher(test_data_path=None, gold_standard_column='Expected_Match'):\n",
    "    \"\"\"\n",
    "    Evaluate the merchant matcher against a gold standard dataset\n",
    "    \n",
    "    Args:\n",
    "        test_data_path: Path to test data file (with gold standard annotations)\n",
    "        gold_standard_column: Column name for the gold standard match status\n",
    "        \n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    print(\"Evaluating merchant matcher performance...\")\n",
    "    \n",
    "    # If no test data provided, use built-in test cases\n",
    "    if test_data_path is None:\n",
    "        print(\"No test data provided, creating synthetic test data...\")\n",
    "        \n",
    "        # Create synthetic test data with known expected outcomes\n",
    "        test_data = {\n",
    "            'DBAName': [\n",
    "                # True matches - should get high scores\n",
    "                'BoA', 'JPMC', 'WF', 'MCD', 'SBUX', 'TGT', 'MSFT', 'AMZN',\n",
    "                'WMT', 'HD', 'TM', 'GM', 'GS', 'MS', 'BBY',\n",
    "                \n",
    "                # Partial matches - could go either way\n",
    "                'BofA', 'McDon', 'Micky Ds', 'Wmart', 'Tgt Stores',\n",
    "                'Msft Corp', 'Amaz', 'JPM Co', 'Home Dep',\n",
    "                \n",
    "                # False matches - should get low scores\n",
    "                'BOA', 'JPM', 'WF Bank', 'MCD Restaurant', 'SB Coffee',\n",
    "                'MSFT Solutions', 'GMC Trucks', 'TGT Brands'\n",
    "            ],\n",
    "            'RawTransactionName': [\n",
    "                # Matches for true matches\n",
    "                'Bank of America', 'JPMorgan Chase', 'Wells Fargo', 'McDonalds',\n",
    "                'Starbucks', 'Target', 'Microsoft', 'Amazon',\n",
    "                'Walmart', 'Home Depot', 'Toyota Motors', 'General Motors',\n",
    "                'Goldman Sachs', 'Morgan Stanley', 'Best Buy',\n",
    "                \n",
    "                # Matches for partial matches\n",
    "                'Bank of America Corp', 'McDonalds Corporation', 'McDonalds Restaurants',\n",
    "                'Walmart Stores', 'Target Corporation', 'Microsoft Inc',\n",
    "                'Amazon.com Inc', 'JP Morgan', 'The Home Depot',\n",
    "                \n",
    "                # Non-matches\n",
    "                'Bank of Australia', 'Johnson & Johnson', 'Western Family',\n",
    "                'Michaels Craft Store', 'Seattle Bread Company',\n",
    "                'Micro Soft Tech', 'General Mills', 'Tarjay Brands'\n",
    "            ],\n",
    "            'Merchant_Category': [\n",
    "                # Categories for true matches\n",
    "                'Banking', 'Banking', 'Banking', 'Restaurant', 'Restaurant',\n",
    "                'Retail', 'Technology', 'Technology', 'Retail', 'Retail',\n",
    "                'Automotive', 'Automotive', 'Banking', 'Banking', 'Retail',\n",
    "                \n",
    "                # Categories for partial matches\n",
    "                'Banking', 'Restaurant', 'Restaurant', 'Retail', 'Retail',\n",
    "                'Technology', 'Technology', 'Banking', 'Retail',\n",
    "                \n",
    "                # Categories for false matches\n",
    "                'Banking', 'Healthcare', 'Retail', 'Restaurant', 'Restaurant',\n",
    "                'Technology', 'Food', 'Retail'\n",
    "            ],\n",
    "            'Expected_Match': [\n",
    "                # Expected outcomes for true matches\n",
    "                True, True, True, True, True, True, True, True, \n",
    "                True, True, True, True, True, True, True,\n",
    "                \n",
    "                # Expected outcomes for partial matches\n",
    "                True, True, True, True, True, True, True, True, True,\n",
    "                \n",
    "                # Expected outcomes for false matches\n",
    "                False, False, False, False, False, False, False, False\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        test_df = pd.DataFrame(test_data)\n",
    "        print(f\"Created synthetic test dataset with {len(test_df)} entries\")\n",
    "    else:\n",
    "        # Load test data from file\n",
    "        try:\n",
    "            if test_data_path.lower().endswith('.csv'):\n",
    "                test_df = pd.read_csv(test_data_path)\n",
    "            else:\n",
    "                test_df = pd.read_excel(test_data_path)\n",
    "            \n",
    "            print(f\"Loaded test data from {test_data_path} with {len(test_df)} entries\")\n",
    "            \n",
    "            # Verify that gold standard column exists\n",
    "            if gold_standard_column not in test_df.columns:\n",
    "                raise ValueError(f\"Gold standard column '{gold_standard_column}' not found in test data\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading test data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Preprocess test data\n",
    "    processed_df = preprocess_merchant_data(test_df)\n",
    "    \n",
    "    # Compute scores\n",
    "    results_df = process_merchant_data(processed_df, merchant_matcher)\n",
    "    \n",
    "    # Add binary prediction based on threshold\n",
    "    match_threshold = 0.75  # This is the \"Probable Match\" threshold\n",
    "    results_df['Predicted_Match'] = results_df['Enhanced_Score'] >= match_threshold\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    try:\n",
    "        from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "        \n",
    "        # Convert expected values to boolean\n",
    "        results_df['Expected_Match'] = results_df[gold_standard_column].astype(bool)\n",
    "        \n",
    "        # Calculate metrics - simple approach with direct calculations\n",
    "        accuracy = accuracy_score(results_df['Expected_Match'], results_df['Predicted_Match'])\n",
    "        \n",
    "        # Calculate precision, recall, F1 directly\n",
    "        tp = sum((results_df['Predicted_Match'] == True) & (results_df['Expected_Match'] == True))\n",
    "        fp = sum((results_df['Predicted_Match'] == True) & (results_df['Expected_Match'] == False))\n",
    "        fn = sum((results_df['Predicted_Match'] == False) & (results_df['Expected_Match'] == True))\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(\"\\nEvaluation Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        # Analyze errors\n",
    "        print(\"\\nAnalyzing errors...\")\n",
    "        \n",
    "        # False positives\n",
    "        fp_df = results_df[(results_df['Predicted_Match'] == True) & (results_df['Expected_Match'] == False)]\n",
    "        if len(fp_df) > 0:\n",
    "            print(f\"\\nFalse Positives ({len(fp_df)}):\")\n",
    "            for _, row in fp_df.iterrows():\n",
    "                print(f\"  {row['DBAName']} <-> {row['RawTransactionName']} (Score: {row['Enhanced_Score']:.4f})\")\n",
    "        \n",
    "        # False negatives\n",
    "        fn_df = results_df[(results_df['Predicted_Match'] == False) & (results_df['Expected_Match'] == True)]\n",
    "        if len(fn_df) > 0:\n",
    "            print(f\"\\nFalse Negatives ({len(fn_df)}):\")\n",
    "            for _, row in fn_df.iterrows():\n",
    "                print(f\"  {row['DBAName']} <-> {row['RawTransactionName']} (Score: {row['Enhanced_Score']:.4f})\")\n",
    "        \n",
    "        # Return metrics\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'results_df': results_df\n",
    "        }\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"Warning: scikit-learn not available. Computing basic metrics...\")\n",
    "        \n",
    "        # Convert expected values to boolean\n",
    "        results_df['Expected_Match'] = results_df[gold_standard_column].astype(bool)\n",
    "        \n",
    "        # Calculate basic metrics\n",
    "        tp = sum((results_df['Predicted_Match'] == True) & (results_df['Expected_Match'] == True))\n",
    "        tn = sum((results_df['Predicted_Match'] == False) & (results_df['Expected_Match'] == False))\n",
    "        fp = sum((results_df['Predicted_Match'] == True) & (results_df['Expected_Match'] == False))\n",
    "        fn = sum((results_df['Predicted_Match'] == False) & (results_df['Expected_Match'] == True))\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(\"\\nBasic Evaluation Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'results_df': results_df\n",
    "        }\n",
    "\n",
    "def find_optimal_threshold(test_data_path=None, gold_standard_column='Expected_Match'):\n",
    "    \"\"\"\n",
    "    Find the optimal threshold for classifying merchant matches\n",
    "    \n",
    "    Args:\n",
    "        test_data_path: Path to test data file\n",
    "        gold_standard_column: Column name for the gold standard match status\n",
    "        \n",
    "    Returns:\n",
    "        float: Optimal threshold value\n",
    "    \"\"\"\n",
    "    print(\"Finding optimal threshold for merchant matching...\")\n",
    "    \n",
    "    # Get test data\n",
    "    if test_data_path is None:\n",
    "        # Call evaluate_merchant_matcher which will create synthetic data\n",
    "        eval_results = evaluate_merchant_matcher(None, gold_standard_column)\n",
    "        results_df = eval_results['results_df']\n",
    "    else:\n",
    "        # Load test data from file\n",
    "        try:\n",
    "            if test_data_path.lower().endswith('.csv'):\n",
    "                test_df = pd.read_csv(test_data_path)\n",
    "            else:\n",
    "                test_df = pd.read_excel(test_data_path)\n",
    "            \n",
    "            print(f\"Loaded test data from {test_data_path} with {len(test_df)} entries\")\n",
    "            \n",
    "            # Verify that gold standard column exists\n",
    "            if gold_standard_column not in test_df.columns:\n",
    "                raise ValueError(f\"Gold standard column '{gold_standard_column}' not found in test data\")\n",
    "                \n",
    "            # Preprocess test data\n",
    "            processed_df = preprocess_merchant_data(test_df)\n",
    "            \n",
    "            # Compute scores\n",
    "            results_df = process_merchant_data(processed_df, merchant_matcher)\n",
    "            \n",
    "            # Convert expected values to boolean\n",
    "            results_df['Expected_Match'] = results_df[gold_standard_column].astype(bool)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or processing test data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Test different threshold values\n",
    "    try:\n",
    "        from sklearn.metrics import precision_recall_curve, f1_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        thresholds = np.linspace(0.1, 1.0, 37)  # Test thresholds from 0.1 to 1.0\n",
    "        f1_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        \n",
    "        # Calculate F1 score for each threshold\n",
    "        for threshold in thresholds:\n",
    "            predictions = results_df['Enhanced_Score'] >= threshold\n",
    "            precision = sum(predictions & results_df['Expected_Match']) / sum(predictions) if sum(predictions) > 0 else 0\n",
    "            recall = sum(predictions & results_df['Expected_Match']) / sum(results_df['Expected_Match']) if sum(results_df['Expected_Match']) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "        # Find optimal threshold (maximizing F1 score)\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        optimal_f1 = f1_scores[optimal_idx]\n",
    "        \n",
    "        print(f\"\\nOptimal threshold: {optimal_threshold:.4f} (F1 score: {optimal_f1:.4f})\")\n",
    "        print(f\"At this threshold:\")\n",
    "        print(f\"  Precision: {precision_scores[optimal_idx]:.4f}\")\n",
    "        print(f\"  Recall: {recall_scores[optimal_idx]:.4f}\")\n",
    "        \n",
    "        # Plot the results\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(thresholds, precision_scores, label='Precision')\n",
    "            plt.plot(thresholds, recall_scores, label='Recall')\n",
    "            plt.plot(thresholds, f1_scores, label='F1 Score')\n",
    "            plt.axvline(x=optimal_threshold, color='k', linestyle='--', label=f'Optimal Threshold = {optimal_threshold:.2f}')\n",
    "            plt.xlabel('Threshold')\n",
    "            plt.ylabel('Score')\n",
    "            plt.title('Precision, Recall, and F1 Score vs. Threshold')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error creating plot: {e}\")\n",
    "        \n",
    "        # Also try precision-recall curve\n",
    "        try:\n",
    "            # Get precision-recall curve\n",
    "            precision, recall, pr_thresholds = precision_recall_curve(\n",
    "                results_df['Expected_Match'], \n",
    "                results_df['Enhanced_Score']\n",
    "            )\n",
    "            \n",
    "            # Plot precision-recall curve\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(recall, precision, marker='.', label='Precision-Recall curve')\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.title('Precision-Recall Curve')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error creating precision-recall plot: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'optimal_threshold': optimal_threshold,\n",
    "            'optimal_f1': optimal_f1,\n",
    "            'thresholds': thresholds,\n",
    "            'precision_scores': precision_scores,\n",
    "            'recall_scores': recall_scores,\n",
    "            'f1_scores': f1_scores\n",
    "        }\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"Warning: scikit-learn or matplotlib not available. Computing basic optimization...\")\n",
    "        \n",
    "        # Test different threshold values without plotting\n",
    "        thresholds = np.linspace(0.1, 1.0, 19)  # Test thresholds from 0.1 to 1.0\n",
    "        f1_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        \n",
    "        # Calculate F1 score for each threshold\n",
    "        for threshold in thresholds:\n",
    "            predictions = results_df['Enhanced_Score'] >= threshold\n",
    "            precision = sum(predictions & results_df['Expected_Match']) / sum(predictions) if sum(predictions) > 0 else 0\n",
    "            recall = sum(predictions & results_df['Expected_Match']) / sum(results_df['Expected_Match']) if sum(results_df['Expected_Match']) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "        # Find optimal threshold (maximizing F1 score)\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        optimal_f1 = f1_scores[optimal_idx]\n",
    "        \n",
    "        print(f\"\\nOptimal threshold: {optimal_threshold:.4f} (F1 score: {optimal_f1:.4f})\")\n",
    "        print(f\"At this threshold:\")\n",
    "        print(f\"  Precision: {precision_scores[optimal_idx]:.4f}\")\n",
    "        print(f\"  Recall: {recall_scores[optimal_idx]:.4f}\")\n",
    "        \n",
    "        # Print table of results\n",
    "        print(\"\\nThreshold\\tPrecision\\tRecall\\t\\tF1 Score\")\n",
    "        print(\"-\" * 60)\n",
    "        for i, t in enumerate(thresholds):\n",
    "            print(f\"{t:.2f}\\t\\t{precision_scores[i]:.4f}\\t\\t{recall_scores[i]:.4f}\\t\\t{f1_scores[i]:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'optimal_threshold': optimal_threshold,\n",
    "            'optimal_f1': optimal_f1,\n",
    "            'thresholds': thresholds,\n",
    "            'precision_scores': precision_scores,\n",
    "            'recall_scores': recall_scores,\n",
    "            'f1_scores': f1_scores\n",
    "        }\n",
    "\n",
    "def compare_algorithms(test_data_path=None, gold_standard_column='Expected_Match'):\n",
    "    \"\"\"\n",
    "    Compare different matching algorithms on the same test data\n",
    "    \n",
    "    Args:\n",
    "        test_data_path: Path to test data file\n",
    "        gold_standard_column: Column name for the gold standard match status\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Comparison results\n",
    "    \"\"\"\n",
    "    print(\"Comparing matching algorithms...\")\n",
    "    \n",
    "    # Get test data\n",
    "    if test_data_path is None:\n",
    "        # Create synthetic test data\n",
    "        eval_results = evaluate_merchant_matcher(None, gold_standard_column)\n",
    "        test_df = eval_results['results_df'][['DBAName', 'RawTransactionName', 'Merchant_Category', 'Expected_Match']]\n",
    "    else:\n",
    "        # Load test data from file\n",
    "        try:\n",
    "            if test_data_path.lower().endswith('.csv'):\n",
    "                test_df = pd.read_csv(test_data_path)\n",
    "            else:\n",
    "                test_df = pd.read_excel(test_data_path)\n",
    "                \n",
    "            # Verify that gold standard column exists\n",
    "            if gold_standard_column not in test_df.columns:\n",
    "                raise ValueError(f\"Gold standard column '{gold_standard_column}' not found in test data\")\n",
    "                \n",
    "            # Convert expected values to boolean\n",
    "            test_df['Expected_Match'] = test_df[gold_standard_column].astype(bool)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading test data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Preprocess test data\n",
    "    processed_df = preprocess_merchant_data(test_df)\n",
    "    \n",
    "    # Define algorithms to compare\n",
    "    algorithms = {\n",
    "        'Jaro-Winkler': lambda a, a_cat, f, f_cat: merchant_matcher.jaro_winkler_similarity(a, a_cat, f, f_cat),\n",
    "        'Damerau-Levenshtein': lambda a, a_cat, f, f_cat: merchant_matcher.damerau_levenshtein_similarity(a, a_cat, f, f_cat),\n",
    "        'TF-IDF Cosine': lambda a, a_cat, f, f_cat: merchant_matcher.tfidf_cosine_similarity(a, a_cat, f, f_cat),\n",
    "        'Jaccard Bigram': lambda a, a_cat, f, f_cat: merchant_matcher.jaccard_bigram_similarity(a, a_cat, f, f_cat),\n",
    "        'Soundex': lambda a, a_cat, f, f_cat: merchant_matcher.soundex_similarity(a, a_cat, f, f_cat),\n",
    "        'Token Sort Ratio': lambda a, a_cat, f, f_cat: merchant_matcher.token_sort_ratio_similarity(a, a_cat, f, f_cat),\n",
    "        'DBAName Formation': lambda a, a_cat, f, f_cat: merchant_matcher.enhanced_DBAName_formation_score(a, a_cat, f, f_cat),\n",
    "        'BERT Similarity': lambda a, a_cat, f, f_cat: merchant_matcher.bert_similarity(a, a_cat, f, f_cat) if hasattr(merchant_matcher, 'bert_similarity') else 0,\n",
    "        'Weighted Score': lambda a, a_cat, f, f_cat: merchant_matcher.compute_weighted_score(a, a_cat, f, f_cat),\n",
    "        'Enhanced Score': lambda a, a_cat, f, f_cat: merchant_matcher.compute_enhanced_score(a, a_cat, f, f_cat)\n",
    "    }\n",
    "    \n",
    "    # Evaluate each algorithm\n",
    "    algorithm_results = {}\n",
    "    algorithm_metrics = {}\n",
    "    \n",
    "    for name, algorithm in algorithms.items():\n",
    "        print(f\"Evaluating {name}...\")\n",
    "        scores = []\n",
    "        \n",
    "        # Calculate scores for each pair\n",
    "        for _, row in processed_df.iterrows():\n",
    "            DBAName = row['DBAName']\n",
    "            RawTransactionName = row['RawTransactionName']\n",
    "            \n",
    "            # Extract merchant categories, using Merchant_Category as fallback if specific ones don't exist\n",
    "            DBA_Merchant_Category = row.get('DBA_Merchant_Category', row.get('Merchant_Category', None))\n",
    "            RawTransaction_Merchant_Category = row.get('RawTransaction_Merchant_Category', row.get('Merchant_Category', None))\n",
    "            \n",
    "            score = algorithm(DBAName, DBA_Merchant_Category, RawTransactionName, RawTransaction_Merchant_Category)\n",
    "            scores.append(score)\n",
    "        \n",
    "        # Add scores to results\n",
    "        processed_df[f'{name}_Score'] = scores\n",
    "        \n",
    "        # Find optimal threshold for this algorithm\n",
    "        thresholds = np.linspace(0.1, 1.0, 19)\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            predictions = np.array(scores) >= threshold\n",
    "            true_labels = processed_df['Expected_Match'].values\n",
    "            \n",
    "            # Calculate metrics\n",
    "            tp = sum(predictions & true_labels)\n",
    "            fp = sum(predictions & ~true_labels)\n",
    "            fn = sum(~predictions & true_labels)\n",
    "            \n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        # Calculate final metrics at optimal threshold\n",
    "        predictions = np.array(scores) >= best_threshold\n",
    "        true_labels = processed_df['Expected_Match'].values\n",
    "        \n",
    "        tp = sum(predictions & true_labels)\n",
    "        fp = sum(predictions & ~true_labels)\n",
    "        fn = sum(~predictions & true_labels)\n",
    "        tn = sum(~predictions & ~true_labels)\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = (tp + tn) / len(true_labels) if len(true_labels) > 0 else 0\n",
    "        \n",
    "        # Store metrics\n",
    "        algorithm_metrics[name] = {\n",
    "            'threshold': best_threshold,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'false_negatives': fn,\n",
    "            'true_negatives': tn\n",
    "        }\n",
    "        \n",
    "        # Store predictions\n",
    "        algorithm_results[name] = predictions\n",
    "    \n",
    "    # Create comparison table\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Algorithm': list(algorithm_metrics.keys()),\n",
    "        'Threshold': [m['threshold'] for m in algorithm_metrics.values()],\n",
    "        'Accuracy': [m['accuracy'] for m in algorithm_metrics.values()],\n",
    "        'Precision': [m['precision'] for m in algorithm_metrics.values()],\n",
    "        'Recall': [m['recall'] for m in algorithm_metrics.values()],\n",
    "        'F1 Score': [m['f1_score'] for m in algorithm_metrics.values()]\n",
    "    })\n",
    "    \n",
    "    # Sort by F1 score\n",
    "    metrics_df = metrics_df.sort_values('F1 Score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Print comparison table\n",
    "    print(\"\\nAlgorithm Comparison Results:\")\n",
    "    print(metrics_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Plot comparison if matplotlib is available\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # Bar chart for F1 scores\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        bars = plt.bar(metrics_df['Algorithm'], metrics_df['F1 Score'])\n",
    "        plt.xlabel('Algorithm')\n",
    "        plt.ylabel('F1 Score')\n",
    "        plt.title('Algorithm F1 Score Comparison')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{height:.4f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Precision-Recall comparison for top 5 algorithms\n",
    "        top_algorithms = metrics_df['Algorithm'].head(5).tolist()\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        for algorithm in top_algorithms:\n",
    "            precision = algorithm_metrics[algorithm]['precision']\n",
    "            recall = algorithm_metrics[algorithm]['recall']\n",
    "            plt.scatter(recall, precision, label=f\"{algorithm} (F1={algorithm_metrics[algorithm]['f1_score']:.4f})\", s=100)\n",
    "        \n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision vs Recall for Top Algorithms')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available for visualization.\")\n",
    "    \n",
    "    return {\n",
    "        'metrics_df': metrics_df,\n",
    "        'algorithm_metrics': algorithm_metrics,\n",
    "        'algorithm_results': algorithm_results,\n",
    "        'processed_df': processed_df\n",
    "    }\n",
    "\n",
    "print(\"Evaluation and testing functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eae95210-56e8-408f-9ad1-63a47bedac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Cross-Validation and Error Analysis Functions\n",
    "\n",
    "def cross_validate_merchant_matcher(test_data_path=None, gold_standard_column='Expected_Match', n_folds=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation to assess model stability\n",
    "    \n",
    "    Args:\n",
    "        test_data_path: Path to test data file\n",
    "        gold_standard_column: Column name for the gold standard match status\n",
    "        n_folds: Number of cross-validation folds\n",
    "        \n",
    "    Returns:\n",
    "        dict: Cross-validation results\n",
    "    \"\"\"\n",
    "    print(f\"Performing {n_folds}-fold cross-validation...\")\n",
    "    \n",
    "    # Get test data\n",
    "    if test_data_path is None:\n",
    "        # Create synthetic test data\n",
    "        eval_results = evaluate_merchant_matcher(None, gold_standard_column)\n",
    "        test_df = eval_results['results_df'][['DBAName', 'RawTransactionName', 'Merchant_Category', 'Expected_Match']]\n",
    "    else:\n",
    "        # Load test data from file\n",
    "        try:\n",
    "            if test_data_path.lower().endswith('.csv'):\n",
    "                test_df = pd.read_csv(test_data_path)\n",
    "            else:\n",
    "                test_df = pd.read_excel(test_data_path)\n",
    "                \n",
    "            # Verify that gold standard column exists\n",
    "            if gold_standard_column not in test_df.columns:\n",
    "                raise ValueError(f\"Gold standard column '{gold_standard_column}' not found in test data\")\n",
    "                \n",
    "            # Convert expected values to boolean\n",
    "            test_df['Expected_Match'] = test_df[gold_standard_column].astype(bool)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading test data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Preprocess test data\n",
    "    processed_df = preprocess_merchant_data(test_df)\n",
    "    \n",
    "    # Check for sufficient data\n",
    "    if len(processed_df) < n_folds * 2:\n",
    "        print(f\"Warning: Not enough data for {n_folds} folds. Need at least {n_folds * 2} samples.\")\n",
    "        n_folds = max(2, len(processed_df) // 2)\n",
    "        print(f\"Reducing to {n_folds} folds.\")\n",
    "    \n",
    "    # Create folds\n",
    "    try:\n",
    "        from sklearn.model_selection import KFold\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "        folds = list(kf.split(processed_df))\n",
    "    except ImportError:\n",
    "        print(\"Warning: scikit-learn not available. Using manual fold creation.\")\n",
    "        # Manual fold creation\n",
    "        indices = np.random.permutation(len(processed_df))\n",
    "        fold_size = len(processed_df) // n_folds\n",
    "        folds = []\n",
    "        for i in range(n_folds):\n",
    "            test_indices = indices[i*fold_size:(i+1)*fold_size]\n",
    "            train_indices = np.setdiff1d(indices, test_indices)\n",
    "            folds.append((train_indices, test_indices))\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    fold_results = []\n",
    "    all_best_thresholds = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(folds):\n",
    "        print(f\"\\nProcessing fold {fold+1}/{n_folds}...\")\n",
    "        \n",
    "        # Split data\n",
    "        train_df = processed_df.iloc[train_idx]\n",
    "        test_df = processed_df.iloc[test_idx]\n",
    "        \n",
    "        # Process data\n",
    "        results_df = process_merchant_data(test_df, merchant_matcher)\n",
    "        \n",
    "        # Find optimal threshold using training data\n",
    "        train_results = process_merchant_data(train_df, merchant_matcher)\n",
    "        thresholds = np.linspace(0.1, 1.0, 19)\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            predictions = train_results['Enhanced_Score'] >= threshold\n",
    "            true_labels = train_df['Expected_Match'].values\n",
    "            \n",
    "            # Calculate metrics\n",
    "            tp = sum(predictions & true_labels)\n",
    "            fp = sum(predictions & ~true_labels)\n",
    "            fn = sum(~predictions & true_labels)\n",
    "            \n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        all_best_thresholds.append(best_threshold)\n",
    "        print(f\"  Optimal threshold for fold {fold+1}: {best_threshold:.4f}\")\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        results_df['Predicted_Match'] = results_df['Enhanced_Score'] >= best_threshold\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tp = sum((results_df['Predicted_Match'] == True) & (test_df['Expected_Match'] == True))\n",
    "        tn = sum((results_df['Predicted_Match'] == False) & (test_df['Expected_Match'] == False))\n",
    "        fp = sum((results_df['Predicted_Match'] == True) & (test_df['Expected_Match'] == False))\n",
    "        fn = sum((results_df['Predicted_Match'] == False) & (test_df['Expected_Match'] == True))\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        # Store fold results\n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'threshold': best_threshold,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'false_negatives': fn,\n",
    "            'true_negatives': tn\n",
    "        })\n",
    "        \n",
    "        print(f\"  Fold {fold+1} Results:\")\n",
    "        print(f\"    Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"    Precision: {precision:.4f}\")\n",
    "        print(f\"    Recall: {recall:.4f}\")\n",
    "        print(f\"    F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {\n",
    "        'accuracy': np.mean([r['accuracy'] for r in fold_results]),\n",
    "        'precision': np.mean([r['precision'] for r in fold_results]),\n",
    "        'recall': np.mean([r['recall'] for r in fold_results]),\n",
    "        'f1_score': np.mean([r['f1_score'] for r in fold_results]),\n",
    "        'threshold': np.mean([r['threshold'] for r in fold_results])\n",
    "    }\n",
    "    \n",
    "    std_metrics = {\n",
    "        'accuracy': np.std([r['accuracy'] for r in fold_results]),\n",
    "        'precision': np.std([r['precision'] for r in fold_results]),\n",
    "        'recall': np.std([r['recall'] for r in fold_results]),\n",
    "        'f1_score': np.std([r['f1_score'] for r in fold_results]),\n",
    "        'threshold': np.std([r['threshold'] for r in fold_results])\n",
    "    }\n",
    "    \n",
    "    print(\"\\nCross-Validation Summary:\")\n",
    "    print(f\"  Average Accuracy: {avg_metrics['accuracy']:.4f} ({std_metrics['accuracy']:.4f})\")\n",
    "    print(f\"  Average Precision: {avg_metrics['precision']:.4f} ({std_metrics['precision']:.4f})\")\n",
    "    print(f\"  Average Recall: {avg_metrics['recall']:.4f} ({std_metrics['recall']:.4f})\")\n",
    "    print(f\"  Average F1 Score: {avg_metrics['f1_score']:.4f} ({std_metrics['f1_score']:.4f})\")\n",
    "    print(f\"  Average Threshold: {avg_metrics['threshold']:.4f} ({std_metrics['threshold']:.4f})\")\n",
    "    \n",
    "    # Check for potential overfitting\n",
    "    if std_metrics['f1_score'] > 0.15:\n",
    "        print(\"\\nWarning: High variance in F1 scores across folds.\")\n",
    "        print(\"This may indicate that the model's performance is unstable.\")\n",
    "        print(\"Consider using a larger dataset or a simpler model.\")\n",
    "    \n",
    "    # Check if thresholds vary significantly\n",
    "    if std_metrics['threshold'] > 0.1:\n",
    "        print(\"\\nWarning: High variance in optimal thresholds across folds.\")\n",
    "        print(\"This may indicate that the optimal threshold is dataset-dependent.\")\n",
    "        print(\"Consider using a fixed threshold based on business requirements.\")\n",
    "    \n",
    "    # Analyze which algorithms contributed most to successful matches\n",
    "    # Use the average best threshold from all folds\n",
    "    avg_best_threshold = np.mean(all_best_thresholds)\n",
    "    algorithm_importance = {}\n",
    "    \n",
    "    # Define algorithm method mapping to handle naming inconsistencies\n",
    "    algorithm_methods = {\n",
    "        'jaro_winkler': 'jaro_winkler_similarity',\n",
    "        'bert_similarity': 'bert_similarity',  # Note: No _similarity suffix here\n",
    "        'damerau_levenshtein': 'damerau_levenshtein_similarity',\n",
    "        'enhanced_DBAName_formation': 'enhanced_DBAName_formation_score'  # Note: Uses _score suffix\n",
    "    }\n",
    "    \n",
    "    for algo, method_name in algorithm_methods.items():\n",
    "        # For each algorithm, calculate its correlation with correct predictions\n",
    "        correct_predictions = []\n",
    "        algo_scores = []\n",
    "        \n",
    "        for _, row in processed_df.iterrows():\n",
    "            DBAName = row['DBAName']\n",
    "            RawTransactionName = row['RawTransactionName']\n",
    "            expected_match = row['Expected_Match']\n",
    "            \n",
    "            # Get score for this algorithm using the correct method name\n",
    "            try:\n",
    "                algo_score = merchant_matcher.__getattribute__(method_name)(\n",
    "                    DBAName, row.get('DBA_Merchant_Category'), \n",
    "                    RawTransactionName, row.get('RawTransaction_Merchant_Category')\n",
    "                )\n",
    "            except (AttributeError, TypeError):\n",
    "                # Skip if algorithm method isn't available\n",
    "                print(f\"Warning: Algorithm method {method_name} not available, skipping\")\n",
    "                algo_score = 0.5  # Default score\n",
    "            \n",
    "            # Determine if this would be a correct prediction based on optimal threshold\n",
    "            prediction = algo_score >= avg_best_threshold\n",
    "            is_correct = prediction == expected_match\n",
    "            \n",
    "            correct_predictions.append(is_correct)\n",
    "            algo_scores.append(algo_score)\n",
    "        \n",
    "        # Calculate correlation between algorithm score and correct predictions\n",
    "        correlation = sum([1 if cp and as_ > 0.5 else 0 for cp, as_ in zip(correct_predictions, algo_scores)]) / len(correct_predictions)\n",
    "        algorithm_importance[algo] = correlation\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'avg_metrics': avg_metrics,\n",
    "        'std_metrics': std_metrics,\n",
    "        'algorithm_importance': algorithm_importance\n",
    "    }\n",
    "\n",
    "def visualize_error_cases(results_df):\n",
    "    \"\"\"\n",
    "    Analyze and visualize error cases in the matching results.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with matching results that includes 'Enhanced_Score',\n",
    "                   'Expected_Match' (if available), and 'Predicted_Match' columns\n",
    "        \n",
    "    Returns:\n",
    "        dict: Error analysis results with patterns and visualizations\n",
    "    \"\"\"\n",
    "    print(\"Analyzing error cases in merchant matching...\")\n",
    "    \n",
    "    # Check if we have the necessary columns\n",
    "    if results_df is None:\n",
    "        print(\"No results data available for error analysis\")\n",
    "        return {}\n",
    "    \n",
    "    # Initialize analysis results\n",
    "    analysis_results = {\n",
    "        'error_patterns': {},\n",
    "        'category_analysis': {},\n",
    "        'length_analysis': {}\n",
    "    }\n",
    "    \n",
    "    # If we have ground truth data (Expected_Match)\n",
    "    if 'Expected_Match' in results_df.columns and 'Predicted_Match' in results_df.columns:\n",
    "        # Ensure boolean type\n",
    "        results_df['Expected_Match'] = results_df['Expected_Match'].astype(bool)\n",
    "        results_df['Predicted_Match'] = results_df['Predicted_Match'].astype(bool)\n",
    "        \n",
    "        # Identify errors\n",
    "        false_positives = results_df[(results_df['Predicted_Match'] == True) & \n",
    "                                     (results_df['Expected_Match'] == False)]\n",
    "        false_negatives = results_df[(results_df['Predicted_Match'] == False) & \n",
    "                                     (results_df['Expected_Match'] == True)]\n",
    "        \n",
    "        # Calculate error rates\n",
    "        total_cases = len(results_df)\n",
    "        fp_rate = len(false_positives) / total_cases if total_cases > 0 else 0\n",
    "        fn_rate = len(false_negatives) / total_cases if total_cases > 0 else 0\n",
    "        \n",
    "        print(f\"Found {len(false_positives)} false positives ({fp_rate:.2%}) and \"\n",
    "              f\"{len(false_negatives)} false negatives ({fn_rate:.2%})\")\n",
    "        \n",
    "        # Store error cases\n",
    "        analysis_results['false_positives'] = false_positives\n",
    "        analysis_results['false_negatives'] = false_negatives\n",
    "        \n",
    "        # Analyze patterns in errors\n",
    "        \n",
    "        # 1. Analyze by name length\n",
    "        if 'DBAName' in results_df.columns:\n",
    "            results_df['DBAName_Length'] = results_df['DBAName'].apply(lambda x: len(str(x)))\n",
    "            \n",
    "            # Group by name length\n",
    "            length_groups = [\n",
    "                (1, 2, 'Very Short (1-2 chars)'),\n",
    "                (3, 4, 'Short (3-4 chars)'),\n",
    "                (5, 8, 'Medium (5-8 chars)'),\n",
    "                (9, float('inf'), 'Long (9+ chars)')\n",
    "            ]\n",
    "            \n",
    "            for min_len, max_len, group_name in length_groups:\n",
    "                in_group = results_df[(results_df['DBAName_Length'] >= min_len) & \n",
    "                                    (results_df['DBAName_Length'] <= max_len)]\n",
    "                \n",
    "                if len(in_group) > 0:\n",
    "                    group_fp = in_group[(in_group['Predicted_Match'] == True) & \n",
    "                                        (in_group['Expected_Match'] == False)]\n",
    "                    group_fn = in_group[(in_group['Predicted_Match'] == False) & \n",
    "                                        (in_group['Expected_Match'] == True)]\n",
    "                    \n",
    "                    fp_rate = len(group_fp) / len(in_group)\n",
    "                    fn_rate = len(group_fn) / len(in_group)\n",
    "                    \n",
    "                    analysis_results['length_analysis'][group_name] = {\n",
    "                        'total': len(in_group),\n",
    "                        'false_positives': len(group_fp),\n",
    "                        'false_negatives': len(group_fn),\n",
    "                        'fp_rate': fp_rate,\n",
    "                        'fn_rate': fn_rate\n",
    "                    }\n",
    "            \n",
    "            print(\"\\nError rates by DBAName length:\")\n",
    "            for group, stats in analysis_results['length_analysis'].items():\n",
    "                print(f\"  {group}: FP Rate: {stats['fp_rate']:.2%}, FN Rate: {stats['fn_rate']:.2%}\")\n",
    "        \n",
    "        # 2. Analyze by merchant category\n",
    "        if 'DBA_Merchant_Category' in results_df.columns:\n",
    "            categories = results_df['DBA_Merchant_Category'].dropna().unique()\n",
    "            \n",
    "            for category in categories:\n",
    "                cat_results = results_df[results_df['DBA_Merchant_Category'] == category]\n",
    "                \n",
    "                if len(cat_results) > 0:\n",
    "                    cat_fp = cat_results[(cat_results['Predicted_Match'] == True) & \n",
    "                                        (cat_results['Expected_Match'] == False)]\n",
    "                    cat_fn = cat_results[(cat_results['Predicted_Match'] == False) & \n",
    "                                        (cat_results['Expected_Match'] == True)]\n",
    "                    \n",
    "                    fp_rate = len(cat_fp) / len(cat_results)\n",
    "                    fn_rate = len(cat_fn) / len(cat_results)\n",
    "                    \n",
    "                    analysis_results['category_analysis'][category] = {\n",
    "                        'total': len(cat_results),\n",
    "                        'false_positives': len(cat_fp),\n",
    "                        'false_negatives': len(cat_fn),\n",
    "                        'fp_rate': fp_rate,\n",
    "                        'fn_rate': fn_rate\n",
    "                    }\n",
    "            \n",
    "            print(\"\\nError rates by merchant category:\")\n",
    "            for category, stats in analysis_results['category_analysis'].items():\n",
    "                if stats['total'] >= 5:  # Only show categories with enough samples\n",
    "                    print(f\"  {category}: FP Rate: {stats['fp_rate']:.2%}, FN Rate: {stats['fn_rate']:.2%}\")\n",
    "        \n",
    "        # 3. Category mismatch analysis\n",
    "        if 'DBA_Merchant_Category' in results_df.columns and 'RawTransaction_Merchant_Category' in results_df.columns:\n",
    "            # Calculate category match rate\n",
    "            results_df['CategoryMatch'] = results_df['DBA_Merchant_Category'] == results_df['RawTransaction_Merchant_Category']\n",
    "            \n",
    "            # Errors by category match/mismatch\n",
    "            cat_match = results_df[results_df['CategoryMatch'] == True]\n",
    "            cat_mismatch = results_df[results_df['CategoryMatch'] == False]\n",
    "            \n",
    "            if len(cat_match) > 0:\n",
    "                match_fp = cat_match[(cat_match['Predicted_Match'] == True) & \n",
    "                                    (cat_match['Expected_Match'] == False)]\n",
    "                match_fn = cat_match[(cat_match['Predicted_Match'] == False) & \n",
    "                                    (cat_match['Expected_Match'] == True)]\n",
    "                \n",
    "                match_fp_rate = len(match_fp) / len(cat_match)\n",
    "                match_fn_rate = len(match_fn) / len(cat_match)\n",
    "                \n",
    "                analysis_results['category_match_errors'] = {\n",
    "                    'total': len(cat_match),\n",
    "                    'false_positives': len(match_fp),\n",
    "                    'false_negatives': len(match_fn),\n",
    "                    'fp_rate': match_fp_rate,\n",
    "                    'fn_rate': match_fn_rate\n",
    "                }\n",
    "            \n",
    "            if len(cat_mismatch) > 0:\n",
    "                mismatch_fp = cat_mismatch[(cat_mismatch['Predicted_Match'] == True) & \n",
    "                                          (cat_mismatch['Expected_Match'] == False)]\n",
    "                mismatch_fn = cat_mismatch[(cat_mismatch['Predicted_Match'] == False) & \n",
    "                                          (cat_mismatch['Expected_Match'] == True)]\n",
    "                \n",
    "                mismatch_fp_rate = len(mismatch_fp) / len(cat_mismatch)\n",
    "                mismatch_fn_rate = len(mismatch_fn) / len(cat_mismatch)\n",
    "                \n",
    "                analysis_results['category_mismatch_errors'] = {\n",
    "                    'total': len(cat_mismatch),\n",
    "                    'false_positives': len(mismatch_fp),\n",
    "                    'false_negatives': len(mismatch_fn),\n",
    "                    'fp_rate': mismatch_fp_rate,\n",
    "                    'fn_rate': mismatch_fn_rate\n",
    "                }\n",
    "            \n",
    "            print(\"\\nError rates by category match status:\")\n",
    "            if 'category_match_errors' in analysis_results:\n",
    "                match_stats = analysis_results['category_match_errors']\n",
    "                print(f\"  Category Match: FP Rate: {match_stats['fp_rate']:.2%}, \"\n",
    "                     f\"FN Rate: {match_stats['fn_rate']:.2%}\")\n",
    "            \n",
    "            if 'category_mismatch_errors' in analysis_results:\n",
    "                mismatch_stats = analysis_results['category_mismatch_errors']\n",
    "                print(f\"  Category Mismatch: FP Rate: {mismatch_stats['fp_rate']:.2%}, \"\n",
    "                     f\"FN Rate: {mismatch_stats['fn_rate']:.2%}\")\n",
    "        \n",
    "        # 4. Show examples of errors\n",
    "        if len(false_positives) > 0:\n",
    "            print(\"\\nExamples of false positives (predicted match but actually not a match):\")\n",
    "            sample_size = min(5, len(false_positives))\n",
    "            for _, row in false_positives.sample(sample_size).iterrows():\n",
    "                print(f\"  {row['DBAName']} <-> {row['RawTransactionName']} \"\n",
    "                     f\"(Score: {row['Enhanced_Score']:.4f})\")\n",
    "        \n",
    "        if len(false_negatives) > 0:\n",
    "            print(\"\\nExamples of false negatives (predicted no match but actually a match):\")\n",
    "            sample_size = min(5, len(false_negatives))\n",
    "            for _, row in false_negatives.sample(sample_size).iterrows():\n",
    "                print(f\"  {row['DBAName']} <-> {row['RawTransactionName']} \"\n",
    "                     f\"(Score: {row['Enhanced_Score']:.4f})\")\n",
    "        \n",
    "        # 5. Try to visualize errors with matplotlib if available\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            \n",
    "            # Create score distribution plots\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            # Plot score distributions for true and false matches\n",
    "            true_matches = results_df[results_df['Expected_Match'] == True]['Enhanced_Score']\n",
    "            false_matches = results_df[results_df['Expected_Match'] == False]['Enhanced_Score']\n",
    "            \n",
    "            plt.hist(true_matches, alpha=0.5, bins=20, label='True Matches')\n",
    "            plt.hist(false_matches, alpha=0.5, bins=20, label='False Matches')\n",
    "            \n",
    "            plt.xlabel('Enhanced Score')\n",
    "            plt.ylabel('Count')\n",
    "            plt.title('Score Distribution for True vs False Matches')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Save the plot\n",
    "            plt.savefig('error_analysis_score_distribution.png')\n",
    "            print(\"\\nScore distribution visualization saved as 'error_analysis_score_distribution.png'\")\n",
    "            \n",
    "            # Add plot to results\n",
    "            analysis_results['visualization_path'] = 'error_analysis_score_distribution.png'\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not create visualizations: {e}\")\n",
    "    \n",
    "    # If we don't have Expected_Match but have scores, analyze score distribution\n",
    "    else:\n",
    "        if 'Enhanced_Score' in results_df.columns:\n",
    "            # Analyze score distribution\n",
    "            score_bins = [\n",
    "                (0.0, 0.5, 'Low (0.0-0.5)'),\n",
    "                (0.5, 0.65, 'Weak (0.5-0.65)'),\n",
    "                (0.65, 0.75, 'Possible (0.65-0.75)'),\n",
    "                (0.75, 0.85, 'Probable (0.75-0.85)'),\n",
    "                (0.85, 0.95, 'Strong (0.85-0.95)'),\n",
    "                (0.95, 1.0, 'Exact (0.95-1.0)')\n",
    "            ]\n",
    "            \n",
    "            bin_counts = {}\n",
    "            for min_score, max_score, bin_name in score_bins:\n",
    "                bin_counts[bin_name] = len(results_df[(results_df['Enhanced_Score'] >= min_score) & \n",
    "                                                      (results_df['Enhanced_Score'] <= max_score)])\n",
    "            \n",
    "            analysis_results['score_distribution'] = bin_counts\n",
    "            \n",
    "            print(\"\\nScore distribution:\")\n",
    "            for bin_name, count in bin_counts.items():\n",
    "                percentage = count / len(results_df) * 100\n",
    "                print(f\"  {bin_name}: {count} records ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nError analysis completed!\")\n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4feec94-f0b7-4dbd-830e-1aa1a65b2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Comprehensive Testing and Analysis\n",
    "\n",
    "def run_comprehensive_evaluation(test_data_path=None, gold_standard_column='Expected_Match'):\n",
    "    \"\"\"\n",
    "    Run a comprehensive evaluation of the merchant matcher\n",
    "    \n",
    "    Args:\n",
    "        test_data_path: Path to test data file\n",
    "        gold_standard_column: Column name for the gold standard match status\n",
    "        \n",
    "    Returns:\n",
    "        dict: Comprehensive evaluation results\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Running comprehensive evaluation of merchant matcher...\")\n",
    "    \n",
    "    # Check if gold standard column exists in the data\n",
    "    has_gold_standard = False\n",
    "    if test_data_path:\n",
    "        try:\n",
    "            # Sample the file to check columns\n",
    "            if test_data_path.lower().endswith('.csv'):\n",
    "                df_sample = pd.read_csv(test_data_path, nrows=5)\n",
    "            else:\n",
    "                df_sample = pd.read_excel(test_data_path, nrows=5)\n",
    "            \n",
    "            has_gold_standard = gold_standard_column in df_sample.columns\n",
    "            \n",
    "            if not has_gold_standard:\n",
    "                print(f\"Warning: Gold standard column '{gold_standard_column}' not found in data.\")\n",
    "                print(\"Creating synthetic evaluation data for demonstration purposes...\")\n",
    "                \n",
    "                # Generate synthetic test data with expected outcomes\n",
    "                # This will be used instead of the actual file for evaluation\n",
    "                test_data = {\n",
    "                    'DBAName': [\n",
    "                        'BoA', 'JPMC', 'WF', 'MCD', 'SBUX', 'TGT', 'MSFT', 'AMZN',\n",
    "                        'WMT', 'HD', 'TM', 'GM', 'GS', 'MS', 'BBY',\n",
    "                    ],\n",
    "                    'RawTransactionName': [\n",
    "                        'Bank of America', 'JPMorgan Chase', 'Wells Fargo', 'McDonalds',\n",
    "                        'Starbucks', 'Target', 'Microsoft', 'Amazon',\n",
    "                        'Walmart', 'Home Depot', 'Toyota Motors', 'General Motors',\n",
    "                        'Goldman Sachs', 'Morgan Stanley', 'Best Buy',\n",
    "                    ],\n",
    "                    'Merchant_Category': [\n",
    "                        'Banking', 'Banking', 'Banking', 'Restaurant', 'Restaurant',\n",
    "                        'Retail', 'Technology', 'Technology', 'Retail', 'Retail',\n",
    "                        'Automotive', 'Automotive', 'Banking', 'Banking', 'Retail',\n",
    "                    ],\n",
    "                    'Expected_Match': [\n",
    "                        True, True, True, True, True, True, True, True, \n",
    "                        True, True, True, True, True, True, True,\n",
    "                    ]\n",
    "                }\n",
    "                \n",
    "                test_df = pd.DataFrame(test_data)\n",
    "                print(f\"Created synthetic test dataset with {len(test_df)} entries\")\n",
    "                \n",
    "                # Set test_data_path to None to use our synthetic data\n",
    "                test_data_path = None\n",
    "                # We now have gold standard data (synthetically created)\n",
    "                has_gold_standard = True\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking for gold standard column: {e}\")\n",
    "            has_gold_standard = False\n",
    "    \n",
    "    # Only perform evaluations that require gold standard if we have it\n",
    "    if has_gold_standard:\n",
    "        # Step 1: Basic Evaluation\n",
    "        print(\"\\n=== Step 1: Basic Evaluation ===\")\n",
    "        basic_eval = evaluate_merchant_matcher(test_data_path, gold_standard_column)\n",
    "        \n",
    "        # Check if basic evaluation was successful before proceeding\n",
    "        if basic_eval is None:\n",
    "            print(\"Basic evaluation failed. Creating minimal result set to continue.\")\n",
    "            basic_eval = {'results_df': None, 'accuracy': 0, 'precision': 0, 'recall': 0, 'f1_score': 0}\n",
    "        \n",
    "        # Step 2: Find Optimal Threshold\n",
    "        print(\"\\n=== Step 2: Finding Optimal Threshold ===\")\n",
    "        threshold_results = find_optimal_threshold(test_data_path, gold_standard_column)\n",
    "        \n",
    "        # Step 3: Algorithm Comparison\n",
    "        print(\"\\n=== Step 3: Algorithm Comparison ===\")\n",
    "        algorithm_comparison = compare_algorithms(test_data_path, gold_standard_column)\n",
    "        \n",
    "        # Step 4: Error Analysis\n",
    "        print(\"\\n=== Step 4: Error Analysis ===\")\n",
    "        if basic_eval['results_df'] is not None:\n",
    "            error_analysis = visualize_error_cases(basic_eval['results_df'])\n",
    "        else:\n",
    "            print(\"Skipping error analysis due to missing results data.\")\n",
    "            error_analysis = None\n",
    "        \n",
    "        # Step 5: Cross-Validation\n",
    "        print(\"\\n=== Step 5: Cross-Validation ===\")\n",
    "        cv_results = cross_validate_merchant_matcher(test_data_path, gold_standard_column)\n",
    "    else:\n",
    "        # If we don't have gold standard data, return default values\n",
    "        print(\"\\nSkipping evaluation steps that require gold standard data.\")\n",
    "        print(\"To perform comprehensive evaluation, add an 'Expected_Match' column to your data.\")\n",
    "        \n",
    "        basic_eval = {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1_score': 0}\n",
    "        threshold_results = {'optimal_threshold': 0.75}  # Default threshold\n",
    "        algorithm_comparison = {}\n",
    "        error_analysis = {}\n",
    "        cv_results = {'avg_metrics': {'threshold': 0.75}}\n",
    "    \n",
    "    # Calculate total execution time\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nComprehensive evaluation completed in {total_time:.2f} seconds\")\n",
    "    \n",
    "    # Return all results, checking for None values\n",
    "    return {\n",
    "        'basic_evaluation': basic_eval,\n",
    "        'threshold_optimization': threshold_results if threshold_results else {'optimal_threshold': 0.75},\n",
    "        'algorithm_comparison': algorithm_comparison if algorithm_comparison else {},\n",
    "        'error_analysis': error_analysis if error_analysis else {},\n",
    "        'cross_validation': cv_results if cv_results else {'avg_metrics': {'threshold': 0.75}},\n",
    "        'execution_time': total_time,\n",
    "        'has_gold_standard': has_gold_standard\n",
    "    }\n",
    "\n",
    "def run_example_pipeline():\n",
    "    \"\"\"\n",
    "    Run an example merchant matching pipeline demonstration\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Enhanced Merchant Name Matching - Pipeline Demonstration\".center(80))\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # Example 1: Process sample input file\n",
    "    print(\"\\n1. Processing a sample merchant file:\")\n",
    "    # Create a sample file for demonstration\n",
    "    sample_data = pd.DataFrame({\n",
    "        'DBAName': ['BOA', 'MCD', 'SBUX', 'TGT', 'MSFT'],\n",
    "        'RawTransactionName': ['Bank of America', 'McDonalds Corporation', 'Starbucks Coffee', 'Target', 'Microsoft'],\n",
    "        'Merchant_Category': ['Banking', 'Restaurant', 'Restaurant', 'Retail', 'Technology']\n",
    "    })\n",
    "    \n",
    "    sample_file = \"Acronym_extramcc.xlsx\"\n",
    "    sample_data.to_excel(sample_file, index=False)\n",
    "    \n",
    "    # Process the sample file\n",
    "    results = run_merchant_matching_pipeline(sample_file, \"sample_results.xlsx\")\n",
    "    \n",
    "    # Example 2: Interactive testing\n",
    "    print(\"\\n2. Interactive Merchant Matcher:\")\n",
    "    print(\"   (Skipped in automated demo - run interactive_merchant_matcher() separately)\")\n",
    "    \n",
    "    # Example 3: Algorithm comparison\n",
    "    print(\"\\n3. Algorithm Comparison:\")\n",
    "    algorithms = ['Jaro-Winkler', 'BERT Similarity', 'DBAName Formation', 'Enhanced Score']\n",
    "    print(f\"   Top algorithms: {', '.join(algorithms)}\")\n",
    "    \n",
    "    # Example 4: Batch processing\n",
    "    print(\"\\n4. Batch Processing Capability:\")\n",
    "    print(\"   System can process large files in batches to manage memory\")\n",
    "    print(\"   For PySpark integration, call adapt_for_pyspark()\")\n",
    "    \n",
    "    # Clean up sample files\n",
    "    try:\n",
    "        import os\n",
    "        os.remove(sample_file)\n",
    "        os.remove(\"Acronym_extramcc.xlsx\")\n",
    "        print(\"\\nCleaned up sample files\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"\\nDemonstration complete!\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage to process a specific file:\n",
    "# results_df = process_DBAName_file_and_export_results(\"Acronym_extramcc.xlsx\", \"DBAName_Matching_Results.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bd57910-f3e1-4533-9a0f-ac7ff08010f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "              Enhanced Merchant Name Matching - Optimized Pipeline              \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Step 1: Initializing models...\n",
      "Loading enhanced BERT model 'sentence-transformers/all-mpnet-base-v2'...\n",
      "Enhanced BERT model loaded successfully on cpu\n",
      "Enhanced merchant matcher initialized!\n",
      "\n",
      "Step 2: Loading and preprocessing merchant data...\n",
      "Loaded 273 merchant entries from Acronym_extramcc.xlsx\n",
      "Columns: ['DBAName', 'DBA_Merchant_Category', 'RawTransactionName', 'RawTransaction_Merchant_Category']\n",
      "\n",
      "Sample data:\n",
      "   DBAName DBA_Merchant_Category  \\\n",
      "0      ANZ               Banking   \n",
      "1   Qantas               Banking   \n",
      "2  Telstra               Telecom   \n",
      "\n",
      "                                  RawTransactionName  \\\n",
      "0            Australia and New Zealand Banking Group   \n",
      "1  Queensland and Northern Territory Aerial Services   \n",
      "2                                  Telecom Australia   \n",
      "\n",
      "  RawTransaction_Merchant_Category  \n",
      "0                          Banking  \n",
      "1                          Banking  \n",
      "2                          Telecom  \n",
      "Category distribution after preprocessing:\n",
      "Merchant_Category\n",
      "Retail             72\n",
      "Government         45\n",
      "Automotive         30\n",
      "Restaurant         18\n",
      "Medical            10\n",
      "Technology          9\n",
      "Banking             8\n",
      "Misc Speciality     6\n",
      "Software IT         5\n",
      "Clothing            4\n",
      "Name: count, dtype: int64\n",
      "Successfully preprocessed 273 merchant records\n",
      "\n",
      "Step 3: Running comprehensive evaluation...\n",
      "Running comprehensive evaluation of merchant matcher...\n",
      "Warning: Gold standard column 'Expected_Match' not found in data.\n",
      "Creating synthetic evaluation data for demonstration purposes...\n",
      "Created synthetic test dataset with 15 entries\n",
      "\n",
      "=== Step 1: Basic Evaluation ===\n",
      "Evaluating merchant matcher performance...\n",
      "No test data provided, creating synthetic test data...\n",
      "Created synthetic test dataset with 32 entries\n",
      "Warning: 'RawTransaction_Merchant_Category' column not found. Adding with default value 'Unknown'.\n",
      "Category distribution after preprocessing:\n",
      "Merchant_Category\n",
      "Unknown    32\n",
      "Name: count, dtype: int64\n",
      "Error processing row 0: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 3.1% (1/32) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Error processing row 1: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 2: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 3: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 4: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 5: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 6: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 7: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 8: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 9: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 10: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 11: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 12: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 13: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 14: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 15: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 16: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 17: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 18: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 19: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 20: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 65.6% (21/32) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Error processing row 21: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 22: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 23: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 24: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 25: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 26: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 27: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 28: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 29: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 30: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 31: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 100.0% (32/32) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Processing completed in 0.00 seconds\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.2500\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Analyzing errors...\n",
      "\n",
      "False Negatives (24):\n",
      "  BoA <-> Bank of America (Score: 0.0000)\n",
      "  JPMC <-> JPMorgan Chase (Score: 0.0000)\n",
      "  WF <-> Wells Fargo (Score: 0.0000)\n",
      "  MCD <-> McDonalds (Score: 0.0000)\n",
      "  SBUX <-> Starbucks (Score: 0.0000)\n",
      "  TGT <-> Target (Score: 0.0000)\n",
      "  MSFT <-> Microsoft (Score: 0.0000)\n",
      "  AMZN <-> Amazon (Score: 0.0000)\n",
      "  WMT <-> Walmart (Score: 0.0000)\n",
      "  HD <-> Home Depot (Score: 0.0000)\n",
      "  TM <-> Toyota Motors (Score: 0.0000)\n",
      "  GM <-> General Motors (Score: 0.0000)\n",
      "  GS <-> Goldman Sachs (Score: 0.0000)\n",
      "  MS <-> Morgan Stanley (Score: 0.0000)\n",
      "  BBY <-> Best Buy (Score: 0.0000)\n",
      "  BofA <-> Bank of America Corp (Score: 0.0000)\n",
      "  McDon <-> McDonalds Corporation (Score: 0.0000)\n",
      "  Micky Ds <-> McDonalds Restaurants (Score: 0.0000)\n",
      "  Wmart <-> Walmart Stores (Score: 0.0000)\n",
      "  Tgt Stores <-> Target Corporation (Score: 0.0000)\n",
      "  Msft Corp <-> Microsoft Inc (Score: 0.0000)\n",
      "  Amaz <-> Amazon.com Inc (Score: 0.0000)\n",
      "  JPM Co <-> JP Morgan (Score: 0.0000)\n",
      "  Home Dep <-> The Home Depot (Score: 0.0000)\n",
      "\n",
      "=== Step 2: Finding Optimal Threshold ===\n",
      "Finding optimal threshold for merchant matching...\n",
      "Evaluating merchant matcher performance...\n",
      "No test data provided, creating synthetic test data...\n",
      "Created synthetic test dataset with 32 entries\n",
      "Warning: 'RawTransaction_Merchant_Category' column not found. Adding with default value 'Unknown'.\n",
      "Category distribution after preprocessing:\n",
      "Merchant_Category\n",
      "Unknown    32\n",
      "Name: count, dtype: int64\n",
      "Error processing row 0: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 3.1% (1/32) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Error processing row 1: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 2: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 3: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 4: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 5: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 6: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 7: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 8: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 9: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 10: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 11: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 12: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 13: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 14: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 15: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 16: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 17: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 18: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 19: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 20: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 65.6% (21/32) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Error processing row 21: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 22: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 23: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 24: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 25: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 26: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 27: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 28: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 29: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 30: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 31: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 100.0% (32/32) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Processing completed in 0.00 seconds\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.2500\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Analyzing errors...\n",
      "\n",
      "False Negatives (24):\n",
      "  BoA <-> Bank of America (Score: 0.0000)\n",
      "  JPMC <-> JPMorgan Chase (Score: 0.0000)\n",
      "  WF <-> Wells Fargo (Score: 0.0000)\n",
      "  MCD <-> McDonalds (Score: 0.0000)\n",
      "  SBUX <-> Starbucks (Score: 0.0000)\n",
      "  TGT <-> Target (Score: 0.0000)\n",
      "  MSFT <-> Microsoft (Score: 0.0000)\n",
      "  AMZN <-> Amazon (Score: 0.0000)\n",
      "  WMT <-> Walmart (Score: 0.0000)\n",
      "  HD <-> Home Depot (Score: 0.0000)\n",
      "  TM <-> Toyota Motors (Score: 0.0000)\n",
      "  GM <-> General Motors (Score: 0.0000)\n",
      "  GS <-> Goldman Sachs (Score: 0.0000)\n",
      "  MS <-> Morgan Stanley (Score: 0.0000)\n",
      "  BBY <-> Best Buy (Score: 0.0000)\n",
      "  BofA <-> Bank of America Corp (Score: 0.0000)\n",
      "  McDon <-> McDonalds Corporation (Score: 0.0000)\n",
      "  Micky Ds <-> McDonalds Restaurants (Score: 0.0000)\n",
      "  Wmart <-> Walmart Stores (Score: 0.0000)\n",
      "  Tgt Stores <-> Target Corporation (Score: 0.0000)\n",
      "  Msft Corp <-> Microsoft Inc (Score: 0.0000)\n",
      "  Amaz <-> Amazon.com Inc (Score: 0.0000)\n",
      "  JPM Co <-> JP Morgan (Score: 0.0000)\n",
      "  Home Dep <-> The Home Depot (Score: 0.0000)\n",
      "\n",
      "Optimal threshold: 0.1000 (F1 score: 0.0000)\n",
      "At this threshold:\n",
      "  Precision: 0.0000\n",
      "  Recall: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 3: Algorithm Comparison ===\n",
      "Comparing matching algorithms...\n",
      "Evaluating merchant matcher performance...\n",
      "No test data provided, creating synthetic test data...\n",
      "Created synthetic test dataset with 32 entries\n",
      "Warning: 'RawTransaction_Merchant_Category' column not found. Adding with default value 'Unknown'.\n",
      "Category distribution after preprocessing:\n",
      "Merchant_Category\n",
      "Unknown    32\n",
      "Name: count, dtype: int64\n",
      "Error processing row 0: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 3.1% (1/32) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Error processing row 1: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 2: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 3: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 4: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 5: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 6: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 7: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 8: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 9: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 10: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 11: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 12: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 13: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 14: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 15: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 16: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 17: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 18: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 19: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 20: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 65.6% (21/32) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Error processing row 21: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 22: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 23: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 24: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 25: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 26: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 27: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 28: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 29: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 30: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 31: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 100.0% (32/32) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Processing completed in 0.01 seconds\n",
      "\n",
      "Evaluation Results:\n",
      "Accuracy: 0.2500\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Analyzing errors...\n",
      "\n",
      "False Negatives (24):\n",
      "  BoA <-> Bank of America (Score: 0.0000)\n",
      "  JPMC <-> JPMorgan Chase (Score: 0.0000)\n",
      "  WF <-> Wells Fargo (Score: 0.0000)\n",
      "  MCD <-> McDonalds (Score: 0.0000)\n",
      "  SBUX <-> Starbucks (Score: 0.0000)\n",
      "  TGT <-> Target (Score: 0.0000)\n",
      "  MSFT <-> Microsoft (Score: 0.0000)\n",
      "  AMZN <-> Amazon (Score: 0.0000)\n",
      "  WMT <-> Walmart (Score: 0.0000)\n",
      "  HD <-> Home Depot (Score: 0.0000)\n",
      "  TM <-> Toyota Motors (Score: 0.0000)\n",
      "  GM <-> General Motors (Score: 0.0000)\n",
      "  GS <-> Goldman Sachs (Score: 0.0000)\n",
      "  MS <-> Morgan Stanley (Score: 0.0000)\n",
      "  BBY <-> Best Buy (Score: 0.0000)\n",
      "  BofA <-> Bank of America Corp (Score: 0.0000)\n",
      "  McDon <-> McDonalds Corporation (Score: 0.0000)\n",
      "  Micky Ds <-> McDonalds Restaurants (Score: 0.0000)\n",
      "  Wmart <-> Walmart Stores (Score: 0.0000)\n",
      "  Tgt Stores <-> Target Corporation (Score: 0.0000)\n",
      "  Msft Corp <-> Microsoft Inc (Score: 0.0000)\n",
      "  Amaz <-> Amazon.com Inc (Score: 0.0000)\n",
      "  JPM Co <-> JP Morgan (Score: 0.0000)\n",
      "  Home Dep <-> The Home Depot (Score: 0.0000)\n",
      "Warning: 'RawTransaction_Merchant_Category' column not found. Adding with default value 'Unknown'.\n",
      "Category distribution after preprocessing:\n",
      "Merchant_Category\n",
      "Unknown    32\n",
      "Name: count, dtype: int64\n",
      "Evaluating Jaro-Winkler...\n",
      "Comprehensive evaluation encountered an error: 'NoneType' object has no attribute 'jaro_winkler_similarity'\n",
      "Continuing with default thresholds...\n",
      "\n",
      "Step 4: Processing merchant data with optimized parameters...\n",
      "Progress: 0.4% (1/273) - Elapsed: 0.3s - Est. remaining: 0.0s\n",
      "Progress: 7.7% (21/273) - Elapsed: 6.6s - Est. remaining: 78.8s\n",
      "Progress: 15.0% (41/273) - Elapsed: 13.0s - Est. remaining: 73.4s\n",
      "Progress: 22.3% (61/273) - Elapsed: 19.4s - Est. remaining: 67.5s\n",
      "Progress: 29.7% (81/273) - Elapsed: 26.1s - Est. remaining: 61.8s\n",
      "Progress: 37.0% (101/273) - Elapsed: 32.4s - Est. remaining: 55.1s\n",
      "Progress: 44.3% (121/273) - Elapsed: 38.7s - Est. remaining: 48.6s\n",
      "Progress: 51.6% (141/273) - Elapsed: 44.9s - Est. remaining: 42.0s\n",
      "Progress: 59.0% (161/273) - Elapsed: 51.1s - Est. remaining: 35.5s\n",
      "Progress: 66.3% (181/273) - Elapsed: 57.1s - Est. remaining: 29.0s\n",
      "Progress: 73.6% (201/273) - Elapsed: 63.3s - Est. remaining: 22.7s\n",
      "Progress: 81.0% (221/273) - Elapsed: 69.8s - Est. remaining: 16.4s\n",
      "Progress: 88.3% (241/273) - Elapsed: 76.0s - Est. remaining: 10.1s\n",
      "Progress: 95.6% (261/273) - Elapsed: 82.0s - Est. remaining: 3.8s\n",
      "Progress: 100.0% (273/273) - Elapsed: 85.7s - Est. remaining: 0.0s\n",
      "Processing completed in 85.69 seconds\n",
      "\n",
      "Match category distribution:\n",
      "  No Match: 273 (100.0%)\n",
      "Results saved to DBAName_Matching_Results_Optimized.xlsx\n",
      "\n",
      "Match category distribution:\n",
      "  No Match: 273 (100.0%)\n",
      "\n",
      "Overall Statistics:\n",
      "  Average Basic Score: 0.5072\n",
      "  Average Enhanced Score: 0.5541\n",
      "  Overall Improvement: 9.25%\n",
      "\n",
      "Sample matches by category:\n",
      "\n",
      "No Match (273 entries):\n",
      "  SBUX <-> Starbucks Coffee (Category: Restaurant, Score: 0.7500)\n",
      "  Sennheiser <-> ROHLIG AUSTRALIA PTY L (Category: COURIER SERVICES, Score: 0.1899)\n",
      "  Thrifty Australia <-> THRIFTY FYSHWICK DOWNTOWN (Category: Automotive, Score: 0.5387)\n",
      "  Pace Athletic <-> AESIR ATHLETICS (Category: Misc PERSONAL SERV - DEF, Score: 0.5391)\n",
      "  AWBC <-> Australian Wine and Brandy Corporation (Category: Beer Store, Score: 0.3532)\n",
      "\n",
      "Performance by Merchant Category:\n",
      "  Banking (8 entries):\n",
      "    Basic Score: 0.6241\n",
      "    Enhanced Score: 0.7625\n",
      "    Improvement: 22.16%\n",
      "  Telecom (2 entries):\n",
      "    Basic Score: 0.5448\n",
      "    Enhanced Score: 0.6605\n",
      "    Improvement: 21.22%\n",
      "  Government (45 entries):\n",
      "    Basic Score: 0.5215\n",
      "    Enhanced Score: 0.6168\n",
      "    Improvement: 18.27%\n",
      "  Insurance (1 entries):\n",
      "    Basic Score: 0.5693\n",
      "    Enhanced Score: 0.7117\n",
      "    Improvement: 25.00%\n",
      "  Automotive (30 entries):\n",
      "    Basic Score: 0.5142\n",
      "    Enhanced Score: 0.5823\n",
      "    Improvement: 13.25%\n",
      "  Grocery (1 entries):\n",
      "    Basic Score: 0.5346\n",
      "    Enhanced Score: 0.5346\n",
      "    Improvement: 0.00%\n",
      "  Misc Speciality (6 entries):\n",
      "    Basic Score: 0.6905\n",
      "    Enhanced Score: 0.7737\n",
      "    Improvement: 12.05%\n",
      "  Postal Service (1 entries):\n",
      "    Basic Score: 0.6293\n",
      "    Enhanced Score: 0.7500\n",
      "    Improvement: 19.19%\n",
      "  Sports (2 entries):\n",
      "    Basic Score: 0.7118\n",
      "    Enhanced Score: 0.8188\n",
      "    Improvement: 15.02%\n",
      "  Travel (1 entries):\n",
      "    Basic Score: 0.5341\n",
      "    Enhanced Score: 0.7500\n",
      "    Improvement: 40.43%\n",
      "  Software IT (5 entries):\n",
      "    Basic Score: 0.5102\n",
      "    Enhanced Score: 0.5345\n",
      "    Improvement: 4.75%\n",
      "  Pharmacy (3 entries):\n",
      "    Basic Score: 0.5329\n",
      "    Enhanced Score: 0.5773\n",
      "    Improvement: 8.34%\n",
      "  Beer Store (3 entries):\n",
      "    Basic Score: 0.4224\n",
      "    Enhanced Score: 0.4224\n",
      "    Improvement: 0.00%\n",
      "  Logistics (1 entries):\n",
      "    Basic Score: 0.6465\n",
      "    Enhanced Score: 0.8081\n",
      "    Improvement: 25.00%\n",
      "  Credit Agency (1 entries):\n",
      "    Basic Score: 0.5880\n",
      "    Enhanced Score: 0.7350\n",
      "    Improvement: 25.00%\n",
      "  Machinery (1 entries):\n",
      "    Basic Score: 0.7349\n",
      "    Enhanced Score: 0.7500\n",
      "    Improvement: 2.05%\n",
      "  Electric components (1 entries):\n",
      "    Basic Score: 0.7118\n",
      "    Enhanced Score: 0.7500\n",
      "    Improvement: 5.37%\n",
      "  Minning (1 entries):\n",
      "    Basic Score: 0.2898\n",
      "    Enhanced Score: 0.2898\n",
      "    Improvement: 0.00%\n",
      "  Electronics (1 entries):\n",
      "    Basic Score: 0.6078\n",
      "    Enhanced Score: 0.6078\n",
      "    Improvement: 0.00%\n",
      "  Restaurant (18 entries):\n",
      "    Basic Score: 0.4967\n",
      "    Enhanced Score: 0.5289\n",
      "    Improvement: 6.50%\n",
      "  Supermart (2 entries):\n",
      "    Basic Score: 0.5277\n",
      "    Enhanced Score: 0.5277\n",
      "    Improvement: 0.00%\n",
      "  Clothing (4 entries):\n",
      "    Basic Score: 0.3686\n",
      "    Enhanced Score: 0.3686\n",
      "    Improvement: 0.00%\n",
      "  Mens/womens wear (2 entries):\n",
      "    Basic Score: 0.5441\n",
      "    Enhanced Score: 0.5441\n",
      "    Improvement: 0.00%\n",
      "  Shoe Store (3 entries):\n",
      "    Basic Score: 0.4420\n",
      "    Enhanced Score: 0.4420\n",
      "    Improvement: 0.00%\n",
      "  MISC GENERAL MERCHANDISE (2 entries):\n",
      "    Basic Score: 0.6458\n",
      "    Enhanced Score: 0.6458\n",
      "    Improvement: 0.00%\n",
      "  Retail (72 entries):\n",
      "    Basic Score: 0.4970\n",
      "    Enhanced Score: 0.5153\n",
      "    Improvement: 3.68%\n",
      "  MOTOR HOME/RV RENTALS (3 entries):\n",
      "    Basic Score: 0.6983\n",
      "    Enhanced Score: 0.7228\n",
      "    Improvement: 3.51%\n",
      "  MISC HOME FURNISHING SPECIALTY (1 entries):\n",
      "    Basic Score: 0.7241\n",
      "    Enhanced Score: 0.7500\n",
      "    Improvement: 3.58%\n",
      "  TELECOMMUNICATION SERVICES (1 entries):\n",
      "    Basic Score: 0.6983\n",
      "    Enhanced Score: 0.7500\n",
      "    Improvement: 7.41%\n",
      "  CABLE, SAT, PAY TV/RADIO SVCS (1 entries):\n",
      "    Basic Score: 0.6777\n",
      "    Enhanced Score: 0.7500\n",
      "    Improvement: 10.68%\n",
      "  Technology (9 entries):\n",
      "    Basic Score: 0.5330\n",
      "    Enhanced Score: 0.6014\n",
      "    Improvement: 12.82%\n",
      "  TRAVEL AGENCIES (3 entries):\n",
      "    Basic Score: 0.5251\n",
      "    Enhanced Score: 0.5601\n",
      "    Improvement: 6.68%\n",
      "  HEATING, PLUMBING, AIR COND (1 entries):\n",
      "    Basic Score: 0.5973\n",
      "    Enhanced Score: 0.5973\n",
      "    Improvement: 0.00%\n",
      "  FREEZER/MEAT LOCKERS (1 entries):\n",
      "    Basic Score: 0.5516\n",
      "    Enhanced Score: 0.5516\n",
      "    Improvement: 0.00%\n",
      "  Medical (10 entries):\n",
      "    Basic Score: 0.4026\n",
      "    Enhanced Score: 0.4346\n",
      "    Improvement: 7.95%\n",
      "  Misc PERSONAL SERV - DEF (1 entries):\n",
      "    Basic Score: 0.5391\n",
      "    Enhanced Score: 0.5391\n",
      "    Improvement: 0.00%\n",
      "  CLEAN/MAINT/JANITORIAL SERV (1 entries):\n",
      "    Basic Score: 0.5367\n",
      "    Enhanced Score: 0.5367\n",
      "    Improvement: 0.00%\n",
      "  MASSAGE PARLORS (1 entries):\n",
      "    Basic Score: 0.5186\n",
      "    Enhanced Score: 0.5186\n",
      "    Improvement: 0.00%\n",
      "  THEATRICAL PRODUCERS (1 entries):\n",
      "    Basic Score: 0.5120\n",
      "    Enhanced Score: 0.5120\n",
      "    Improvement: 0.00%\n",
      "  LAUNDRIES-FAMILY/COMMERCIAL (1 entries):\n",
      "    Basic Score: 0.5112\n",
      "    Enhanced Score: 0.5112\n",
      "    Improvement: 0.00%\n",
      "  RECREATION SERVICES (2 entries):\n",
      "    Basic Score: 0.4654\n",
      "    Enhanced Score: 0.4654\n",
      "    Improvement: 0.00%\n",
      "  DIGITAL GOODS:ARPLICATIONS(EXCLUDES GAMES) (1 entries):\n",
      "    Basic Score: 0.4744\n",
      "    Enhanced Score: 0.4744\n",
      "    Improvement: 0.00%\n",
      "  MEMBER CLUBS/SPORT/REC/GOLF (1 entries):\n",
      "    Basic Score: 0.4607\n",
      "    Enhanced Score: 0.4607\n",
      "    Improvement: 0.00%\n",
      "  BANDS/ORCHESTRAS/ENTERTAIN (1 entries):\n",
      "    Basic Score: 0.4477\n",
      "    Enhanced Score: 0.4477\n",
      "    Improvement: 0.00%\n",
      "  TRAVEL 'AGENCIES (1 entries):\n",
      "    Basic Score: 0.4245\n",
      "    Enhanced Score: 0.4245\n",
      "    Improvement: 0.00%\n",
      "  HOTELS7MO,TELSiRSORTS. (1 entries):\n",
      "    Basic Score: 0.4006\n",
      "    Enhanced Score: 0.4006\n",
      "    Improvement: 0.00%\n",
      "  MISCEGENERAL MERCHANDISE (1 entries):\n",
      "    Basic Score: 0.3754\n",
      "    Enhanced Score: 0.3754\n",
      "    Improvement: 0.00%\n",
      "  HOTELS/MOTELS/RESORTS (3 entries):\n",
      "    Basic Score: 0.2898\n",
      "    Enhanced Score: 0.2898\n",
      "    Improvement: 0.00%\n",
      "  BARS/TAVERNS/LOUNGES/DISCOS (1 entries):\n",
      "    Basic Score: 0.3474\n",
      "    Enhanced Score: 0.3474\n",
      "    Improvement: 0.00%\n",
      "  DETECTIVE/PROTECTIVE AGEN (1 entries):\n",
      "    Basic Score: 0.3164\n",
      "    Enhanced Score: 0.3164\n",
      "    Improvement: 0.00%\n",
      "  REAL EST AGNTS & MGRS RENTALS (1 entries):\n",
      "    Basic Score: 0.3060\n",
      "    Enhanced Score: 0.3060\n",
      "    Improvement: 0.00%\n",
      "  Misc HOME FURNISHING SPECIALTY (1 entries):\n",
      "    Basic Score: 0.2822\n",
      "    Enhanced Score: 0.2822\n",
      "    Improvement: 0.00%\n",
      "  MOTORCYCLE DEALERS (1 entries):\n",
      "    Basic Score: 0.2603\n",
      "    Enhanced Score: 0.2603\n",
      "    Improvement: 0.00%\n",
      "  ELECTRICAL CONTRACTORS (1 entries):\n",
      "    Basic Score: 0.2404\n",
      "    Enhanced Score: 0.2404\n",
      "    Improvement: 0.00%\n",
      "  OTHER DIRECT MARKETERS (1 entries):\n",
      "    Basic Score: 0.2169\n",
      "    Enhanced Score: 0.2169\n",
      "    Improvement: 0.00%\n",
      "  BOAT DEALERS (1 entries):\n",
      "    Basic Score: 0.2102\n",
      "    Enhanced Score: 0.2102\n",
      "    Improvement: 0.00%\n",
      "  COURIER SERVICES (1 entries):\n",
      "    Basic Score: 0.1899\n",
      "    Enhanced Score: 0.1899\n",
      "    Improvement: 0.00%\n",
      "  Financial (1 entries):\n",
      "    Basic Score: 0.5866\n",
      "    Enhanced Score: 0.7500\n",
      "    Improvement: 27.85%\n",
      "\n",
      "Most improved matches:\n",
      "  ACCC <-> Australian Competition & Consumer Commission (Category: Government)\n",
      "    Basic: 0.4948, Enhanced: 0.7669, Improvement: 0.2721 (55.0%)\n",
      "  ANSTO <-> Australian Nuclear Science and Technology Organisation (Category: Government)\n",
      "    Basic: 0.4852, Enhanced: 0.7500, Improvement: 0.2648 (54.6%)\n",
      "  MCD <-> McDonalds (Category: Restaurant)\n",
      "    Basic: 0.7412, Enhanced: 1.0000, Improvement: 0.2588 (34.9%)\n",
      "  KPMG <-> Klynveld Peat Marwick Goerdeler (Category: Technology)\n",
      "    Basic: 0.4933, Enhanced: 0.7500, Improvement: 0.2567 (52.0%)\n",
      "  ASIC <-> Australian Securities and Investments Commission (Category: Government)\n",
      "    Basic: 0.5071, Enhanced: 0.7500, Improvement: 0.2429 (47.9%)\n",
      "\n",
      "Step 5: Demonstrating batch processing capability...\n",
      "Batch processing merchant data from Acronym_extramcc.xlsx\n",
      "Category distribution after preprocessing:\n",
      "Merchant_Category\n",
      "Retail             72\n",
      "Government         45\n",
      "Automotive         30\n",
      "Restaurant         18\n",
      "Medical            10\n",
      "Technology          9\n",
      "Banking             8\n",
      "Misc Speciality     6\n",
      "Software IT         5\n",
      "Clothing            4\n",
      "Name: count, dtype: int64\n",
      "Processing batch 1/55 (0-5)\n",
      "Error processing row 0: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 20.0% (1/5) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Error processing row 1: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 2: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 3: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 4: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 100.0% (5/5) - Elapsed: 0.0s - Est. remaining: 0.0s\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 5/273 records (1.8%)\n",
      "Processing batch 2/55 (5-10)\n",
      "Error processing row 5: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 6: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 7: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 8: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 9: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 10/273 records (3.7%)\n",
      "Processing batch 3/55 (10-15)\n",
      "Error processing row 10: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 11: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 12: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 13: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 14: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 15/273 records (5.5%)\n",
      "Processing batch 4/55 (15-20)\n",
      "Error processing row 15: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 16: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 17: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 18: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 19: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 20/273 records (7.3%)\n",
      "Processing batch 5/55 (20-25)\n",
      "Error processing row 20: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 420.0% (21/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 21: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 22: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 23: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 24: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 25/273 records (9.2%)\n",
      "Processing batch 6/55 (25-30)\n",
      "Error processing row 25: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 26: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 27: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 28: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 29: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 30/273 records (11.0%)\n",
      "Processing batch 7/55 (30-35)\n",
      "Error processing row 30: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 31: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 32: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 33: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 34: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 35/273 records (12.8%)\n",
      "Processing batch 8/55 (35-40)\n",
      "Error processing row 35: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 36: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 37: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 38: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 39: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 40/273 records (14.7%)\n",
      "Processing batch 9/55 (40-45)\n",
      "Error processing row 40: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 820.0% (41/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 41: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 42: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 43: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 44: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 45/273 records (16.5%)\n",
      "Processing batch 10/55 (45-50)\n",
      "Error processing row 45: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 46: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 47: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 48: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 49: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 50/273 records (18.3%)\n",
      "Processing batch 11/55 (50-55)\n",
      "Error processing row 50: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 51: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 52: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 53: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 54: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 55/273 records (20.1%)\n",
      "Processing batch 12/55 (55-60)\n",
      "Error processing row 55: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 56: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 57: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 58: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 59: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 60/273 records (22.0%)\n",
      "Processing batch 13/55 (60-65)\n",
      "Error processing row 60: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 1220.0% (61/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 61: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 62: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 63: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 64: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 65/273 records (23.8%)\n",
      "Processing batch 14/55 (65-70)\n",
      "Error processing row 65: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 66: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 67: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 68: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 69: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 70/273 records (25.6%)\n",
      "Processing batch 15/55 (70-75)\n",
      "Error processing row 70: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 71: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 72: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 73: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 74: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 75/273 records (27.5%)\n",
      "Processing batch 16/55 (75-80)\n",
      "Error processing row 75: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 76: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 77: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 78: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 79: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 80/273 records (29.3%)\n",
      "Processing batch 17/55 (80-85)\n",
      "Error processing row 80: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 1620.0% (81/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 81: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 82: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 83: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 84: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 85/273 records (31.1%)\n",
      "Processing batch 18/55 (85-90)\n",
      "Error processing row 85: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 86: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 87: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 88: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 89: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 90/273 records (33.0%)\n",
      "Processing batch 19/55 (90-95)\n",
      "Error processing row 90: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 91: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 92: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 93: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 94: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 95/273 records (34.8%)\n",
      "Processing batch 20/55 (95-100)\n",
      "Error processing row 95: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 96: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 97: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 98: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 99: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 100/273 records (36.6%)\n",
      "Processing batch 21/55 (100-105)\n",
      "Error processing row 100: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 2020.0% (101/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 101: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 102: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 103: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 104: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 105/273 records (38.5%)\n",
      "Processing batch 22/55 (105-110)\n",
      "Error processing row 105: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 106: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 107: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 108: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 109: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 110/273 records (40.3%)\n",
      "Processing batch 23/55 (110-115)\n",
      "Error processing row 110: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 111: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 112: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 113: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 114: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 115/273 records (42.1%)\n",
      "Processing batch 24/55 (115-120)\n",
      "Error processing row 115: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 116: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 117: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 118: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 119: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 120/273 records (44.0%)\n",
      "Processing batch 25/55 (120-125)\n",
      "Error processing row 120: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 2420.0% (121/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 121: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 122: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 123: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 124: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 125/273 records (45.8%)\n",
      "Processing batch 26/55 (125-130)\n",
      "Error processing row 125: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 126: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 127: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 128: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 129: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 130/273 records (47.6%)\n",
      "Processing batch 27/55 (130-135)\n",
      "Error processing row 130: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 131: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 132: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 133: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 134: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 135/273 records (49.5%)\n",
      "Processing batch 28/55 (135-140)\n",
      "Error processing row 135: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 136: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 137: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 138: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 139: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 140/273 records (51.3%)\n",
      "Processing batch 29/55 (140-145)\n",
      "Error processing row 140: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 2820.0% (141/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 141: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 142: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 143: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 144: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 145/273 records (53.1%)\n",
      "Processing batch 30/55 (145-150)\n",
      "Error processing row 145: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 146: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 147: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 148: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 149: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 150/273 records (54.9%)\n",
      "Processing batch 31/55 (150-155)\n",
      "Error processing row 150: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 151: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 152: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 153: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 154: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 155/273 records (56.8%)\n",
      "Processing batch 32/55 (155-160)\n",
      "Error processing row 155: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 156: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 157: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 158: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 159: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 160/273 records (58.6%)\n",
      "Processing batch 33/55 (160-165)\n",
      "Error processing row 160: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 3220.0% (161/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 161: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 162: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 163: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 164: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 165/273 records (60.4%)\n",
      "Processing batch 34/55 (165-170)\n",
      "Error processing row 165: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 166: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 167: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 168: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 169: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 170/273 records (62.3%)\n",
      "Processing batch 35/55 (170-175)\n",
      "Error processing row 170: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 171: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 172: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 173: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 174: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 175/273 records (64.1%)\n",
      "Processing batch 36/55 (175-180)\n",
      "Error processing row 175: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 176: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 177: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 178: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 179: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 180/273 records (65.9%)\n",
      "Processing batch 37/55 (180-185)\n",
      "Error processing row 180: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 3620.0% (181/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 181: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 182: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 183: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 184: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 185/273 records (67.8%)\n",
      "Processing batch 38/55 (185-190)\n",
      "Error processing row 185: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 186: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 187: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 188: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 189: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 190/273 records (69.6%)\n",
      "Processing batch 39/55 (190-195)\n",
      "Error processing row 190: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 191: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 192: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 193: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 194: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 195/273 records (71.4%)\n",
      "Processing batch 40/55 (195-200)\n",
      "Error processing row 195: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 196: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 197: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 198: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 199: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 200/273 records (73.3%)\n",
      "Processing batch 41/55 (200-205)\n",
      "Error processing row 200: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 4020.0% (201/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 201: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 202: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 203: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 204: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 205/273 records (75.1%)\n",
      "Processing batch 42/55 (205-210)\n",
      "Error processing row 205: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 206: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 207: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 208: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 209: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 210/273 records (76.9%)\n",
      "Processing batch 43/55 (210-215)\n",
      "Error processing row 210: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 211: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 212: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 213: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 214: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 215/273 records (78.8%)\n",
      "Processing batch 44/55 (215-220)\n",
      "Error processing row 215: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 216: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 217: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 218: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 219: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 220/273 records (80.6%)\n",
      "Processing batch 45/55 (220-225)\n",
      "Error processing row 220: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 4420.0% (221/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 221: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 222: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 223: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 224: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 225/273 records (82.4%)\n",
      "Processing batch 46/55 (225-230)\n",
      "Error processing row 225: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 226: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 227: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 228: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 229: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 230/273 records (84.2%)\n",
      "Processing batch 47/55 (230-235)\n",
      "Error processing row 230: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 231: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 232: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 233: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 234: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 235/273 records (86.1%)\n",
      "Processing batch 48/55 (235-240)\n",
      "Error processing row 235: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 236: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 237: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 238: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 239: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 240/273 records (87.9%)\n",
      "Processing batch 49/55 (240-245)\n",
      "Error processing row 240: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 4820.0% (241/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 241: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 242: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 243: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 244: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 245/273 records (89.7%)\n",
      "Processing batch 50/55 (245-250)\n",
      "Error processing row 245: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 246: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 247: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 248: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 249: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 250/273 records (91.6%)\n",
      "Processing batch 51/55 (250-255)\n",
      "Error processing row 250: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 251: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 252: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 253: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 254: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 255/273 records (93.4%)\n",
      "Processing batch 52/55 (255-260)\n",
      "Error processing row 255: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 256: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 257: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 258: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 259: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 260/273 records (95.2%)\n",
      "Processing batch 53/55 (260-265)\n",
      "Error processing row 260: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Progress: 5220.0% (261/5) - Elapsed: 0.0s - Est. remaining: -0.0s\n",
      "Error processing row 261: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 262: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 263: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 264: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 265/273 records (97.1%)\n",
      "Processing batch 54/55 (265-270)\n",
      "Error processing row 265: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 266: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 267: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 268: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 269: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 270/273 records (98.9%)\n",
      "Processing batch 55/55 (270-273)\n",
      "Error processing row 270: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 271: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Error processing row 272: 'NoneType' object has no attribute 'compute_weighted_score'\n",
      "Processing completed in 0.00 seconds\n",
      "Processed 273/273 records (100.0%)\n",
      "\n",
      "Match category distribution:\n",
      "  No Match: 273 (100.0%)\n",
      "Successfully processed 273 records in batches\n",
      "\n",
      "Step 6: Finding optimal threshold directly...\n",
      "Finding optimal threshold for merchant matching...\n",
      "Loaded test data from Acronym_extramcc.xlsx with 273 entries\n",
      "Error loading or processing test data: Gold standard column 'Expected_Match' not found in test data\n",
      "\n",
      "Step 7: Interactive merchant matcher demonstration...\n",
      "Auto-matching example: 'BOA' and 'Bank of America'\n",
      "Match score: 0.8271\n",
      "\n",
      "Complete merchant matching pipeline executed in 90.05 seconds\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Usage Examples and Main Execution\n",
    "\n",
    "# This cell contains usage examples and demonstrations\n",
    "merchant_matcher = None\n",
    "DBA_Merchant_Category = None\n",
    "RawTransaction_Merchant_Category = None\n",
    "\n",
    "# Define thresholds for categorization\n",
    "thresholds = {\n",
    "    'Exact Match': 0.95,\n",
    "    'Strong Match': 0.85,\n",
    "    'Probable Match': 0.75,\n",
    "    'Possible Match': 0.65,\n",
    "    'Weak Match': 0.50,\n",
    "    'No Match': 0.0\n",
    "}\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the enhanced merchant matching pipeline with proper error handling\n",
    "    and no duplicate processing.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Dictionary to store all results, with proper initialization to avoid undefined variables\n",
    "    results = {\n",
    "        'results_df': None,\n",
    "        'analysis_results': None,\n",
    "        'threshold_results': None,\n",
    "        'eval_results': None,\n",
    "        'batch_results': None\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Enhanced Merchant Name Matching - Optimized Pipeline\".center(80))\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Check for input file and create if missing\n",
    "        input_file = \"Acronym_extramcc.xlsx\"\n",
    "        import os.path\n",
    "        if not os.path.isfile(input_file):\n",
    "            print(f\"Input file '{input_file}' not found. Creating sample file...\")\n",
    "            # Create sample file code as in original\n",
    "            import pandas as pd\n",
    "            sample_data = {\n",
    "                'DBAName': ['BOA', 'MCD', 'SBUX', 'AMZN', 'MSFT', 'WMT', 'TGT', 'HD', 'COST', 'GS'],\n",
    "                'RawTransactionName': ['Bank of America', 'McDonalds', 'Starbucks Coffee', 'Amazon', \n",
    "                                      'Microsoft', 'Walmart', 'Target', 'Home Depot', 'Costco', 'Goldman Sachs'],\n",
    "                'DBA_Merchant_Category': ['Banking', 'Restaurant', 'Restaurant', 'Technology', 'Technology',\n",
    "                                         'Retail', 'Retail', 'Retail', 'Retail', 'Banking'],\n",
    "                'RawTransaction_Merchant_Category': ['Banking', 'Restaurant', 'Restaurant', 'Technology', 'Technology',\n",
    "                                                   'Retail', 'Retail', 'Retail', 'Retail', 'Banking'],\n",
    "                'Expected_Match': [True, True, True, True, True, True, True, True, True, True]\n",
    "            }\n",
    "            test_df = pd.DataFrame(sample_data)\n",
    "            test_df.to_excel(input_file, index=False)\n",
    "            print(f\"Created sample file '{input_file}' with 10 merchant entries\")\n",
    "        \n",
    "        # Step 1: Initialize models - do this only ONCE\n",
    "        print(\"\\nStep 1: Initializing models...\")\n",
    "        bert_embedder = EnhancedBERTEmbedder(model_name='sentence-transformers/all-mpnet-base-v2')\n",
    "        #merchant_matcher = EnhancedMerchantMatcher(bert_embedder=bert_embedder)\n",
    "        merchant_matcher = EnhancedMerchantMatcherWithSimilarity(bert_embedder)\n",
    "        \n",
    "        # Set common DBANames\n",
    "        merchant_matcher.common_dbanames = COMMON_DBANameS\n",
    "        print(f\"Enhanced merchant matcher initialized!\")\n",
    "        \n",
    "        # Step 2: Unified data loading and preprocessing - do this ONCE\n",
    "        print(\"\\nStep 2: Loading and preprocessing merchant data...\")\n",
    "        merchant_df = load_merchant_data(input_file)\n",
    "        processed_df = preprocess_merchant_data(merchant_df)\n",
    "        print(f\"Successfully preprocessed {len(processed_df)} merchant records\")\n",
    "        \n",
    "        # Step 3: Run comprehensive evaluation for insights\n",
    "        print(\"\\nStep 3: Running comprehensive evaluation...\")\n",
    "        try:\n",
    "            eval_results = run_comprehensive_evaluation(test_data_path=input_file)\n",
    "            results['eval_results'] = eval_results\n",
    "\n",
    "            # Add the new code right here\n",
    "            if results['eval_results'] and 'has_gold_standard' in results['eval_results']:\n",
    "                has_gold_standard = results['eval_results']['has_gold_standard']\n",
    "                if not has_gold_standard:\n",
    "                    print(\"Note: Using default threshold values since no gold standard data was available.\")\n",
    "                    \n",
    "            # Extract and use threshold from evaluation\n",
    "            if eval_results and 'threshold_optimization' in eval_results:\n",
    "                threshold_opt = eval_results['threshold_optimization']\n",
    "                if threshold_opt and 'optimal_threshold' in threshold_opt:\n",
    "                    optimal_threshold = threshold_opt['optimal_threshold']\n",
    "                    \n",
    "                    # Update global thresholds dictionary\n",
    "                    global thresholds\n",
    "                    thresholds['Probable Match'] = optimal_threshold\n",
    "                    thresholds['Strong Match'] = min(1.0, optimal_threshold + 0.1)\n",
    "                    thresholds['Possible Match'] = max(0.0, optimal_threshold - 0.1)\n",
    "                    print(f\"Updated thresholds based on evaluation: {optimal_threshold:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Comprehensive evaluation encountered an error: {e}\")\n",
    "            print(\"Continuing with default thresholds...\")\n",
    "        \n",
    "        # Step 4: Process data with single unified approach\n",
    "        print(\"\\nStep 4: Processing merchant data with optimized parameters...\")\n",
    "        output_file = \"DBAName_Matching_Results_Optimized.xlsx\"\n",
    "        try:\n",
    "            # Use the unified processing function\n",
    "            results_df = process_merchant_data(processed_df, merchant_matcher)\n",
    "            \n",
    "            # Add match categories\n",
    "            results_df = add_match_categories(results_df, thresholds)\n",
    "            \n",
    "            # Save results\n",
    "            results_df.to_excel(output_file, index=False)\n",
    "            results['results_df'] = results_df\n",
    "            print(f\"Results saved to {output_file}\")\n",
    "            \n",
    "            # Analyze the results properly\n",
    "            analysis_results = analyze_merchant_results(results_df)\n",
    "            results['analysis_results'] = analysis_results\n",
    "        except Exception as e:\n",
    "            print(f\"Error in processing data: {e}\")\n",
    "        \n",
    "        # Step 5: Demonstrate batch processing capability (if needed for large files)\n",
    "        print(\"\\nStep 5: Demonstrating batch processing capability...\")\n",
    "        try:\n",
    "            batch_results = batch_process_file(\n",
    "                input_file=input_file,\n",
    "                output_file=\"DBAName_Matching_Batched.xlsx\",\n",
    "                batch_size=5,  # Small for demonstration\n",
    "                use_spark=False  # Only use True if PySpark is properly installed\n",
    "            )\n",
    "            results['batch_results'] = batch_results\n",
    "            \n",
    "            if isinstance(batch_results, dict) and 'records_processed' in batch_results:\n",
    "                print(f\"Successfully processed {batch_results['records_processed']} records in batches\")\n",
    "        except Exception as e:\n",
    "            print(f\"Batch processing demonstration error: {e}\")\n",
    "        \n",
    "        # Step 6: Find optimal threshold directly (just to demonstrate the function)\n",
    "        try:\n",
    "            print(\"\\nStep 6: Finding optimal threshold directly...\")\n",
    "            threshold_results = find_optimal_threshold(input_file)\n",
    "            results['threshold_results'] = threshold_results\n",
    "            \n",
    "            if threshold_results and 'optimal_threshold' in threshold_results:\n",
    "                print(f\"Optimal threshold found: {threshold_results['optimal_threshold']:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding optimal threshold: {e}\")\n",
    "        \n",
    "        # Step 7: Run interactive matcher with limited examples for demonstration\n",
    "        print(\"\\nStep 7: Interactive merchant matcher demonstration...\")\n",
    "        try:\n",
    "            example_pairs = [\n",
    "                ('BOA', 'Bank of America'),\n",
    "                ('MCD', 'McDonalds'),\n",
    "                ('AMZN', 'Amazon.com')\n",
    "            ]\n",
    "            # Just demonstrate the first example automatically\n",
    "            DBAName, RawTransactionName = example_pairs[0]\n",
    "            print(f\"Auto-matching example: '{DBAName}' and '{RawTransactionName}'\")\n",
    "            \n",
    "            # Get score\n",
    "            score = merchant_matcher.compute_enhanced_score(\n",
    "                DBAName, 'Banking', RawTransactionName, 'Banking'\n",
    "            )\n",
    "            print(f\"Match score: {score:.4f}\")\n",
    "            \n",
    "            # Interactive mode can be enabled with:\n",
    "            # interactive_merchant_matcher(merchant_matcher, examples=example_pairs, top_n=3)\n",
    "        except Exception as e:\n",
    "            print(f\"Interactive matcher demonstration error: {e}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Major error in merchant matching pipeline: {e}\")\n",
    "    \n",
    "    # Calculate total execution time\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nComplete merchant matching pipeline executed in {total_time:.2f} seconds\")\n",
    "    \n",
    "    # Return safely with all variables properly initialized\n",
    "    return results\n",
    "\n",
    "# Make sure to actually call the main function if running as a script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e440b285-b4a6-4f4b-95c2-7bf35c084fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
