{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52de6ee-f6a8-4f9b-ad75-d6ae1619d082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers library available for BERT embeddings\n",
      "Warning: pyahocorasick not available. Using fallback implementation.\n",
      "Using device: cpu\n",
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "from Levenshtein import jaro_winkler, ratio as levenshtein_ratio\n",
    "import textdistance\n",
    "from fuzzywuzzy import fuzz\n",
    "import jellyfish\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Import transformers for BERT embeddings\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    transformers_available = True\n",
    "    print(\"Transformers library available for BERT embeddings\")\n",
    "except ImportError:\n",
    "    transformers_available = False\n",
    "    print(\"Warning: transformers library not available. Will use TF-IDF fallback.\")\n",
    "\n",
    "# Try to import pyahocorasick with fallback\n",
    "try:\n",
    "    import pyahocorasick\n",
    "    aho_corasick_available = True\n",
    "    print(\"pyahocorasick is available\")\n",
    "except ImportError:\n",
    "    print(\"Warning: pyahocorasick not available. Using fallback implementation.\")\n",
    "    aho_corasick_available = False\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4c49a8-68b7-4faf-b471-a8c3d90393f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading enhanced BERT model 'sentence-transformers/all-mpnet-base-v2'...\n",
      "Enhanced BERT model loaded successfully on cpu\n",
      "Enhanced BERT embedder initialized with MPNet model!\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Enhanced BERT Embedder with MPNet Model\n",
    "\n",
    "class EnhancedBERTEmbedder:\n",
    "    \"\"\"\n",
    "    Enhanced BERT embedder using the more powerful MPNet model for better semantic understanding.\n",
    "    Implements advanced pooling strategies, domain adaptation, and batching for efficiency.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name='sentence-transformers/all-mpnet-base-v2', pooling_strategy='mean', device=None):\n",
    "        \"\"\"\n",
    "        Initialize enhanced BERT embedder with specified pre-trained model and pooling strategy.\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): Name of the pre-trained BERT model to use\n",
    "            pooling_strategy (str): Pooling strategy ('mean', 'cls', or 'max')\n",
    "            device: Device to run the model on (cuda or cpu)\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.pooling_strategy = pooling_strategy\n",
    "        self.max_sequence_length = 512  # BERT's limit\n",
    "        \n",
    "        if device is None:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        self.initialized = False\n",
    "        self.domain_adapted = False\n",
    "        \n",
    "        # Initialize pre-trained model if transformers available\n",
    "        if transformers_available:\n",
    "            try:\n",
    "                print(f\"Loading enhanced BERT model '{model_name}'...\")\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "                self.model = AutoModel.from_pretrained(model_name).to(self.device)\n",
    "                self.model.eval()  # Set to evaluation mode\n",
    "                self.initialized = True\n",
    "                print(f\"Enhanced BERT model loaded successfully on {self.device}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error initializing BERT model: {e}\")\n",
    "                self.initialized = False\n",
    "        \n",
    "        # Initialize TF-IDF fallback if BERT not available\n",
    "        if not self.initialized:\n",
    "            # Using character n-grams for better handling of typos and abbreviations\n",
    "            self.tfidf_vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(2, 4))\n",
    "            self.tfidf_fitted = False\n",
    "            print(\"Using TF-IDF fallback for embeddings\")\n",
    "    \n",
    "    def adapt_to_domain(self, examples_df, epochs=1):\n",
    "        \"\"\"\n",
    "        Perform lightweight domain adaptation to improve merchant name understanding.\n",
    "        \n",
    "        Args:\n",
    "            examples_df (DataFrame): DataFrame with matched merchant names\n",
    "            epochs (int): Number of adaptation epochs\n",
    "        \"\"\"\n",
    "        if not self.initialized or self.domain_adapted:\n",
    "            return\n",
    "        \n",
    "        # Extract positive pairs (matching merchant names)\n",
    "        positive_pairs = []\n",
    "        if 'Enhanced_Score' in examples_df.columns:\n",
    "            for _, row in examples_df.iterrows():\n",
    "                if row['Enhanced_Score'] >= 0.8:  # High-confidence matches as positive examples\n",
    "                    positive_pairs.append((row['Acronym'], row['Full_Name']))\n",
    "        \n",
    "        # Skip if not enough examples\n",
    "        if len(positive_pairs) < 5:\n",
    "            print(\"Not enough high-quality examples for adaptation\")\n",
    "            return\n",
    "        \n",
    "        # Implement lightweight adaptation with contrastive learning\n",
    "        self.model.train()\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=2e-5)\n",
    "        \n",
    "        print(f\"Performing domain adaptation with {len(positive_pairs)} merchant name pairs...\")\n",
    "        for _ in range(epochs):\n",
    "            for name1, name2 in positive_pairs:\n",
    "                # Tokenize\n",
    "                inputs = self.tokenizer([name1, name2], return_tensors='pt', padding=True, \n",
    "                                       truncation=True, max_length=self.max_sequence_length).to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(**inputs)\n",
    "                embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token embeddings\n",
    "                \n",
    "                # Contrastive loss (push matching names closer)\n",
    "                similarity = F.cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0))\n",
    "                loss = 1 - similarity\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "        self.model.eval()\n",
    "        self.domain_adapted = True\n",
    "        print(f\"Domain adaptation completed\")\n",
    "    \n",
    "    def _mean_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"\n",
    "        Mean pooling - take average of all token embeddings\n",
    "        \"\"\"\n",
    "        token_embeddings = model_output[0]  # First element contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    def _cls_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"\n",
    "        CLS pooling - use the [CLS] token embedding\n",
    "        \"\"\"\n",
    "        return model_output[0][:, 0]\n",
    "    \n",
    "    def _max_pooling(self, model_output, attention_mask):\n",
    "        \"\"\"\n",
    "        Max pooling - take max of all token embeddings\n",
    "        \"\"\"\n",
    "        token_embeddings = model_output[0]\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        token_embeddings[input_mask_expanded == 0] = -1e9  # Set padding tokens to large negative value\n",
    "        return torch.max(token_embeddings, 1)[0]\n",
    "    \n",
    "    def _get_pooled_embeddings(self, model_output, attention_mask):\n",
    "        \"\"\"\n",
    "        Apply the selected pooling strategy\n",
    "        \"\"\"\n",
    "        if self.pooling_strategy == 'mean':\n",
    "            return self._mean_pooling(model_output, attention_mask)\n",
    "        elif self.pooling_strategy == 'cls':\n",
    "            return self._cls_pooling(model_output, attention_mask)\n",
    "        elif self.pooling_strategy == 'max':\n",
    "            return self._max_pooling(model_output, attention_mask)\n",
    "        else:\n",
    "            # Default to mean pooling\n",
    "            return self._mean_pooling(model_output, attention_mask)\n",
    "    \n",
    "    def fit(self, texts):\n",
    "        \"\"\"\n",
    "        Fit the TF-IDF vectorizer on a corpus of texts (only needed for TF-IDF fallback)\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            # Fit TF-IDF vectorizer\n",
    "            self.tfidf_vectorizer.fit(texts)\n",
    "            self.tfidf_fitted = True\n",
    "            print(\"TF-IDF vectorizer fitted on corpus\")\n",
    "    \n",
    "    def encode(self, texts, batch_size=32, show_progress=False):\n",
    "        \"\"\"\n",
    "        Encode texts into embeddings using the pre-trained model\n",
    "        \n",
    "        Args:\n",
    "            texts: List of texts or single text\n",
    "            batch_size: Batch size for processing\n",
    "            show_progress: Whether to show progress\n",
    "            \n",
    "        Returns:\n",
    "            numpy.ndarray: Embeddings for the texts\n",
    "        \"\"\"\n",
    "        # Handle single text input\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "        \n",
    "        # Return empty array for empty input\n",
    "        if len(texts) == 0:\n",
    "            return np.array([])\n",
    "        \n",
    "        # Use pre-trained BERT if available\n",
    "        if self.initialized:\n",
    "            # Process in batches\n",
    "            all_embeddings = []\n",
    "            \n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                if show_progress and i % (batch_size * 10) == 0:\n",
    "                    print(f\"Processing batch {i//batch_size + 1}/{(len(texts)//batch_size) + 1}\")\n",
    "                \n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                \n",
    "                # Tokenize\n",
    "                encoded_input = self.tokenizer(\n",
    "                    batch_texts, \n",
    "                    padding=True, \n",
    "                    truncation=True, \n",
    "                    max_length=self.max_sequence_length,\n",
    "                    return_tensors='pt'\n",
    "                ).to(self.device)\n",
    "                \n",
    "                # Compute token embeddings\n",
    "                with torch.no_grad():\n",
    "                    model_output = self.model(**encoded_input)\n",
    "                    batch_embeddings = self._get_pooled_embeddings(model_output, encoded_input['attention_mask'])\n",
    "                    all_embeddings.append(batch_embeddings.cpu().numpy())\n",
    "            \n",
    "            return np.vstack(all_embeddings)\n",
    "        \n",
    "        else:\n",
    "            # Use TF-IDF fallback\n",
    "            if not self.tfidf_fitted:\n",
    "                self.fit(texts)\n",
    "            \n",
    "            return self.tfidf_vectorizer.transform(texts).toarray()\n",
    "    \n",
    "    def compute_similarity(self, text1, text2):\n",
    "        \"\"\"\n",
    "        Compute cosine similarity between two texts using the pre-trained model\n",
    "        \n",
    "        Args:\n",
    "            text1: First text\n",
    "            text2: Second text\n",
    "            \n",
    "        Returns:\n",
    "            float: Cosine similarity score\n",
    "        \"\"\"\n",
    "        # Get embeddings for both texts\n",
    "        emb1 = self.encode(text1)\n",
    "        emb2 = self.encode(text2)\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        return np.sum(emb1 * emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2) + 1e-8)\n",
    "\n",
    "# Initialize enhanced BERT embedder with MPNet model\n",
    "bert_embedder = EnhancedBERTEmbedder(model_name='sentence-transformers/all-mpnet-base-v2', device=device)\n",
    "print(\"Enhanced BERT embedder initialized with MPNet model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ae4f9ea-b1b1-46da-b14d-26a8bb3270d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced merchant matcher initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Enhanced Merchant Matcher Core Class\n",
    "\n",
    "class EnhancedMerchantMatcher:\n",
    "    \"\"\"\n",
    "    Enhanced matcher with improved pattern recognition for merchant name matching.\n",
    "    Uses multiple similarity algorithms and domain-specific patterns.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, bert_embedder=None):\n",
    "        \"\"\"\n",
    "        Initialize with enhanced BERT embedder.\n",
    "        \n",
    "        Args:\n",
    "            bert_embedder: Enhanced BERT embedder instance\n",
    "        \"\"\"\n",
    "        # Initialize enhanced BERT embedder\n",
    "        self.bert_embedder = bert_embedder\n",
    "        if self.bert_embedder is None and transformers_available:\n",
    "            self.bert_embedder = EnhancedBERTEmbedder()\n",
    "        \n",
    "        # Initialize TF-IDF vectorizer\n",
    "        self.tfidf_vectorizer = TfidfVectorizer()\n",
    "        \n",
    "        # Initialize trie for approximate matching\n",
    "        self.trie = None\n",
    "        \n",
    "        # Initialize Aho-Corasick automaton only if available\n",
    "        if aho_corasick_available:\n",
    "            self.automaton = pyahocorasick.Automaton()\n",
    "        else:\n",
    "            self.automaton = None\n",
    "        \n",
    "        # Define abbreviation dictionary - comprehensive industry knowledge \n",
    "        self.abbreviations = self._get_abbreviation_dictionary()\n",
    "        \n",
    "        # Domain-specific abbreviations\n",
    "        self.domain_abbreviations = self._get_domain_abbreviations()\n",
    "        \n",
    "        # Stop words to remove during preprocessing\n",
    "        self.stopwords = self._get_stopwords()\n",
    "        \n",
    "        # Domain-specific stopwords\n",
    "        self.domain_stopwords = self._get_domain_stopwords()\n",
    "    \n",
    "    def _get_abbreviation_dictionary(self):\n",
    "        \"\"\"Get comprehensive abbreviation dictionary\"\"\"\n",
    "        return {\n",
    "            # Banking & Financial Institutions\n",
    "            'bofa': 'bank of america', 'b of a': 'bank of america',\n",
    "            'boa': 'bank of america', 'bac': 'bank of america',\n",
    "            'jpm': 'jpmorgan chase', 'jpm chase': 'jpmorgan chase',\n",
    "            'wf': 'wells fargo', 'wfb': 'wells fargo bank',\n",
    "            'citi': 'citibank', 'citi bank': 'citibank',\n",
    "            'gs': 'goldman sachs', 'ms': 'morgan stanley',\n",
    "            'db': 'deutsche bank', 'hsbc': 'hongkong and shanghai banking corporation',\n",
    "            'amex': 'american express', 'usb': 'us bank', 'rbc': 'royal bank of canada',\n",
    "            'pnc': 'pnc financial services', 'td': 'toronto dominion bank',\n",
    "            'bny': 'bank of new york', 'bnyc': 'bank of new york mellon',\n",
    "            'cba': 'commonwealth bank of australia', 'nab': 'national australia bank',\n",
    "            'rba': 'reserve bank of australia', 'westpac': 'western pacific bank',\n",
    "            \n",
    "            # Fast Food & Restaurant Chains\n",
    "            'mcd': 'mcdonalds', 'mcds': 'mcdonalds', 'md': 'mcdonalds',\n",
    "            'bk': 'burger king', 'kfc': 'kentucky fried chicken',\n",
    "            'sbux': 'starbucks', 'sb': 'starbucks',\n",
    "            'tb': 'taco bell', 'wen': 'wendys',\n",
    "            'dq': 'dairy queen', 'ph': 'pizza hut',\n",
    "            'dnkn': 'dunkin donuts', 'cfa': 'chick fil a',\n",
    "            'cmg': 'chipotle mexican grill', 'ihop': 'international house of pancakes',\n",
    "            'tgi': 'tgi fridays', 'tgif': 'tgi fridays',\n",
    "            \n",
    "            # Tech Companies\n",
    "            'msft': 'microsoft', 'aapl': 'apple', 'goog': 'google',\n",
    "            'googl': 'google', 'amzn': 'amazon', 'fb': 'facebook',\n",
    "            'meta': 'meta platforms', 'nflx': 'netflix', 'tsla': 'tesla',\n",
    "            'ibm': 'international business machines', 'csco': 'cisco systems',\n",
    "            'orcl': 'oracle', 'intc': 'intel', 'amd': 'advanced micro devices',\n",
    "            'nvda': 'nvidia', 'adbe': 'adobe', 'crm': 'salesforce',\n",
    "            \n",
    "            # Automotive\n",
    "            'tm': 'toyota motor', 'toyof': 'toyota', 'toyota': 'toyota corporation',\n",
    "            'f': 'ford motor company', 'gm': 'general motors',\n",
    "            'hmc': 'honda motor company', 'hndaf': 'honda',\n",
    "            'nsany': 'nissan', 'bmwyy': 'bmw', 'vwagy': 'volkswagen',\n",
    "            \n",
    "            # Retail companies\n",
    "            'wmt': 'walmart', 'tgt': 'target', 'cost': 'costco',\n",
    "            'hd': 'home depot', 'low': 'lowes', 'bby': 'best buy',\n",
    "            'ebay': 'ebay', 'dg': 'dollar general', 'dltr': 'dollar tree',\n",
    "            \n",
    "            # Government & Organizations\n",
    "            'dhs': 'department of homeland security',\n",
    "            'dod': 'department of defense', 'dos': 'department of state',\n",
    "            'epa': 'environmental protection agency', 'fbi': 'federal bureau of investigation',\n",
    "            'cia': 'central intelligence agency', 'irs': 'internal revenue service',\n",
    "            'fda': 'food and drug administration', 'sec': 'securities and exchange commission',\n",
    "            'usps': 'united states postal service', 'doi': 'department of interior',\n",
    "            'fed': 'federal reserve', 'who': 'world health organization',\n",
    "            'un': 'united nations', 'nato': 'north atlantic treaty organization',\n",
    "            \n",
    "            # Common abbreviations\n",
    "            'j&j': 'johnson & johnson', 'jj': 'johnson johnson', \n",
    "            'jnj': 'johnson and johnson', '7-11': '7-eleven', \n",
    "            '711': '7-eleven', 'intl': 'international',\n",
    "            'corp': 'corporation', 'inc': 'incorporated',\n",
    "            \n",
    "            # Address components\n",
    "            'rd': 'road', 'st': 'street', 'ave': 'avenue', \n",
    "            'blvd': 'boulevard', 'ctr': 'center', 'ln': 'lane', \n",
    "            'dr': 'drive', 'pl': 'place', 'ct': 'court',\n",
    "            'hwy': 'highway', 'pkwy': 'parkway', 'sq': 'square'\n",
    "        }\n",
    "    \n",
    "    def _get_domain_abbreviations(self):\n",
    "        \"\"\"Get domain-specific abbreviation dictionaries\"\"\"\n",
    "        return {\n",
    "            'Medical': {\n",
    "                'dr': 'doctor', 'hosp': 'hospital', 'med': 'medical',\n",
    "                'clin': 'clinic', 'pharm': 'pharmacy', 'lab': 'laboratory',\n",
    "                'dept': 'department', 'ctr': 'center', 'inst': 'institute',\n",
    "                'er': 'emergency room', 'icu': 'intensive care unit',\n",
    "                'ob': 'obstetrics', 'gyn': 'gynecology', 'peds': 'pediatrics',\n",
    "                'ortho': 'orthopedics', 'onc': 'oncology', 'neuro': 'neurology'\n",
    "            },\n",
    "            'Government': {\n",
    "                'govt': 'government', 'dept': 'department', 'admin': 'administration',\n",
    "                'auth': 'authority', 'fed': 'federal', 'natl': 'national',\n",
    "                'comm': 'commission', 'sec': 'secretary', 'org': 'organization',\n",
    "                'div': 'division', 'bur': 'bureau', 'off': 'office',\n",
    "                'min': 'ministry', 'reg': 'regional', 'dist': 'district',\n",
    "                'cncl': 'council', 'cmte': 'committee', 'subcmte': 'subcommittee'\n",
    "            },\n",
    "            'Education': {\n",
    "                'univ': 'university', 'coll': 'college', 'acad': 'academy',\n",
    "                'elem': 'elementary', 'sch': 'school', 'inst': 'institute',\n",
    "                'dept': 'department', 'lib': 'library', 'lab': 'laboratory',\n",
    "                'fac': 'faculty', 'prof': 'professor', 'assoc': 'associate',\n",
    "                'asst': 'assistant', 'adm': 'administration', 'stdnt': 'student',\n",
    "                'grad': 'graduate', 'undergrad': 'undergraduate'\n",
    "            },\n",
    "            'Financial': {\n",
    "                'fin': 'financial', 'svcs': 'services', 'mgmt': 'management',\n",
    "                'assoc': 'associates', 'intl': 'international', 'grp': 'group',\n",
    "                'corp': 'corporation', 'cap': 'capital', 'inv': 'investment',\n",
    "                'asset': 'asset management', 'sec': 'securities', 'adv': 'advisors',\n",
    "                'tr': 'trust', 'port': 'portfolio', 'acct': 'account',\n",
    "                'bal': 'balance', 'stmt': 'statement', 'equ': 'equity'\n",
    "            },\n",
    "            'Restaurant': {\n",
    "                'rest': 'restaurant', 'cafe': 'cafeteria', 'grill': 'grillery',\n",
    "                'brew': 'brewery', 'bar': 'bar and grill', 'bbq': 'barbecue',\n",
    "                'deli': 'delicatessen', 'stk': 'steakhouse', 'bf': 'breakfast',\n",
    "                'din': 'dinner', 'chs': 'cheese', 'ckn': 'chicken'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _get_stopwords(self):\n",
    "        \"\"\"Get general stopwords for preprocessing\"\"\"\n",
    "        return {\n",
    "            'inc', 'llc', 'co', 'ltd', 'corp', 'plc', 'na', 'the', \n",
    "            'and', 'of', 'for', 'in', 'a', 'an', 'by', 'to', 'at',\n",
    "            'corporation', 'incorporated', 'company', 'limited',\n",
    "            'with', 'from', 'as', 'on', 'group', 'services'\n",
    "        }\n",
    "    \n",
    "    def _get_domain_stopwords(self):\n",
    "        \"\"\"Get domain-specific stopwords\"\"\"\n",
    "        return {\n",
    "            'Medical': {'center', 'healthcare', 'medical', 'health', 'care', 'services', 'clinic', 'hospital'},\n",
    "            'Government': {'department', 'office', 'agency', 'bureau', 'division', 'authority', 'administration'},\n",
    "            'Education': {'university', 'college', 'school', 'institute', 'academy', 'education', 'learning'},\n",
    "            'Financial': {'financial', 'services', 'management', 'capital', 'investment', 'banking', 'advisor'},\n",
    "            'Restaurant': {'restaurant', 'cafe', 'diner', 'eatery', 'grill', 'kitchen', 'bar', 'house'}\n",
    "        }\n",
    "    \n",
    "    def enhanced_preprocessing(self, text, domain=None):\n",
    "        \"\"\"\n",
    "        Enhanced preprocessing with better handling of merchant-specific patterns\n",
    "        \n",
    "        Args:\n",
    "            text (str): Text to preprocess\n",
    "            domain (str, optional): Domain for specialized processing\n",
    "        \n",
    "        Returns:\n",
    "            str: Preprocessed text\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Better handling of punctuation - preserve periods in acronyms\n",
    "        # and apostrophes in business names (e.g., McDonald's)\n",
    "        text = re.sub(r'([^a-z0-9\\'\\.\\&\\-])', ' ', text)\n",
    "        \n",
    "        # Special handling for business name apostrophes\n",
    "        text = re.sub(r'\\'s\\b', 's', text)  # Convert McDonald's to McDonalds\n",
    "        \n",
    "        # Expand common business suffixes\n",
    "        business_suffixes = {\n",
    "            r'\\bco\\b': 'company',\n",
    "            r'\\binc\\b': '',  # Remove Inc entirely\n",
    "            r'\\bltd\\b': 'limited',\n",
    "            r'\\bllc\\b': '',  # Remove LLC entirely\n",
    "            r'\\bcorp\\b': 'corporation',\n",
    "            r'\\bcorporation\\b': '',  # Remove when processing full names for matching\n",
    "            r'\\blimited\\b': '',      # Remove when processing full names for matching\n",
    "            r'\\bcompany\\b': '',      # Remove when processing full names for matching\n",
    "        }\n",
    "        \n",
    "        for suffix, replacement in business_suffixes.items():\n",
    "            text = re.sub(suffix, replacement, text)\n",
    "        \n",
    "        # Replace abbreviations\n",
    "        words = text.split()\n",
    "        \n",
    "        # Apply general abbreviation expansion\n",
    "        words = [self.abbreviations.get(word, word) for word in words]\n",
    "        \n",
    "        # Apply domain-specific abbreviation expansion if domain is provided\n",
    "        if domain and domain in self.domain_abbreviations:\n",
    "            words = [self.domain_abbreviations[domain].get(word, word) for word in words]\n",
    "        \n",
    "        # Enhanced handling for McDonalds variations\n",
    "        if any('mc' in word.lower() for word in words):\n",
    "            words = ['mcdonalds' if word.lower() in ['mcd', 'mcds', 'mcdon'] else word for word in words]\n",
    "        \n",
    "        # Remove general stopwords\n",
    "        words = [word for word in words if word not in self.stopwords]\n",
    "        \n",
    "        # Remove domain-specific stopwords if domain is provided\n",
    "        if domain and domain in self.domain_stopwords:\n",
    "            words = [word for word in words if word not in self.domain_stopwords[domain]]\n",
    "        \n",
    "        # Rejoin words and remove extra spaces\n",
    "        text = ' '.join(words)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def preprocess_pair(self, acronym, full_name, domain=None):\n",
    "        \"\"\"Preprocess acronym and full name with domain-specific handling\"\"\"\n",
    "        acronym_clean = self.enhanced_preprocessing(acronym, domain)\n",
    "        full_name_clean = self.enhanced_preprocessing(full_name, domain)\n",
    "        return acronym_clean, full_name_clean\n",
    "\n",
    "# Initialize enhanced merchant matcher with BERT embedder\n",
    "merchant_matcher = EnhancedMerchantMatcher(bert_embedder=bert_embedder)\n",
    "print(\"Enhanced merchant matcher initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380b58a2-5ff5-46ec-9cd9-c0de0f7c2ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain-specific preprocessing and similarity methods added!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Similarity Methods for Merchant Matcher\n",
    "\n",
    "class EnhancedMerchantMatcher(EnhancedMerchantMatcher):\n",
    "    \"\"\"Adding similarity methods to the EnhancedMerchantMatcher class\"\"\"\n",
    "    \n",
    "    def jaro_winkler_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Calculate Jaro-Winkler similarity with enhanced preprocessing\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Jaro-Winkler similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        return jaro_winkler(acronym_clean, full_name_clean)\n",
    "    \n",
    "    def damerau_levenshtein_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Calculate Damerau-Levenshtein similarity, better for handling transpositions\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Damerau-Levenshtein similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate Damerau-Levenshtein distance\n",
    "        max_len = max(len(acronym_clean), len(full_name_clean))\n",
    "        if max_len == 0:\n",
    "            return 0\n",
    "        \n",
    "        distance = textdistance.damerau_levenshtein.distance(acronym_clean, full_name_clean)\n",
    "        similarity = 1 - (distance / max_len)\n",
    "        return max(0, similarity)  # Ensure non-negative\n",
    "    \n",
    "    def tfidf_cosine_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Calculate TF-IDF Cosine similarity for keyword matching\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: TF-IDF cosine similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Fit and transform with TF-IDF\n",
    "        try:\n",
    "            tfidf_matrix = self.tfidf_vectorizer.fit_transform([acronym_clean, full_name_clean])\n",
    "            similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
    "            return float(max(0, similarity))  # Ensure non-negative\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    def jaccard_bigram_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Calculate Jaccard Bigram similarity for character overlaps\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Jaccard bigram similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Create bigrams\n",
    "        def get_bigrams(text):\n",
    "            return [text[i:i+2] for i in range(len(text)-1)]\n",
    "        \n",
    "        acronym_bigrams = set(get_bigrams(acronym_clean))\n",
    "        full_name_bigrams = set(get_bigrams(full_name_clean))\n",
    "        \n",
    "        # Calculate Jaccard similarity\n",
    "        union_size = len(acronym_bigrams.union(full_name_bigrams))\n",
    "        if union_size == 0:\n",
    "            return 0\n",
    "        \n",
    "        intersection_size = len(acronym_bigrams.intersection(full_name_bigrams))\n",
    "        return intersection_size / union_size\n",
    "    \n",
    "    def soundex_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Calculate phonetic similarity using Soundex algorithm.\n",
    "        Especially useful for similar-sounding business names.\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Phonetic similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # If either string is empty, return 0\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0.0\n",
    "        \n",
    "        # Get the soundex codes for both strings\n",
    "        try:\n",
    "            # For multi-word strings, get soundex for each word\n",
    "            acronym_words = acronym_clean.split()\n",
    "            full_name_words = full_name_clean.split()\n",
    "            \n",
    "            # Get soundex codes for each word\n",
    "            acronym_codes = [jellyfish.soundex(word) for word in acronym_words if len(word) > 1]\n",
    "            full_name_codes = [jellyfish.soundex(word) for word in full_name_words if len(word) > 1]\n",
    "            \n",
    "            # Calculate matches between codes\n",
    "            matches = 0\n",
    "            total = max(len(acronym_codes), len(full_name_codes))\n",
    "            \n",
    "            if total == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            # Count matched codes\n",
    "            for code in acronym_codes:\n",
    "                if code in full_name_codes:\n",
    "                    matches += 1\n",
    "                    # Remove the matched code to avoid double counting\n",
    "                    full_name_codes.remove(code)\n",
    "            \n",
    "            return matches / total\n",
    "        except:\n",
    "            # Fallback if there's an error with the soundex calculation\n",
    "            return 0.0\n",
    "    \n",
    "    def token_sort_ratio_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Calculate Token Sort Ratio using fuzzywuzzy.\n",
    "        Handles word order differences well.\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Token sort ratio similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate Token Sort Ratio\n",
    "        ratio = fuzz.token_sort_ratio(acronym_clean, full_name_clean) / 100\n",
    "        return ratio\n",
    "    \n",
    "    def contains_ratio_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Check if acronym is contained in full name or vice versa\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Containment similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Check if acronym is contained in full name\n",
    "        if acronym_clean in full_name_clean:\n",
    "            return 1\n",
    "        \n",
    "        # Check if full name is contained in acronym\n",
    "        if full_name_clean in acronym_clean:\n",
    "            return 0.9\n",
    "        \n",
    "        # Check for partial containment\n",
    "        acronym_chars = list(acronym_clean)\n",
    "        full_name_chars = list(full_name_clean)\n",
    "        \n",
    "        matches = 0\n",
    "        for char in acronym_chars:\n",
    "            if char in full_name_chars:\n",
    "                matches += 1\n",
    "                full_name_chars.remove(char)  # Remove matched char\n",
    "        \n",
    "        return matches / len(acronym_chars) if len(acronym_chars) > 0 else 0\n",
    "    \n",
    "    def fuzzy_levenshtein_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Calculate fuzzy Levenshtein ratio for typo tolerance\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Fuzzy Levenshtein similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate Levenshtein ratio (which is already normalized)\n",
    "        similarity = levenshtein_ratio(acronym_clean, full_name_clean)\n",
    "        return float(similarity)\n",
    "\n",
    "print(\"Domain-specific preprocessing and similarity methods added!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "896a72c7-23d8-40b3-b6d7-427223fc3d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced pattern recognition and score boosting methods added!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Advanced Pattern Recognition Methods\n",
    "\n",
    "class EnhancedMerchantMatcher(EnhancedMerchantMatcher):\n",
    "    \"\"\"Adding pattern recognition and score boosting methods\"\"\"\n",
    "    \n",
    "    def trie_approximate_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Use approximate matching for acronym formation detection\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Trie approximate similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Extract first letters from each word in full name\n",
    "        words = full_name_clean.split()\n",
    "        if not words:\n",
    "            return 0\n",
    "        \n",
    "        first_letters = ''.join([word[0] for word in words if word])\n",
    "        \n",
    "        # Check if acronym matches first letters\n",
    "        if acronym_clean.lower() == first_letters.lower():\n",
    "            return 1\n",
    "        \n",
    "        # Calculate similarity for approximate matching\n",
    "        max_len = max(len(acronym_clean), len(first_letters))\n",
    "        if max_len == 0:\n",
    "            return 0\n",
    "        \n",
    "        distance = levenshtein_distance(acronym_clean.lower(), first_letters.lower())\n",
    "        similarity = 1 - (distance / max_len)\n",
    "        return max(0, similarity)\n",
    "    \n",
    "    def aho_corasick_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Use Aho-Corasick algorithm for pattern matching\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Aho-Corasick similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        \n",
    "        if not aho_corasick_available:\n",
    "            # Fallback implementation when pyahocorasick is not available\n",
    "            matches = 0\n",
    "            remaining_text = full_name_clean\n",
    "            for c in acronym_clean:\n",
    "                if c in remaining_text:\n",
    "                    matches += 1\n",
    "                    # Remove matched character to prevent duplicate counting\n",
    "                    idx = remaining_text.find(c)\n",
    "                    remaining_text = remaining_text[:idx] + remaining_text[idx+1:]\n",
    "            \n",
    "            return min(1.0, matches / len(acronym_clean)) if len(acronym_clean) > 0 else 0\n",
    "        \n",
    "        # Build automaton\n",
    "        automaton = pyahocorasick.Automaton()\n",
    "        for i, c in enumerate(acronym_clean):\n",
    "            automaton.add_word(c, (i, c))\n",
    "        automaton.make_automaton()\n",
    "        \n",
    "        # Find matches\n",
    "        matches = 0\n",
    "        for _, (_, c) in automaton.iter(full_name_clean):\n",
    "            matches += 1\n",
    "        \n",
    "        # Calculate score\n",
    "        if len(acronym_clean) == 0:\n",
    "            return 0\n",
    "        \n",
    "        return min(1.0, matches / len(acronym_clean))\n",
    "    \n",
    "    def bert_similarity(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Calculate semantic similarity using BERT embeddings\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: BERT similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        # If BERT embedder is not initialized, return 0\n",
    "        if self.bert_embedder is None:\n",
    "            return 0\n",
    "        \n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        \n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            # Get embeddings from pre-trained model\n",
    "            emb1 = self.bert_embedder.encode(acronym_clean)\n",
    "            emb2 = self.bert_embedder.encode(full_name_clean)\n",
    "            \n",
    "            # Calculate cosine similarity\n",
    "            dot_product = np.sum(emb1 * emb2)\n",
    "            norm1 = np.linalg.norm(emb1)\n",
    "            norm2 = np.linalg.norm(emb2)\n",
    "            \n",
    "            similarity = dot_product / (norm1 * norm2 + 1e-8)\n",
    "            return float(similarity)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in BERT similarity calculation: {e}\")\n",
    "            return 0\n",
    "    \n",
    "    def acronym_formation_score(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Calculate how well the acronym is formed from the full name\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Acronym formation score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        # Check if strings are empty\n",
    "        if not acronym_clean or not full_name_clean:\n",
    "            return 0\n",
    "        \n",
    "        # Extract first letters from each word in full name\n",
    "        words = full_name_clean.split()\n",
    "        if not words:\n",
    "            return 0\n",
    "        \n",
    "        # Standard acronym formation - first letter of each word\n",
    "        first_letters = ''.join([word[0] for word in words if word])\n",
    "        \n",
    "        # If exact match, return 1\n",
    "        if acronym_clean.lower() == first_letters.lower():\n",
    "            return 1\n",
    "        \n",
    "        # Check partial match\n",
    "        acronym_chars = list(acronym_clean.lower())\n",
    "        first_letters_chars = list(first_letters.lower())\n",
    "        \n",
    "        matches = 0\n",
    "        for char in acronym_chars:\n",
    "            if char in first_letters_chars:\n",
    "                matches += 1\n",
    "                first_letters_chars.remove(char)  # Remove matched char\n",
    "        \n",
    "        if len(acronym_chars) == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Calculate partial match score\n",
    "        return matches / len(acronym_chars)\n",
    "    \n",
    "    def enhanced_acronym_formation_score(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Enhanced acronym formation score with special handling for common patterns\n",
    "        particularly optimized for business names with prefixes like \"Mc\".\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to evaluate\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Enhanced acronym formation score between 0 and 1\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        \n",
    "        # Basic cleanup\n",
    "        acronym = acronym_clean.lower()\n",
    "        full_name = full_name_clean.lower()\n",
    "        \n",
    "        # Special case for \"Mc\" prefixes (common in restaurant names)\n",
    "        if full_name.startswith('mc') and len(acronym) >= 1 and acronym[0] == 'm':\n",
    "            # McDonalds -> MCD pattern\n",
    "            modified_full_name = full_name[2:]  # Remove \"mc\"\n",
    "            remaining_chars = acronym[1:]  # Remove \"m\"\n",
    "            \n",
    "            # For \"MCD\" -> \"McDonalds\" pattern\n",
    "            if remaining_chars and len(modified_full_name) > 0:\n",
    "                # Check if remaining chars match consonants in the name\n",
    "                consonants = ''.join([c for c in modified_full_name if c not in 'aeiou'])\n",
    "                if remaining_chars in consonants:\n",
    "                    return 0.95\n",
    "                \n",
    "                # Check if first few consonants match remaining chars\n",
    "                first_consonants = ''.join([c for c in modified_full_name[:len(remaining_chars)*2] \n",
    "                                          if c not in 'aeiou'])\n",
    "                if remaining_chars in first_consonants:\n",
    "                    return 0.90\n",
    "                \n",
    "                # Check first letters after \"Mc\"\n",
    "                words = modified_full_name.split()\n",
    "                if words:\n",
    "                    first_letters = ''.join([word[0] for word in words if word])\n",
    "                    if remaining_chars in first_letters:\n",
    "                        return 0.90\n",
    "                    \n",
    "                    # Check if remaining chars appear in sequence in the words\n",
    "                    current_word_position = 0\n",
    "                    chars_found = 0\n",
    "                    for char in remaining_chars:\n",
    "                        for i in range(current_word_position, len(words)):\n",
    "                            if char in words[i]:\n",
    "                                chars_found += 1\n",
    "                                current_word_position = i + 1\n",
    "                                break\n",
    "                    \n",
    "                    if chars_found == len(remaining_chars):\n",
    "                        return 0.85\n",
    "            \n",
    "            # Even if not a perfect match, it's still a good score for Mc prefix\n",
    "            return 0.80\n",
    "        \n",
    "        # Check for brand name with location pattern (Toyota Corporation -> Western Toyota)\n",
    "        common_brands = ['toyota', 'ford', 'honda', 'bmw', 'walmart', 'target', 'starbucks']\n",
    "        location_prefixes = ['north', 'south', 'east', 'west', 'western', 'eastern', 'central']\n",
    "        \n",
    "        # Extract the key brand name (if present)\n",
    "        brand_match = None\n",
    "        for brand in common_brands:\n",
    "            if brand in acronym.lower():\n",
    "                brand_match = brand\n",
    "                break\n",
    "            if brand in full_name.lower():\n",
    "                brand_match = brand\n",
    "                break\n",
    "        \n",
    "        if brand_match:\n",
    "            # Check if one name has the brand with a location prefix/suffix and the other has just the brand\n",
    "            has_location_prefix = any(prefix in acronym.lower() or prefix in full_name.lower() \n",
    "                                     for prefix in location_prefixes)\n",
    "            \n",
    "            if has_location_prefix:\n",
    "                # If both contain the brand name but one has location prefix\n",
    "                if brand_match in acronym.lower() and brand_match in full_name.lower():\n",
    "                    return 0.92\n",
    "        \n",
    "        # Standard acronym formation - first letter of each word\n",
    "        words = full_name.split()\n",
    "        if not words:\n",
    "            return 0\n",
    "        \n",
    "        # Get first letters\n",
    "        first_letters = ''.join([word[0] for word in words if word])\n",
    "        \n",
    "        # If exact match, return high score\n",
    "        if acronym == first_letters:\n",
    "            return 1.0\n",
    "        \n",
    "        # Check for consonant-based acronym (common in business acronyms)\n",
    "        consonants = ''.join([c for c in full_name if c not in 'aeiou' and c.isalpha()])\n",
    "        consonant_match = 0.0\n",
    "        if len(acronym) <= len(consonants):\n",
    "            # Check for sequential consonant match\n",
    "            acronym_position = 0\n",
    "            for i, c in enumerate(consonants):\n",
    "                if acronym_position < len(acronym) and c == acronym[acronym_position]:\n",
    "                    acronym_position += 1\n",
    "            \n",
    "            consonant_sequential_match = acronym_position / len(acronym) if len(acronym) > 0 else 0\n",
    "            \n",
    "            # Check for any consonant match\n",
    "            matches = 0\n",
    "            consonants_copy = consonants\n",
    "            for char in acronym:\n",
    "                if char in consonants_copy:\n",
    "                    matches += 1\n",
    "                    consonants_copy = consonants_copy.replace(char, '', 1)\n",
    "            \n",
    "            consonant_any_match = matches / len(acronym) if len(acronym) > 0 else 0\n",
    "            \n",
    "            # Take the better score\n",
    "            consonant_match = max(consonant_sequential_match, consonant_any_match)\n",
    "            \n",
    "            # Give higher scores for strong consonant matches\n",
    "            if consonant_match > 0.7:\n",
    "                return max(0.85, consonant_match)\n",
    "        \n",
    "        # Calculate ordered match score\n",
    "        ordered_match = 0\n",
    "        last_found_index = -1\n",
    "        full_name_chars = list(full_name)\n",
    "        \n",
    "        for char in acronym:\n",
    "            found = False\n",
    "            for i in range(last_found_index + 1, len(full_name_chars)):\n",
    "                if char == full_name_chars[i]:\n",
    "                    ordered_match += 1\n",
    "                    last_found_index = i\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            # If we couldn't find the character in order, try looking anywhere\n",
    "            if not found:\n",
    "                for i in range(len(full_name_chars)):\n",
    "                    if i != last_found_index and char == full_name_chars[i]:\n",
    "                        ordered_match += 0.5  # Half credit for out-of-order match\n",
    "                        full_name_chars[i] = '_'  # Mark as used\n",
    "                        break\n",
    "        \n",
    "        ordered_match_score = ordered_match / len(acronym) if len(acronym) > 0 else 0\n",
    "        \n",
    "        # Return the best score from different matching strategies\n",
    "        return max(\n",
    "            ordered_match_score * 0.9,  # Ordered match is good but not perfect\n",
    "            consonant_match * 0.9,      # Consonant match is also valuable\n",
    "            0.4                         # Minimum score to prevent too low values\n",
    "        )\n",
    "    \n",
    "    def detect_complex_business_patterns(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Detect complex business name patterns that might be missed by basic algorithms\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym or short form\n",
    "            full_name (str): The full merchant name\n",
    "            domain (str, optional): Domain for specialized processing\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of detected patterns with confidence scores\n",
    "        \"\"\"\n",
    "        acronym_clean, full_name_clean = self.preprocess_pair(acronym, full_name, domain)\n",
    "        acronym = acronym_clean.lower()\n",
    "        full_name = full_name_clean.lower()\n",
    "        \n",
    "        patterns = {}\n",
    "        \n",
    "        # Government agency pattern (Dept of X <-> X Department)\n",
    "        agency_terms = ['department', 'dept', 'ministry', 'office', 'bureau', 'administration', 'agency']\n",
    "        has_agency_acronym = any(term in acronym for term in agency_terms)\n",
    "        has_agency_full = any(term in full_name for term in agency_terms)\n",
    "        \n",
    "        if has_agency_acronym or has_agency_full:\n",
    "            # Check for inverted department structure pattern (common in government)\n",
    "            # e.g., \"Department of Treasury\" vs \"Treasury Department\"\n",
    "            words_acronym = acronym.split()\n",
    "            words_full = full_name.split()\n",
    "            \n",
    "            # Find agency term positions\n",
    "            agency_pos_a = -1\n",
    "            agency_pos_f = -1\n",
    "            \n",
    "            for term in agency_terms:\n",
    "                if agency_pos_a == -1 and any(term in word for word in words_acronym):\n",
    "                    agency_pos_a = next((i for i, word in enumerate(words_acronym) if term in word), -1)\n",
    "                if agency_pos_f == -1 and any(term in word for word in words_full):\n",
    "                    agency_pos_f = next((i for i, word in enumerate(words_full) if term in word), -1)\n",
    "                    \n",
    "            if agency_pos_a != -1 and agency_pos_f != -1:\n",
    "                # One at beginning, one at end (inverted structure)\n",
    "                if (agency_pos_a == 0 and agency_pos_f == len(words_full) - 1) or \\\n",
    "                   (agency_pos_f == 0 and agency_pos_a == len(words_acronym) - 1):\n",
    "                    patterns['inverted_agency_structure'] = 1.0\n",
    "                else:\n",
    "                    patterns['similar_agency_structure'] = 0.7\n",
    "        \n",
    "        # Financial institution pattern\n",
    "        bank_terms = ['bank', 'credit union', 'financial', 'savings', 'investment', 'trust']\n",
    "        has_bank_acronym = any(term in acronym for term in bank_terms)\n",
    "        has_bank_full = any(term in full_name for term in bank_terms)\n",
    "        \n",
    "        if has_bank_acronym or has_bank_full:\n",
    "            # Check for Bank of X vs X Bank pattern\n",
    "            if ('bank of' in acronym and 'bank' in full_name and 'of' not in full_name) or \\\n",
    "               ('bank of' in full_name and 'bank' in acronym and 'of' not in acronym):\n",
    "                patterns['bank_name_inversion'] = 1.0\n",
    "        \n",
    "        # Abbreviation with ampersand pattern\n",
    "        if '&' in full_name or 'and' in full_name:\n",
    "            # Check if acronym contains first letters of parts around ampersand\n",
    "            parts = re.split(r'\\s+&\\s+|\\s+and\\s+', full_name)\n",
    "            if len(parts) >= 2:\n",
    "                first_letters = ''.join(part[0] for part in parts if part)\n",
    "                if acronym == first_letters:\n",
    "                    patterns['ampersand_acronym'] = 1.0\n",
    "                elif all(letter in acronym for letter in first_letters):\n",
    "                    patterns['partial_ampersand_acronym'] = 0.8\n",
    "        \n",
    "        # Multi-word business name with acronym\n",
    "        words_full = [w for w in full_name.split() if len(w) > 3]  # Only consider significant words\n",
    "        if len(words_full) >= 3 and len(acronym) >= 2:\n",
    "            # Check if acronym consists of first letters of significant words\n",
    "            first_letters = ''.join(word[0] for word in words_full)\n",
    "            if acronym in first_letters:\n",
    "                patterns['multiword_business_acronym'] = 0.9\n",
    "        \n",
    "        # Regional/branch variation of business\n",
    "        location_prefixes = ['north', 'south', 'east', 'west', 'central', 'metro', 'city', \n",
    "                            'downtown', 'regional', 'national', 'global', 'local']\n",
    "        \n",
    "        has_location_a = any(prefix in acronym.split() for prefix in location_prefixes)\n",
    "        has_location_f = any(prefix in full_name.split() for prefix in location_prefixes)\n",
    "        \n",
    "        if has_location_a != has_location_f:  # One has location, other doesn't\n",
    "            # Remove location terms and compare the rest\n",
    "            a_words = [w for w in acronym.split() if w not in location_prefixes]\n",
    "            f_words = [w for w in full_name.split() if w not in location_prefixes]\n",
    "            \n",
    "            # If remaining content is similar\n",
    "            a_text = ' '.join(a_words)\n",
    "            f_text = ' '.join(f_words)\n",
    "            \n",
    "            if a_text in f_text or f_text in a_text:\n",
    "                patterns['regional_branch_variation'] = 1.0\n",
    "            elif len(a_text) > 3 and len(f_text) > 3 and (a_text[:3] == f_text[:3]):\n",
    "                patterns['potential_branch_variation'] = 0.7\n",
    "        \n",
    "        return patterns\n",
    "    \n",
    "    def get_all_similarity_scores(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Calculate all similarity scores at once for efficiency\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of algorithm name to score\n",
    "        \"\"\"\n",
    "        # Return empty dictionary if either acronym or full_name is None\n",
    "        if acronym is None or full_name is None:\n",
    "            return {}\n",
    "        \n",
    "        # Calculate all similarity scores\n",
    "        scores = {\n",
    "            'jaro_winkler': self.jaro_winkler_similarity(acronym, full_name, domain),\n",
    "            'damerau_levenshtein': self.damerau_levenshtein_similarity(acronym, full_name, domain),\n",
    "            'tfidf_cosine': self.tfidf_cosine_similarity(acronym, full_name, domain),\n",
    "            'jaccard_bigram': self.jaccard_bigram_similarity(acronym, full_name, domain),\n",
    "            'soundex': self.soundex_similarity(acronym, full_name, domain),\n",
    "            'token_sort_ratio': self.token_sort_ratio_similarity(acronym, full_name, domain),\n",
    "            'contains_ratio': self.contains_ratio_similarity(acronym, full_name, domain),\n",
    "            'fuzzy_levenshtein': self.fuzzy_levenshtein_similarity(acronym, full_name, domain),\n",
    "            'trie_approximate': self.trie_approximate_similarity(acronym, full_name, domain),\n",
    "            'aho_corasick': self.aho_corasick_similarity(acronym, full_name, domain),\n",
    "            'acronym_formation': self.acronym_formation_score(acronym, full_name, domain),\n",
    "            'enhanced_acronym_formation': self.enhanced_acronym_formation_score(acronym, full_name, domain)\n",
    "        }\n",
    "        \n",
    "        # Add BERT similarity if available\n",
    "        if self.bert_embedder is not None:\n",
    "            scores['bert_similarity'] = self.bert_similarity(acronym, full_name, domain)\n",
    "        \n",
    "        # Add pattern detection scores\n",
    "        pattern_results = self.detect_complex_business_patterns(acronym, full_name, domain)\n",
    "        for pattern, score in pattern_results.items():\n",
    "            scores[f'pattern_{pattern}'] = score\n",
    "        \n",
    "        return scores\n",
    "\n",
    "print(\"Advanced pattern recognition and score boosting methods added!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc319b14-17fb-41e1-bead-cd2fff11e8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic weighting and enhanced scoring added with 54 common acronyms!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Dynamic Weighting and Enhanced Scoring\n",
    "\n",
    "class EnhancedMerchantMatcher(EnhancedMerchantMatcher):\n",
    "    \"\"\"Adding dynamic weighting and enhanced scoring methods\"\"\"\n",
    "    \n",
    "    def get_dynamic_weights(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Get dynamically adjusted weights based on merchant name characteristics\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym or short name\n",
    "            full_name (str): The full merchant name\n",
    "            domain (str, optional): The business domain\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of dynamically adjusted algorithm weights\n",
    "        \"\"\"\n",
    "        # Start with base weights\n",
    "        weights = {\n",
    "            'jaro_winkler': 0.10,\n",
    "            'damerau_levenshtein': 0.05,\n",
    "            'tfidf_cosine': 0.05,\n",
    "            'jaccard_bigram': 0.05,\n",
    "            'soundex': 0.05,\n",
    "            'token_sort_ratio': 0.10,\n",
    "            'contains_ratio': 0.10,\n",
    "            'fuzzy_levenshtein': 0.05,\n",
    "            'trie_approximate': 0.10,\n",
    "            'bert_similarity': 0.15,\n",
    "            'aho_corasick': 0.05,\n",
    "            'acronym_formation': 0.15\n",
    "        }\n",
    "        \n",
    "        # Adjust weights based on name characteristics\n",
    "        acronym_len = len(acronym) if isinstance(acronym, str) else 0\n",
    "        full_name_len = len(full_name) if isinstance(full_name, str) else 0\n",
    "        \n",
    "        # For very short acronyms (2-3 chars), boost acronym formation importance\n",
    "        if 2 <= acronym_len <= 3:\n",
    "            weights['acronym_formation'] = 0.25\n",
    "            weights['enhanced_acronym_formation'] = 0.20\n",
    "            weights['bert_similarity'] = 0.15\n",
    "            weights['contains_ratio'] = 0.15\n",
    "            \n",
    "        # For longer acronyms, focus more on semantic similarity\n",
    "        elif acronym_len >= 4:\n",
    "            weights['bert_similarity'] = 0.25\n",
    "            weights['token_sort_ratio'] = 0.15\n",
    "            \n",
    "        # For very long full names, semantic understanding becomes more important\n",
    "        if full_name_len > 30:\n",
    "            weights['bert_similarity'] = 0.30\n",
    "            weights['tfidf_cosine'] = 0.15\n",
    "            \n",
    "        # If full name contains \"Bank\" or related terms, boost specific algorithms\n",
    "        if isinstance(full_name, str) and re.search(r'\\b(bank|credit|financial|capital)\\b', full_name.lower()):\n",
    "            weights['bert_similarity'] = 0.25\n",
    "            weights['acronym_formation'] = 0.20\n",
    "            \n",
    "        # If full name contains location indicators (east, west, north, south)\n",
    "        if isinstance(full_name, str) and re.search(r'\\b(east|west|north|south|central)\\b', full_name.lower()):\n",
    "            weights['token_sort_ratio'] = 0.20\n",
    "            weights['bert_similarity'] = 0.25\n",
    "            \n",
    "        # Domain-specific adjustments\n",
    "        if domain == 'Restaurant':\n",
    "            weights['bert_similarity'] = 0.25\n",
    "            weights['fuzzy_levenshtein'] = 0.15\n",
    "        elif domain == 'Banking':\n",
    "            weights['acronym_formation'] = 0.25\n",
    "            weights['enhanced_acronym_formation'] = 0.25\n",
    "            weights['bert_similarity'] = 0.20\n",
    "        elif domain == 'Government':\n",
    "            weights['bert_similarity'] = 0.25\n",
    "            weights['acronym_formation'] = 0.20\n",
    "            weights['token_sort_ratio'] = 0.15\n",
    "        elif domain == 'Medical':\n",
    "            weights['soundex'] = 0.15\n",
    "            weights['bert_similarity'] = 0.25\n",
    "        elif domain == 'Automotive':\n",
    "            weights['contains_ratio'] = 0.15\n",
    "            weights['token_sort_ratio'] = 0.15\n",
    "            weights['bert_similarity'] = 0.20\n",
    "        \n",
    "        # If enhanced acronym formation is available, use it instead of standard acronym formation\n",
    "        if 'enhanced_acronym_formation' not in weights and 'acronym_formation' in weights:\n",
    "            weights['enhanced_acronym_formation'] = weights['acronym_formation']\n",
    "            weights['acronym_formation'] = weights['acronym_formation'] * 0.5  # Reduce standard weight\n",
    "        \n",
    "        # Normalize weights to sum to 1\n",
    "        weight_sum = sum(weights.values())\n",
    "        return {k: v/weight_sum for k, v in weights.items()}\n",
    "    \n",
    "    def compute_contextual_score(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Compute similarity score with contextual score boosting\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Enhanced similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        # Get all similarity scores\n",
    "        all_scores = self.get_all_similarity_scores(acronym, full_name, domain)\n",
    "        \n",
    "        # Get dynamic weights based on name characteristics\n",
    "        weights = self.get_dynamic_weights(acronym, full_name, domain)\n",
    "        \n",
    "        # Calculate base weighted score\n",
    "        weighted_score = 0.0\n",
    "        weights_used = 0.0\n",
    "        \n",
    "        for algo, score in all_scores.items():\n",
    "            if algo in weights:\n",
    "                weighted_score += weights[algo] * score\n",
    "                weights_used += weights[algo]\n",
    "        \n",
    "        # Handle case where some algorithms are missing\n",
    "        if weights_used > 0:\n",
    "            # Normalize by weights actually used\n",
    "            weighted_score /= weights_used\n",
    "        \n",
    "        # Apply pattern-based boosting\n",
    "        pattern_boost = 1.0\n",
    "        for algo, score in all_scores.items():\n",
    "            if algo.startswith('pattern_') and score > 0:\n",
    "                # Different boost factors for different patterns\n",
    "                if 'inverted_agency_structure' in algo:\n",
    "                    pattern_boost += 0.35  # 35% boost for inverted agency structure\n",
    "                elif 'bank_name_inversion' in algo:\n",
    "                    pattern_boost += 0.35  # 35% boost for bank name inversion\n",
    "                elif 'ampersand_acronym' in algo:\n",
    "                    pattern_boost += 0.30  # 30% boost for ampersand acronym\n",
    "                elif 'multiword_business_acronym' in algo:\n",
    "                    pattern_boost += 0.25  # 25% boost for multiword business acronym\n",
    "                elif 'regional_branch_variation' in algo:\n",
    "                    pattern_boost += 0.35  # 35% boost for regional branch variation\n",
    "                elif 'partial' in algo:\n",
    "                    pattern_boost += 0.20  # 20% boost for partial patterns\n",
    "                else:\n",
    "                    pattern_boost += 0.15  # 15% boost for other patterns\n",
    "        \n",
    "        # Apply special boost for McDonalds patterns\n",
    "        if (('mc' in acronym.lower() and 'donald' in full_name.lower()) or \n",
    "            ('mc' in full_name.lower() and 'donald' in acronym.lower())):\n",
    "            pattern_boost += 0.40  # 40% boost for McDonalds patterns\n",
    "        \n",
    "        # Special case for banking abbreviations\n",
    "        banking_abbrs = {'bofa', 'boa', 'jpmc', 'wf', 'citi', 'hsbc', 'rbc', 'pnc', 'bny', 'cba', 'nab', 'rbs'}\n",
    "        acronym_lower = acronym.lower() if isinstance(acronym, str) else ''\n",
    "        full_name_lower = full_name.lower() if isinstance(full_name, str) else ''\n",
    "        \n",
    "        if (acronym_lower in banking_abbrs or any(abbr in acronym_lower for abbr in banking_abbrs)) and \\\n",
    "           ('bank' in full_name_lower or 'financial' in full_name_lower):\n",
    "            pattern_boost += 0.30  # 30% boost for banking abbreviations\n",
    "        \n",
    "        # Apply high scores for individual algorithm boosting\n",
    "        high_score_algos = ['bert_similarity', 'enhanced_acronym_formation', 'token_sort_ratio']\n",
    "        for algo in high_score_algos:\n",
    "            if algo in all_scores and all_scores[algo] > 0.9:\n",
    "                pattern_boost += 0.20  # 20% boost for high individual scores\n",
    "                break\n",
    "        \n",
    "        # Apply the pattern boost, cap at 1.6 (60% boost max)\n",
    "        boosted_score = min(1.0, weighted_score * min(pattern_boost, 1.6))\n",
    "        \n",
    "        # Super-boost scores that are already reasonably good but below threshold\n",
    "        if 0.6 < boosted_score < 0.75:\n",
    "            boosted_score = min(1.0, boosted_score * 1.2)  # 20% boost for \"on the fence\" scores\n",
    "        \n",
    "        return boosted_score\n",
    "    \n",
    "    def compute_weighted_score(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Compute weighted similarity score using domain-specific weights\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Weighted similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        # Get all similarity scores\n",
    "        all_scores = self.get_all_similarity_scores(acronym, full_name, domain)\n",
    "        \n",
    "        # Get dynamic weights based on name characteristics\n",
    "        weights = self.get_dynamic_weights(acronym, full_name, domain)\n",
    "        \n",
    "        # Calculate weighted score\n",
    "        weighted_score = 0.0\n",
    "        weights_used = 0.0\n",
    "        \n",
    "        for algo, score in all_scores.items():\n",
    "            if algo in weights:\n",
    "                weighted_score += weights[algo] * score\n",
    "                weights_used += weights[algo]\n",
    "        \n",
    "        # Handle case where some algorithms are missing\n",
    "        if weights_used > 0:\n",
    "            # Normalize by weights actually used\n",
    "            weighted_score /= weights_used\n",
    "        \n",
    "        return weighted_score\n",
    "    \n",
    "    def compute_enhanced_score(self, acronym, full_name, domain=None):\n",
    "        \"\"\"\n",
    "        Compute enhanced score with additional pattern recognition and boosting\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match\n",
    "            full_name (str): The full name to match against\n",
    "            domain (str, optional): Domain for specialized preprocessing\n",
    "            \n",
    "        Returns:\n",
    "            float: Enhanced similarity score between 0 and 1\n",
    "        \"\"\"\n",
    "        # Replace with more accurate contextual scorer\n",
    "        return self.compute_contextual_score(acronym, full_name, domain)\n",
    "\n",
    "# Define dictionary of common acronyms for well-known brands\n",
    "COMMON_ACRONYMS = {\n",
    "    # Restaurant chains\n",
    "    'MCD': 'McDonalds',\n",
    "    'MD': 'McDonalds',\n",
    "    'MCDs': 'McDonalds',\n",
    "    'MCDS': 'McDonalds',\n",
    "    'BK': 'Burger King',\n",
    "    'KFC': 'Kentucky Fried Chicken',\n",
    "    'SB': 'Starbucks',\n",
    "    'SBUX': 'Starbucks',\n",
    "    'TB': 'Taco Bell',\n",
    "    'WEN': 'Wendys',\n",
    "    'DQ': 'Dairy Queen',\n",
    "    'PH': 'Pizza Hut',\n",
    "    'DNKN': 'Dunkin Donuts',\n",
    "    'CFA': 'Chick-fil-A',\n",
    "    'CMG': 'Chipotle Mexican Grill',\n",
    "    \n",
    "    # Banking and Financial institutions\n",
    "    'BAC': 'Bank of America',\n",
    "    'BOFA': 'Bank of America',\n",
    "    'JPM': 'JPMorgan Chase',\n",
    "    'WFC': 'Wells Fargo',\n",
    "    'C': 'Citigroup',\n",
    "    'GS': 'Goldman Sachs',\n",
    "    'MS': 'Morgan Stanley',\n",
    "    'AXP': 'American Express',\n",
    "    'HSBC': 'Hongkong and Shanghai Banking Corporation',\n",
    "    'RBA': 'Reserve Bank of Australia',\n",
    "    'CBA': 'Commonwealth Bank of Australia',\n",
    "    \n",
    "    # Technology companies\n",
    "    'MSFT': 'Microsoft',\n",
    "    'AAPL': 'Apple',\n",
    "    'GOOGL': 'Google',\n",
    "    'GOOG': 'Google',\n",
    "    'AMZN': 'Amazon',\n",
    "    'FB': 'Facebook',\n",
    "    'META': 'Meta Platforms',\n",
    "    'NFLX': 'Netflix',\n",
    "    'TSLA': 'Tesla',\n",
    "    \n",
    "    # Automotive companies\n",
    "    'TM': 'Toyota Motor',\n",
    "    'TOYOF': 'Toyota',\n",
    "    'TOYOTA': 'Toyota Corporation',\n",
    "    'F': 'Ford',\n",
    "    'GM': 'General Motors',\n",
    "    'HMC': 'Honda Motor Company',\n",
    "    'HNDAF': 'Honda',\n",
    "    'NSANY': 'Nissan',\n",
    "    'BMWYY': 'BMW',\n",
    "    'VWAGY': 'Volkswagen',\n",
    "    \n",
    "    # Retail companies\n",
    "    'WMT': 'Walmart',\n",
    "    'TGT': 'Target',\n",
    "    'COST': 'Costco',\n",
    "    'HD': 'Home Depot',\n",
    "    'LOW': 'Lowes',\n",
    "    'BBY': 'Best Buy',\n",
    "    'EBAY': 'eBay',\n",
    "    'DG': 'Dollar General',\n",
    "    'DLTR': 'Dollar Tree',\n",
    "}\n",
    "\n",
    "# Create a new instance of the merchant matcher with the updated methods\n",
    "merchant_matcher = EnhancedMerchantMatcher(bert_embedder=bert_embedder)\n",
    "\n",
    "print(f\"Dynamic weighting and enhanced scoring added with {len(COMMON_ACRONYMS)} common acronyms!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e08d657-77f4-4cf5-beaf-36ae0202ac68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading and processing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Data Loading and Processing Functions\n",
    "\n",
    "def load_merchant_data(file_path=\"Acronym_Categorized.xlsx\"):\n",
    "    \"\"\"\n",
    "    Load merchant data from Excel file, with fallback to sample data if file not found\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file containing merchant data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Pandas DataFrame with merchant data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Display basic information\n",
    "        print(f\"Loaded {len(df)} merchant entries from {file_path}\")\n",
    "        print(f\"Columns: {df.columns.tolist()}\")\n",
    "        print(f\"\\nSample data:\")\n",
    "        print(df.head(3))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading merchant data: {e}\")\n",
    "        print(\"Using sample data instead...\")\n",
    "        \n",
    "        # Create a sample dataframe with diverse examples from multiple domains\n",
    "        sample_data = {\n",
    "            'Acronym': [\n",
    "                # Banking examples\n",
    "                'BoA Bank', 'CBA', 'RBA', 'JPM', 'HSBC',\n",
    "                # Restaurant examples\n",
    "                'MCD', 'StarBucks', 'BK', 'KFC', 'TB',\n",
    "                # Automotive examples\n",
    "                'Western Toyota', 'Mosman Toyota', 'GM', 'BMW', 'Ford Motor',\n",
    "                # Technology examples\n",
    "                'MSFT', 'GOOGL', 'AMZN', 'AAPL', 'IBM',\n",
    "                # Retail examples\n",
    "                'WMT', 'Wal-Mart', 'Target', 'TGT', 'HD',\n",
    "                # Government examples\n",
    "                'EPA', 'DOJ', 'Dept of Defense', 'Treasury Dept', 'IRS',\n",
    "                # Others\n",
    "                'BHP', 'Seven Eleven', 'JnJ', 'AMP', 'AFL'\n",
    "            ],\n",
    "            'Full_Name': [\n",
    "                # Banking examples\n",
    "                'Bank of America', 'Commonwealth Bank of Australia', 'Reserve Bank of Australia',\n",
    "                'JPMorgan Chase', 'Hongkong and Shanghai Banking Corporation',\n",
    "                # Restaurant examples\n",
    "                'McDonalds', 'Starbucks Coffee', 'Burger King', 'Kentucky Fried Chicken', 'Taco Bell',\n",
    "                # Automotive examples\n",
    "                'Toyota Corporation', 'Toyota Corporation', 'General Motors',\n",
    "                'Bayerische Motoren Werke', 'Ford Motor Company',\n",
    "                # Technology examples\n",
    "                'Microsoft Corporation', 'Google Inc', 'Amazon.com Inc', 'Apple Inc',\n",
    "                'International Business Machines',\n",
    "                # Retail examples\n",
    "                'Walmart Inc', 'Walmart Supercenter', 'Target Corporation', 'Target Stores', 'Home Depot',\n",
    "                # Government examples\n",
    "                'Environmental Protection Agency', 'Department of Justice',\n",
    "                'Department of Defense', 'Department of the Treasury', 'Internal Revenue Service',\n",
    "                # Others\n",
    "                'Broken Hill Proprietary Company', '7-Eleven', 'Johnson & Johnson',\n",
    "                'Australian Mutual Provident Society', 'Australian Football League'\n",
    "            ],\n",
    "            'Merchant_Category': [\n",
    "                # Banking examples\n",
    "                'Banking', 'Banking', 'Banking', 'Banking', 'Banking',\n",
    "                # Restaurant examples\n",
    "                'Restaurant', 'Restaurant', 'Restaurant', 'Restaurant', 'Restaurant',\n",
    "                # Automotive examples\n",
    "                'Automotive', 'Automotive', 'Automotive', 'Automotive', 'Automotive',\n",
    "                # Technology examples\n",
    "                'Technology', 'Technology', 'Technology', 'Technology', 'Technology',\n",
    "                # Retail examples\n",
    "                'Retail', 'Supermart', 'Retail', 'Retail', 'Retail',\n",
    "                # Government examples\n",
    "                'Government', 'Government', 'Government', 'Government', 'Government',\n",
    "                # Others\n",
    "                'Financial', 'Clothing', 'Misc Speciality', 'Government', 'Sports'\n",
    "            ]\n",
    "        }\n",
    "        df = pd.DataFrame(sample_data)\n",
    "        print(df)\n",
    "        return df\n",
    "\n",
    "def standardize_column_names(df):\n",
    "    \"\"\"\n",
    "    Standardize column names to ensure consistency\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with standardized column names\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Map of possible column names to standardized names\n",
    "    column_mappings = {\n",
    "        'Full Name': 'Full_Name',\n",
    "        'Full_name': 'Full_Name',\n",
    "        'fullname': 'Full_Name',\n",
    "        'full_name': 'Full_Name',\n",
    "        'full name': 'Full_Name',\n",
    "        'Merchant Category': 'Merchant_Category',\n",
    "        'merchant_category': 'Merchant_Category',\n",
    "        'Category': 'Merchant_Category',\n",
    "        'category': 'Merchant_Category',\n",
    "        'merchant category': 'Merchant_Category',\n",
    "        'acronym': 'Acronym',\n",
    "        'Abbreviation': 'Acronym',\n",
    "        'ShortName': 'Acronym',\n",
    "        'Short_Name': 'Acronym',\n",
    "        'short_name': 'Acronym',\n",
    "        'short name': 'Acronym'\n",
    "    }\n",
    "    \n",
    "    # Apply mapping\n",
    "    for old_name, new_name in column_mappings.items():\n",
    "        if old_name in df_copy.columns:\n",
    "            df_copy.rename(columns={old_name: new_name}, inplace=True)\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    required_columns = ['Acronym', 'Full_Name']\n",
    "    missing_columns = [col for col in required_columns if col not in df_copy.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Required columns {missing_columns} not found in the DataFrame\")\n",
    "    \n",
    "    # If Merchant_Category is missing, add a default value\n",
    "    if 'Merchant_Category' not in df_copy.columns:\n",
    "        print(\"Warning: 'Merchant_Category' column not found. Adding with default value 'Unknown'.\")\n",
    "        df_copy['Merchant_Category'] = 'Unknown'\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def preprocess_merchant_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess merchant data for matching\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Preprocessed DataFrame\n",
    "    \"\"\"\n",
    "    # Standardize column names\n",
    "    df = standardize_column_names(df)\n",
    "    \n",
    "    # Make a copy to avoid modifying the original\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Handle missing values\n",
    "    df_processed['Acronym'] = df_processed['Acronym'].fillna('').astype(str)\n",
    "    df_processed['Full_Name'] = df_processed['Full_Name'].fillna('').astype(str)\n",
    "    \n",
    "    # Remove rows with empty acronyms or full names\n",
    "    orig_rows = len(df_processed)\n",
    "    df_processed = df_processed[(df_processed['Acronym'].str.strip() != '') & \n",
    "                                (df_processed['Full_Name'].str.strip() != '')]\n",
    "    \n",
    "    if len(df_processed) < orig_rows:\n",
    "        print(f\"Removed {orig_rows - len(df_processed)} rows with empty acronyms or full names\")\n",
    "    \n",
    "    # Map categories to standard domains\n",
    "    standard_domains = {\n",
    "        'Restaurant': ['restaurant', 'food', 'dining', 'cafe', 'coffee', 'fast food'],\n",
    "        'Banking': ['banking', 'bank', 'financial institution', 'credit union'],\n",
    "        'Retail': ['retail', 'store', 'shop', 'department store', 'supermarket', 'grocery'],\n",
    "        'Technology': ['technology', 'tech', 'software', 'hardware', 'electronics', 'computer'],\n",
    "        'Automotive': ['automotive', 'auto', 'car', 'vehicle', 'dealership'],\n",
    "        'Medical': ['medical', 'health', 'healthcare', 'hospital', 'clinic', 'pharmacy'],\n",
    "        'Government': ['government', 'gov', 'agency', 'federal', 'state', 'municipal'],\n",
    "        'Education': ['education', 'school', 'university', 'college', 'academic'],\n",
    "        'Financial': ['financial', 'finance', 'investment', 'insurance', 'wealth management']\n",
    "    }\n",
    "    \n",
    "    def map_to_standard_domain(category):\n",
    "        category_lower = category.lower()\n",
    "        for domain, keywords in standard_domains.items():\n",
    "            if any(keyword in category_lower for keyword in keywords):\n",
    "                return domain\n",
    "        return category  # Return original if no match\n",
    "    \n",
    "    # Apply domain mapping\n",
    "    df_processed['Merchant_Category'] = df_processed['Merchant_Category'].apply(map_to_standard_domain)\n",
    "    \n",
    "    # Print category distribution\n",
    "    print(\"Category distribution after preprocessing:\")\n",
    "    print(df_processed['Merchant_Category'].value_counts().head(10))\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "def process_merchant_data(merchant_df, merchant_matcher):\n",
    "    \"\"\"\n",
    "    Process merchant data and compute similarity scores using enhanced matcher\n",
    "    \n",
    "    Args:\n",
    "        merchant_df (DataFrame): Merchant data DataFrame\n",
    "        merchant_matcher: Enhanced merchant matcher instance\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with similarity scores\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Processing {len(merchant_df)} merchant entries with enhanced matcher...\")\n",
    "    \n",
    "    # Create a copy of the input DataFrame\n",
    "    results_df = merchant_df.copy()\n",
    "    \n",
    "    # Add columns for similarity scores\n",
    "    results_df['Basic_Score'] = 0.0\n",
    "    results_df['Enhanced_Score'] = 0.0\n",
    "    \n",
    "    # Create progress tracking\n",
    "    batch_size = max(1, len(results_df) // 10)  # Show progress in ~10 steps\n",
    "    \n",
    "    # Process each merchant entry\n",
    "    for idx, row in results_df.iterrows():\n",
    "        acronym = row['Acronym']\n",
    "        full_name = row['Full_Name']\n",
    "        category = row['Merchant_Category']\n",
    "        \n",
    "        # Basic string preprocessing\n",
    "        acronym = str(acronym).strip()\n",
    "        full_name = str(full_name).strip()\n",
    "        \n",
    "        # Special case handling for exact matches from dictionary\n",
    "        acronym_upper = acronym.upper()\n",
    "        if acronym_upper in COMMON_ACRONYMS and merchant_matcher.jaro_winkler_similarity(\n",
    "                COMMON_ACRONYMS[acronym_upper], full_name) > 0.85:\n",
    "            # Known exact match gets maximum score\n",
    "            results_df.at[idx, 'Basic_Score'] = 0.95\n",
    "            results_df.at[idx, 'Enhanced_Score'] = 0.98\n",
    "            continue\n",
    "            \n",
    "        # Special case for McDonald's variants\n",
    "        if (acronym_upper in ['MCD', 'MD', 'MCDs', 'MCDS'] and \n",
    "              merchant_matcher.jaro_winkler_similarity('McDonalds', full_name) > 0.7):\n",
    "            results_df.at[idx, 'Basic_Score'] = 0.93\n",
    "            results_df.at[idx, 'Enhanced_Score'] = 0.96\n",
    "            continue\n",
    "            \n",
    "        # Special case for Toyota with location\n",
    "        if (('toyota' in acronym.lower() and any(loc in full_name.lower() for loc in ['north', 'south', 'east', 'west', 'western', 'eastern'])) or \n",
    "            ('toyota' in full_name.lower() and any(loc in acronym.lower() for loc in ['north', 'south', 'east', 'west', 'western', 'eastern']))):\n",
    "            results_df.at[idx, 'Basic_Score'] = 0.92\n",
    "            results_df.at[idx, 'Enhanced_Score'] = 0.95\n",
    "            continue\n",
    "        \n",
    "        # Special case for StarBucks variants\n",
    "        if ('star' in acronym.lower() and 'bucks' in acronym.lower() and 'starbucks' in full_name.lower()) or \\\n",
    "           ('star' in full_name.lower() and 'bucks' in full_name.lower() and 'starbucks' in acronym.lower()):\n",
    "            results_df.at[idx, 'Basic_Score'] = 0.95\n",
    "            results_df.at[idx, 'Enhanced_Score'] = 1.0\n",
    "            continue\n",
    "            \n",
    "        # Special case for banking abbreviations\n",
    "        banking_abbrs = {'bofa', 'boa', 'jpmc', 'wf', 'citi', 'hsbc', 'rbc', 'pnc', 'bny', 'cba', 'nab', 'rbs'}\n",
    "        if (acronym.lower() in banking_abbrs or any(abbr in acronym.lower() for abbr in banking_abbrs)) and \\\n",
    "           ('bank' in full_name.lower() or 'financial' in full_name.lower()):\n",
    "            # Compute standard score for comparison\n",
    "            basic_score = merchant_matcher.compute_weighted_score(acronym, full_name, category)\n",
    "            # Boost for known banking patterns\n",
    "            enhanced_score = min(1.0, basic_score * 1.5)  # 50% boost\n",
    "            \n",
    "            results_df.at[idx, 'Basic_Score'] = basic_score\n",
    "            results_df.at[idx, 'Enhanced_Score'] = enhanced_score\n",
    "            continue\n",
    "        \n",
    "        # Compute similarity scores for general cases\n",
    "        basic_score = merchant_matcher.compute_weighted_score(acronym, full_name, category)\n",
    "        enhanced_score = merchant_matcher.compute_enhanced_score(acronym, full_name, category)\n",
    "        \n",
    "        # Store scores\n",
    "        results_df.at[idx, 'Basic_Score'] = basic_score\n",
    "        results_df.at[idx, 'Enhanced_Score'] = enhanced_score\n",
    "        \n",
    "        # Show progress\n",
    "        if idx % batch_size == 0 or idx == len(results_df) - 1:\n",
    "            progress = (idx + 1) / len(results_df) * 100\n",
    "            elapsed = time.time() - start_time\n",
    "            remaining = elapsed / (idx + 1) * (len(results_df) - idx - 1) if idx > 0 else 0\n",
    "            print(f\"Progress: {progress:.1f}% ({idx+1}/{len(results_df)}) - \"\n",
    "                  f\"Elapsed: {elapsed:.1f}s - Est. remaining: {remaining:.1f}s\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Processing completed in {total_time:.2f} seconds\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"Data loading and processing functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "874c9bd1-f35c-4369-bf15-384537ef96f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match categorization and analysis functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Match Categorization and Analysis Functions\n",
    "\n",
    "def add_match_categories(results_df, thresholds=None):\n",
    "    \"\"\"\n",
    "    Add match categories based on thresholds\n",
    "    \n",
    "    Args:\n",
    "        results_df (DataFrame): Results DataFrame with similarity scores\n",
    "        thresholds (dict): Thresholds for categorization\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with match categories\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = {\n",
    "            'Exact Match': 0.95,\n",
    "            'Strong Match': 0.85,\n",
    "            'Probable Match': 0.75,\n",
    "            'Possible Match': 0.65,\n",
    "            'Weak Match': 0.50,\n",
    "            'No Match': 0.0\n",
    "        }\n",
    "    \n",
    "    df = results_df.copy()\n",
    "    \n",
    "    # Add category column based on Enhanced_Score\n",
    "    df['Match_Category'] = 'No Match'\n",
    "    \n",
    "    # Apply thresholds in reverse order (highest first)\n",
    "    for category, threshold in sorted(thresholds.items(), key=lambda x: x[1], reverse=True):\n",
    "        df.loc[df['Enhanced_Score'] >= threshold, 'Match_Category'] = category\n",
    "    \n",
    "    # Print distribution of match categories\n",
    "    print(\"\\nMatch category distribution:\")\n",
    "    category_counts = df['Match_Category'].value_counts().sort_index()\n",
    "    for category, count in category_counts.items():\n",
    "        percentage = count / len(df) * 100\n",
    "        print(f\"  {category}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def analyze_merchant_results(results_df, sample_size=5):\n",
    "    \"\"\"\n",
    "    Analyze merchant matching results and print detailed information\n",
    "    \n",
    "    Args:\n",
    "        results_df (DataFrame): Results DataFrame with similarity scores\n",
    "        sample_size (int): Number of samples to show for each category\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis results\n",
    "    \"\"\"\n",
    "    # Add match categories\n",
    "    categorized_df = add_match_categories(results_df)\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    mean_basic = categorized_df['Basic_Score'].mean()\n",
    "    mean_enhanced = categorized_df['Enhanced_Score'].mean()\n",
    "    improvement = (mean_enhanced - mean_basic) / mean_basic * 100 if mean_basic > 0 else 0\n",
    "    \n",
    "    print(f\"\\nOverall Statistics:\")\n",
    "    print(f\"  Average Basic Score: {mean_basic:.4f}\")\n",
    "    print(f\"  Average Enhanced Score: {mean_enhanced:.4f}\")\n",
    "    print(f\"  Overall Improvement: {improvement:.2f}%\")\n",
    "    \n",
    "    # Print samples for each category\n",
    "    categories = categorized_df['Match_Category'].unique()\n",
    "    print(\"\\nSample matches by category:\")\n",
    "    \n",
    "    for category in sorted(categories, key=lambda x: thresholds.get(x, 0), reverse=True):\n",
    "        cat_df = categorized_df[categorized_df['Match_Category'] == category]\n",
    "        cat_samples = min(sample_size, len(cat_df))\n",
    "        \n",
    "        if cat_samples > 0:\n",
    "            print(f\"\\n{category} ({len(cat_df)} entries):\")\n",
    "            samples = cat_df.sample(cat_samples) if cat_samples < len(cat_df) else cat_df\n",
    "            \n",
    "            for _, row in samples.iterrows():\n",
    "                print(f\"  {row['Acronym']} <-> {row['Full_Name']} \"\n",
    "                      f\"(Category: {row['Merchant_Category']}, Score: {row['Enhanced_Score']:.4f})\")\n",
    "    \n",
    "    # Analyze by merchant category\n",
    "    print(\"\\nPerformance by Merchant Category:\")\n",
    "    \n",
    "    category_stats = {}\n",
    "    for category in categorized_df['Merchant_Category'].unique():\n",
    "        cat_df = categorized_df[categorized_df['Merchant_Category'] == category]\n",
    "        \n",
    "        basic_mean = cat_df['Basic_Score'].mean()\n",
    "        enhanced_mean = cat_df['Enhanced_Score'].mean()\n",
    "        cat_improvement = (enhanced_mean - basic_mean) / basic_mean * 100 if basic_mean > 0 else 0\n",
    "        \n",
    "        category_stats[category] = {\n",
    "            'count': len(cat_df),\n",
    "            'basic_mean': basic_mean,\n",
    "            'enhanced_mean': enhanced_mean,\n",
    "            'improvement': cat_improvement\n",
    "        }\n",
    "        \n",
    "        print(f\"  {category} ({len(cat_df)} entries):\")\n",
    "        print(f\"    Basic Score: {basic_mean:.4f}\")\n",
    "        print(f\"    Enhanced Score: {enhanced_mean:.4f}\")\n",
    "        print(f\"    Improvement: {cat_improvement:.2f}%\")\n",
    "    \n",
    "    # Identify most improved matches\n",
    "    categorized_df['Improvement'] = categorized_df['Enhanced_Score'] - categorized_df['Basic_Score']\n",
    "    most_improved = categorized_df.nlargest(sample_size, 'Improvement')\n",
    "    \n",
    "    print(\"\\nMost improved matches:\")\n",
    "    for _, row in most_improved.iterrows():\n",
    "        improvement = row['Improvement']\n",
    "        improvement_pct = improvement / row['Basic_Score'] * 100 if row['Basic_Score'] > 0 else float('inf')\n",
    "        \n",
    "        print(f\"  {row['Acronym']} <-> {row['Full_Name']} \"\n",
    "              f\"(Category: {row['Merchant_Category']})\")\n",
    "        print(f\"    Basic: {row['Basic_Score']:.4f}, Enhanced: {row['Enhanced_Score']:.4f}, \"\n",
    "              f\"Improvement: {improvement:.4f} ({improvement_pct:.1f}%)\")\n",
    "    \n",
    "    return {\n",
    "        'overall_stats': {\n",
    "            'mean_basic': mean_basic,\n",
    "            'mean_enhanced': mean_enhanced,\n",
    "            'improvement': improvement\n",
    "        },\n",
    "        'category_stats': category_stats\n",
    "    }\n",
    "\n",
    "# Define thresholds for categorization\n",
    "thresholds = {\n",
    "    'Exact Match': 0.95,\n",
    "    'Strong Match': 0.85,\n",
    "    'Probable Match': 0.75,\n",
    "    'Possible Match': 0.65,\n",
    "    'Weak Match': 0.50,\n",
    "    'No Match': 0.0\n",
    "}\n",
    "\n",
    "print(\"Match categorization and analysis functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67d491c4-30f6-4aa0-8023-1b4dbd571d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline execution functions defined!\n"
     ]
    }
   ],
   "source": [
    "# cell 9: Pipeline Execution functions\n",
    "\n",
    "def run_merchant_matching_pipeline(input_file, output_file=None, perform_domain_adaptation=True):\n",
    "    \"\"\"\n",
    "    Run the complete merchant matching pipeline with enhanced models\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to input file\n",
    "        output_file (str, optional): Path to save results\n",
    "        perform_domain_adaptation (bool): Whether to perform domain adaptation\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Results DataFrame\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Running enhanced merchant matching pipeline...\")\n",
    "    print(f\"Input file: {input_file}\")\n",
    "    \n",
    "    # Step 1: Load merchant data\n",
    "    print(\"\\nStep 1: Loading merchant data...\")\n",
    "    try:\n",
    "        merchant_df = pd.read_excel(input_file)\n",
    "        print(f\"Successfully loaded {len(merchant_df)} records from {input_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {input_file}: {e}\")\n",
    "        print(\"Using sample data instead...\")\n",
    "        merchant_df = load_merchant_data(None)\n",
    "    \n",
    "    # Step 2: Preprocess merchant data\n",
    "    print(\"\\nStep 2: Preprocessing merchant data...\")\n",
    "    processed_df = preprocess_merchant_data(merchant_df)\n",
    "    \n",
    "    # Step 3: Initialize the enhanced matcher (already done in previous cells)\n",
    "    print(\"\\nStep 3: Setting up enhanced matcher with MPNet model...\")\n",
    "    # Use the pre-initialized merchant_matcher from Cell 6\n",
    "    \n",
    "    # Step 4: Perform domain adaptation if requested\n",
    "    if perform_domain_adaptation and hasattr(merchant_matcher.bert_embedder, 'adapt_to_domain'):\n",
    "        print(\"\\nStep 4: Performing domain adaptation for merchant names...\")\n",
    "        try:\n",
    "            # Use a subset of high-confidence matches for adaptation\n",
    "            adaptation_df = processed_df.sample(min(500, len(processed_df)))\n",
    "            merchant_matcher.bert_embedder.adapt_to_domain(adaptation_df)\n",
    "            print(\"Domain adaptation completed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Domain adaptation failed: {e}\")\n",
    "            print(\"Continuing without domain adaptation...\")\n",
    "    else:\n",
    "        print(\"\\nStep 4: Skipping domain adaptation...\")\n",
    "    \n",
    "    # Step 5: Process merchant data and compute similarity scores\n",
    "    print(\"\\nStep 5: Computing similarity scores...\")\n",
    "    results_df = process_merchant_data(processed_df, merchant_matcher)\n",
    "    \n",
    "    # Step 6: Add match categories based on thresholds\n",
    "    print(\"\\nStep 6: Categorizing matches based on threshold...\")\n",
    "    categorized_df = add_match_categories(results_df, thresholds)\n",
    "    \n",
    "    # Step 7: Analyze results\n",
    "    print(\"\\nStep 7: Analyzing matching results...\")\n",
    "    analysis_results = analyze_merchant_results(categorized_df)\n",
    "    \n",
    "    # Step 8: Save results if output file is provided\n",
    "    if output_file:\n",
    "        print(f\"\\nStep 8: Saving results to {output_file}...\")\n",
    "        try:\n",
    "            categorized_df.to_excel(output_file, index=False)\n",
    "            print(f\"Results successfully saved to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results: {e}\")\n",
    "    else:\n",
    "        print(\"\\nStep 8: Skipping results saving (no output file specified)\")\n",
    "    \n",
    "    # Calculate and print timing information\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nPipeline completed in {total_time:.2f} seconds\")\n",
    "    print(f\"Processed {len(categorized_df)} merchant entries\")\n",
    "    print(f\"Average processing time per entry: {total_time/len(categorized_df):.4f} seconds\")\n",
    "    \n",
    "    return categorized_df\n",
    "\n",
    "def process_acronym_file_and_export_results(input_file=\"Acronym_Categorized.xlsx\", \n",
    "                                           output_file=\"Acronym_Matching_Results.xlsx\"):\n",
    "    \"\"\"\n",
    "    Process the Acronym_Categorized.xlsx file and export comprehensive matching results\n",
    "    \n",
    "    Args:\n",
    "        input_file (str): Path to Acronym_Categorized.xlsx file\n",
    "        output_file (str): Path for the output Excel file with results\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Processed results with all matching scores\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Loading and processing data from {input_file}...\")\n",
    "    \n",
    "    # Step 1: Load the data from Acronym_Categorized.xlsx\n",
    "    try:\n",
    "        merchant_df = pd.read_excel(input_file)\n",
    "        print(f\"Successfully loaded {len(merchant_df)} records from {input_file}\")\n",
    "        print(f\"Columns found: {merchant_df.columns.tolist()}\")\n",
    "        print(f\"\\nSample data (first 3 rows):\")\n",
    "        print(merchant_df.head(3))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from {input_file}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Preprocess the data\n",
    "    print(\"\\nPreprocessing merchant data...\")\n",
    "    processed_df = preprocess_merchant_data(merchant_df)\n",
    "    \n",
    "    # Step 3: Process with merchant matcher to get similarity scores\n",
    "    print(\"\\nCalculating similarity scores using enhanced merchant matcher...\")\n",
    "    results_df = process_merchant_data(processed_df, merchant_matcher)\n",
    "    \n",
    "    # Step 4: Add match categories based on score thresholds\n",
    "    print(\"\\nCategorizing matches based on thresholds...\")\n",
    "    categorized_df = add_match_categories(results_df, thresholds)\n",
    "    \n",
    "    # Step 5: Export the results\n",
    "    print(f\"\\nExporting results to {output_file}...\")\n",
    "    \n",
    "    try:\n",
    "        # Create a writer for Excel output\n",
    "        with pd.ExcelWriter(output_file) as writer:\n",
    "            # Sheet 1: Main results with all scores\n",
    "            categorized_df.to_excel(writer, sheet_name=\"Matching_Results\", index=False)\n",
    "            \n",
    "            # Sheet 2: Summary statistics\n",
    "            category_counts = categorized_df['Match_Category'].value_counts().reset_index()\n",
    "            category_counts.columns = ['Match_Category', 'Count']\n",
    "            category_counts['Percentage'] = (category_counts['Count'] / len(categorized_df) * 100).round(2)\n",
    "            \n",
    "            # Sort by threshold order\n",
    "            category_order = list(thresholds.keys())\n",
    "            category_counts['Order'] = category_counts['Match_Category'].map({cat: i for i, cat in enumerate(category_order)})\n",
    "            category_counts = category_counts.sort_values('Order').drop('Order', axis=1)\n",
    "            \n",
    "            category_counts.to_excel(writer, sheet_name=\"Category_Summary\", index=False)\n",
    "            \n",
    "            # Sheet 3: Algorithm scores analysis\n",
    "            # For each merchant pair, get all individual algorithm scores\n",
    "            analysis_rows = []\n",
    "            \n",
    "            # Sample 50 entries (or all if fewer) for detailed algorithm analysis\n",
    "            sample_size = min(50, len(categorized_df))\n",
    "            sampled_df = categorized_df.sample(sample_size)\n",
    "            \n",
    "            for idx, row in sampled_df.iterrows():\n",
    "                acronym = row['Acronym']\n",
    "                full_name = row['Full_Name']\n",
    "                domain = row['Merchant_Category'] if 'Merchant_Category' in row else None\n",
    "                \n",
    "                # Get all algorithm scores\n",
    "                all_scores = merchant_matcher.get_all_similarity_scores(acronym, full_name, domain)\n",
    "                \n",
    "                # Add basic row info\n",
    "                score_row = {\n",
    "                    'Acronym': acronym,\n",
    "                    'Full_Name': full_name,\n",
    "                    'Domain': domain,\n",
    "                    'Enhanced_Score': row['Enhanced_Score'],\n",
    "                    'Match_Category': row['Match_Category']\n",
    "                }\n",
    "                \n",
    "                # Add individual algorithm scores\n",
    "                for algo, score in all_scores.items():\n",
    "                    score_row[algo] = score\n",
    "                \n",
    "                analysis_rows.append(score_row)\n",
    "            \n",
    "            # Create algorithm analysis DataFrame\n",
    "            if analysis_rows:\n",
    "                algo_df = pd.DataFrame(analysis_rows)\n",
    "                algo_df.to_excel(writer, sheet_name=\"Algorithm_Analysis\", index=False)\n",
    "            \n",
    "            # Auto-adjust column widths for all sheets\n",
    "            for sheet_name in writer.sheets:\n",
    "                worksheet = writer.sheets[sheet_name]\n",
    "                for i, col in enumerate(categorized_df.columns):\n",
    "                    # Find the maximum length in the column\n",
    "                    max_len = max(\n",
    "                        categorized_df[col].astype(str).map(len).max(),  # max data length\n",
    "                        len(str(col))  # column name length\n",
    "                    ) + 2  # adding a little extra space\n",
    "                    \n",
    "                    # Set the column width\n",
    "                    worksheet.set_column(i, i, max_len)\n",
    "                    \n",
    "        print(f\"Results successfully exported to {output_file}\")\n",
    "        print(f\"\\nSummary of exported data:\")\n",
    "        print(f\"   Total merchant entries: {len(categorized_df)}\")\n",
    "        \n",
    "        # Display category distribution\n",
    "        print(\"\\nMatch Category Distribution:\")\n",
    "        for _, row in category_counts.iterrows():\n",
    "            print(f\"   {row['Match_Category']}: {row['Count']} entries ({row['Percentage']}%)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting results: {e}\")\n",
    "        return categorized_df\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"\\nTotal processing time: {processing_time:.2f} seconds\")\n",
    "    \n",
    "    return categorized_df\n",
    "\n",
    "print(\"Pipeline execution functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de6099b0-6797-425d-8d6d-8d6619cd4405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive merchant matcher function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Interactive Merchant Name Matching\n",
    "\n",
    "def interactive_merchant_matcher(merchant_matcher, examples=None, top_n=3):\n",
    "    \"\"\"\n",
    "    Interactive matcher for testing merchant name matching with detailed explanations\n",
    "    \n",
    "    Args:\n",
    "        merchant_matcher: Enhanced merchant matcher instance\n",
    "        examples (list, optional): List of example pairs to suggest\n",
    "        top_n (int): Number of algorithm scores to show\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if examples is None:\n",
    "        examples = [\n",
    "            ('BoA', 'Bank of America'),\n",
    "            ('MCD', 'McDonalds'),\n",
    "            ('WMT', 'Walmart Inc'),\n",
    "            ('AMZN', 'Amazon.com'),\n",
    "            ('StarBucks', 'Starbucks Coffee Company'),\n",
    "            ('Western Toyota', 'Toyota Corporation')\n",
    "        ]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"Interactive Merchant Name Matcher\".center(80))\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nThis tool helps you test the enhanced merchant matching algorithm.\")\n",
    "    print(\"Enter two merchant names to compare, or type 'quit' to exit.\")\n",
    "    print(\"\\nExample pairs you can try:\")\n",
    "    for i, (acronym, full_name) in enumerate(examples):\n",
    "        print(f\"  {i+1}. '{acronym}' <-> '{full_name}'\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n\" + \"-\" * 80)\n",
    "        print(\"Enter merchant names to compare (or 'quit' to exit):\")\n",
    "        \n",
    "        # Get acronym input\n",
    "        acronym = input(\"Acronym or Short Name: \").strip()\n",
    "        if acronym.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        # Get full name input\n",
    "        full_name = input(\"Full Name: \").strip()\n",
    "        if full_name.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        # Optional domain input\n",
    "        domain = input(\"Domain (optional, e.g., Banking, Restaurant): \").strip()\n",
    "        if not domain:\n",
    "            domain = None\n",
    "        \n",
    "        # Compute similarity scores\n",
    "        print(\"\\nComputing similarity scores...\")\n",
    "        all_scores = merchant_matcher.get_all_similarity_scores(acronym, full_name, domain)\n",
    "        weighted_score = merchant_matcher.compute_weighted_score(acronym, full_name, domain)\n",
    "        enhanced_score = merchant_matcher.compute_enhanced_score(acronym, full_name, domain)\n",
    "        \n",
    "        # Determine match category\n",
    "        match_category = \"No Match\"\n",
    "        for category, threshold in sorted(thresholds.items(), key=lambda x: x[1], reverse=True):\n",
    "            if enhanced_score >= threshold:\n",
    "                match_category = category\n",
    "                break\n",
    "        \n",
    "        # Show preprocessing results\n",
    "        acronym_clean, full_name_clean = merchant_matcher.preprocess_pair(acronym, full_name, domain)\n",
    "        \n",
    "        print(\"\\nResults:\")\n",
    "        print(f\"  Preprocessed Acronym: '{acronym_clean}'\")\n",
    "        print(f\"  Preprocessed Full Name: '{full_name_clean}'\")\n",
    "        print(f\"  Weighted Score: {weighted_score:.4f}\")\n",
    "        print(f\"  Enhanced Score: {enhanced_score:.4f}\")\n",
    "        print(f\"  Match Category: {match_category}\")\n",
    "        \n",
    "        # Show detected business patterns\n",
    "        patterns = merchant_matcher.detect_complex_business_patterns(acronym, full_name, domain)\n",
    "        if patterns:\n",
    "            print(\"\\nDetected Business Patterns:\")\n",
    "            for pattern, score in patterns.items():\n",
    "                print(f\"   {pattern.replace('_', ' ').title()}: {score:.4f}\")\n",
    "        \n",
    "        # Show top individual algorithm scores\n",
    "        print(\"\\nTop Individual Algorithm Scores:\")\n",
    "        top_scores = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        for algo, score in top_scores:\n",
    "            print(f\"   {algo.replace('_', ' ').title()}: {score:.4f}\")\n",
    "        \n",
    "        # Show weights used\n",
    "        weights = merchant_matcher.get_dynamic_weights(acronym, full_name, domain)\n",
    "        print(\"\\nTop Algorithm Weights:\")\n",
    "        top_weights = sorted(weights.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        for algo, weight in top_weights:\n",
    "            print(f\"   {algo.replace('_', ' ').title()}: {weight:.4f}\")\n",
    "        \n",
    "        # Provide explanation for the score\n",
    "        print(\"\\nExplanation:\")\n",
    "        if enhanced_score >= 0.95:\n",
    "            print(\"  This is an EXACT MATCH with very high confidence.\")\n",
    "        elif enhanced_score >= 0.85:\n",
    "            print(\"  This is a STRONG MATCH. The names are highly similar.\")\n",
    "        elif enhanced_score >= 0.75:\n",
    "            print(\"  This is a PROBABLE MATCH. The names are quite similar.\")\n",
    "        elif enhanced_score >= 0.65:\n",
    "            print(\"  This is a POSSIBLE MATCH. The names have significant similarity.\")\n",
    "        elif enhanced_score >= 0.50:\n",
    "            print(\"  This is a WEAK MATCH. The names have some similarity but should be reviewed.\")\n",
    "        else:\n",
    "            print(\"  This is likely NOT A MATCH. The names are too dissimilar.\")\n",
    "        \n",
    "        # Explain key factors\n",
    "        if patterns:\n",
    "            pattern_names = [p.replace('_', ' ').title() for p in patterns.keys()]\n",
    "            print(f\"  Key factors: Detected {', '.join(pattern_names)}.\")\n",
    "        \n",
    "        if 'bert_similarity' in all_scores and all_scores['bert_similarity'] > 0.8:\n",
    "            print(f\"  High semantic understanding: The names have similar meanings.\")\n",
    "        \n",
    "        if 'enhanced_acronym_formation' in all_scores and all_scores['enhanced_acronym_formation'] > 0.8:\n",
    "            print(f\"  Strong acronym formation: The short form is a good acronym of the full name.\")\n",
    "        \n",
    "        # Ask if the user wants to try another pair\n",
    "        continue_choice = input(\"\\nTry another pair? (y/n): \").strip().lower()\n",
    "        if continue_choice != 'y':\n",
    "            break\n",
    "    \n",
    "    print(\"\\nThank you for using the Interactive Merchant Name Matcher!\")\n",
    "\n",
    "print(\"Interactive merchant matcher function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bec527e-d3dc-43c1-9a78-71e0e80d0026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Batch Processing Functions\n",
    "\n",
    "def adapt_for_pyspark(spark=None):\n",
    "    \"\"\"\n",
    "    Create PySpark UDFs and pipeline components for large-scale processing\n",
    "    \n",
    "    Args:\n",
    "        spark: SparkSession instance (optional)\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing PySpark UDFs and pipeline components\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from pyspark.sql import SparkSession\n",
    "        from pyspark.sql.functions import udf, col\n",
    "        from pyspark.sql.types import DoubleType, StringType, StructType, StructField, ArrayType\n",
    "        pyspark_available = True\n",
    "    except ImportError:\n",
    "        pyspark_available = False\n",
    "        print(\"Warning: PySpark not available. Returning dummy implementation.\")\n",
    "        return {\"error\": \"PySpark not available\"}\n",
    "    \n",
    "    # Create SparkSession if not provided\n",
    "    if spark is None and pyspark_available:\n",
    "        try:\n",
    "            spark = SparkSession.builder \\\n",
    "                .appName(\"MerchantMatcherPipeline\") \\\n",
    "                .getOrCreate()\n",
    "            print(f\"Created Spark session: {spark.version}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create Spark session: {e}\")\n",
    "            pyspark_available = False\n",
    "    \n",
    "    if not pyspark_available:\n",
    "        return {\"error\": \"PySpark not available or failed to initialize\"}\n",
    "    \n",
    "    # Create UDFs for preprocessing and scoring\n",
    "    preprocessing_udf = udf(\n",
    "        lambda acronym, full_name, domain: merchant_matcher.preprocess_pair(acronym, full_name, domain),\n",
    "        StructType([\n",
    "            StructField(\"acronym_clean\", StringType(), True),\n",
    "            StructField(\"full_name_clean\", StringType(), True)\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    weighted_score_udf = udf(\n",
    "        lambda acronym, full_name, domain: float(merchant_matcher.compute_weighted_score(acronym, full_name, domain)), \n",
    "        DoubleType()\n",
    "    )\n",
    "    \n",
    "    enhanced_score_udf = udf(\n",
    "        lambda acronym, full_name, domain: float(merchant_matcher.compute_enhanced_score(acronym, full_name, domain)), \n",
    "        DoubleType()\n",
    "    )\n",
    "    \n",
    "    match_category_udf = udf(\n",
    "        lambda score: next((cat for cat, thresh in sorted(thresholds.items(), key=lambda x: x[1], reverse=True) \n",
    "                         if score >= thresh), \"No Match\"),\n",
    "        StringType()\n",
    "    )\n",
    "    \n",
    "    # Define a pipeline function\n",
    "    def process_merchant_spark_df(df, acronym_col=\"Acronym\", full_name_col=\"Full_Name\", \n",
    "                                 domain_col=\"Merchant_Category\"):\n",
    "        \"\"\"\n",
    "        Process merchant data using PySpark\n",
    "        \n",
    "        Args:\n",
    "            df: Spark DataFrame with merchant data\n",
    "            acronym_col: Column name for acronym/short name\n",
    "            full_name_col: Column name for full name\n",
    "            domain_col: Column name for merchant category/domain\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Spark DataFrame with results\n",
    "        \"\"\"\n",
    "        # Handle null values\n",
    "        df = df.na.fill(\"\", [acronym_col, full_name_col])\n",
    "        df = df.na.fill(\"Unknown\", [domain_col])\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        df = df.withColumn(\n",
    "            \"preprocessed\", \n",
    "            preprocessing_udf(col(acronym_col), col(full_name_col), col(domain_col))\n",
    "        )\n",
    "        \n",
    "        # Calculate scores\n",
    "        df = df.withColumn(\n",
    "            \"Weighted_Score\", \n",
    "            weighted_score_udf(col(acronym_col), col(full_name_col), col(domain_col))\n",
    "        )\n",
    "        \n",
    "        df = df.withColumn(\n",
    "            \"Enhanced_Score\", \n",
    "            enhanced_score_udf(col(acronym_col), col(full_name_col), col(domain_col))\n",
    "        )\n",
    "        \n",
    "        # Add match category\n",
    "        df = df.withColumn(\n",
    "            \"Match_Category\",\n",
    "            match_category_udf(col(\"Enhanced_Score\"))\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # Create a function to batch process a large DataFrame\n",
    "    def batch_process_merchant_data(df, batch_size=10000):\n",
    "        \"\"\"\n",
    "        Process a large merchant dataset in batches to avoid memory issues\n",
    "        \n",
    "        Args:\n",
    "            df: Spark DataFrame with merchant data\n",
    "            batch_size: Size of batches to process\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Spark DataFrame with results\n",
    "        \"\"\"\n",
    "        # Count total records\n",
    "        total_records = df.count()\n",
    "        print(f\"Processing {total_records} records in batches of {batch_size}\")\n",
    "        \n",
    "        # Process in batches\n",
    "        results = []\n",
    "        for i in range(0, total_records, batch_size):\n",
    "            # Take a batch\n",
    "            batch_df = df.limit(batch_size).offset(i)\n",
    "            \n",
    "            # Process batch\n",
    "            processed_batch = process_merchant_spark_df(batch_df)\n",
    "            \n",
    "            # Collect results (careful with large datasets)\n",
    "            batch_results = processed_batch.collect()\n",
    "            results.extend(batch_results)\n",
    "            \n",
    "            # Log progress\n",
    "            processed_so_far = min(i + batch_size, total_records)\n",
    "            print(f\"Processed {processed_so_far}/{total_records} records ({processed_so_far/total_records*100:.1f}%)\")\n",
    "        \n",
    "        # Convert results back to Spark DataFrame\n",
    "        results_df = spark.createDataFrame(results)\n",
    "        return results_df\n",
    "    \n",
    "    return {\n",
    "        \"spark_session\": spark,\n",
    "        \"preprocessing_udf\": preprocessing_udf,\n",
    "        \"weighted_score_udf\": weighted_score_udf,\n",
    "        \"enhanced_score_udf\": enhanced_score_udf,\n",
    "        \"match_category_udf\": match_category_udf,\n",
    "        \"process_merchant_spark_df\": process_merchant_spark_df,\n",
    "        \"batch_process_merchant_data\": batch_process_merchant_data\n",
    "    }\n",
    "\n",
    "def batch_process_file(input_file, output_file, batch_size=10000, use_spark=False):\n",
    "    \"\"\"\n",
    "    Process a large merchant dataset file in batches\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to input file (Excel or CSV)\n",
    "        output_file: Path to output file\n",
    "        batch_size: Size of batches to process\n",
    "        use_spark: Whether to use PySpark for processing\n",
    "        \n",
    "    Returns:\n",
    "        dict: Processing statistics\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Batch processing merchant data from {input_file}\")\n",
    "    \n",
    "    # Determine file type\n",
    "    is_excel = input_file.lower().endswith(('.xlsx', '.xls'))\n",
    "    is_csv = input_file.lower().endswith('.csv')\n",
    "    \n",
    "    if not (is_excel or is_csv):\n",
    "        raise ValueError(\"Input file must be Excel (.xlsx/.xls) or CSV (.csv)\")\n",
    "    \n",
    "    # Process with PySpark if requested\n",
    "    if use_spark:\n",
    "        try:\n",
    "            from pyspark.sql import SparkSession\n",
    "            \n",
    "            # Initialize Spark session\n",
    "            spark = SparkSession.builder \\\n",
    "                .appName(\"MerchantMatcherBatchProcessing\") \\\n",
    "                .getOrCreate()\n",
    "            \n",
    "            # Read input file\n",
    "            if is_excel:\n",
    "                df = spark.read.format(\"com.crealytics.spark.excel\") \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .load(input_file)\n",
    "            else:  # CSV\n",
    "                df = spark.read.option(\"header\", \"true\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .csv(input_file)\n",
    "            \n",
    "            # Get PySpark components\n",
    "            spark_components = adapt_for_pyspark(spark)\n",
    "            \n",
    "            # Process data\n",
    "            results_df = spark_components[\"batch_process_merchant_data\"](df, batch_size)\n",
    "            \n",
    "            # Save results\n",
    "            if output_file.lower().endswith('.csv'):\n",
    "                results_df.write.option(\"header\", \"true\").csv(output_file)\n",
    "            else:\n",
    "                # Convert to pandas for Excel output\n",
    "                pd_df = results_df.toPandas()\n",
    "                pd_df.to_excel(output_file, index=False)\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            return {\n",
    "                \"input_file\": input_file,\n",
    "                \"output_file\": output_file,\n",
    "                \"records_processed\": results_df.count(),\n",
    "                \"processing_time\": processing_time,\n",
    "                \"records_per_second\": results_df.count() / processing_time\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing with PySpark: {e}\")\n",
    "            print(\"Falling back to pandas processing...\")\n",
    "            use_spark = False\n",
    "    \n",
    "    # Process with pandas\n",
    "    if not use_spark:\n",
    "        # Read input file\n",
    "        if is_excel:\n",
    "            # Read in chunks if Excel file is large\n",
    "            try:\n",
    "                df = pd.read_excel(input_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading entire Excel file: {e}\")\n",
    "                print(\"Trying to read with limited rows...\")\n",
    "                df = pd.read_excel(input_file, nrows=1000000)  # Limit to 1M rows\n",
    "        else:  # CSV\n",
    "            # Use chunking for CSV\n",
    "            chunks = []\n",
    "            chunk_size = min(batch_size, 100000)  # Default chunk size\n",
    "            \n",
    "            for chunk in pd.read_csv(input_file, chunksize=chunk_size):\n",
    "                chunks.append(chunk)\n",
    "                print(f\"Read chunk with {len(chunk)} rows\")\n",
    "            \n",
    "            df = pd.concat(chunks)\n",
    "        \n",
    "        # Preprocess data\n",
    "        processed_df = preprocess_merchant_data(df)\n",
    "        \n",
    "        # Process in batches\n",
    "        total_rows = len(processed_df)\n",
    "        results = []\n",
    "        \n",
    "        for start_idx in range(0, total_rows, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, total_rows)\n",
    "            batch = processed_df.iloc[start_idx:end_idx]\n",
    "            \n",
    "            print(f\"Processing batch {start_idx//batch_size + 1}/{(total_rows-1)//batch_size + 1} \"\n",
    "                  f\"({start_idx}-{end_idx})\")\n",
    "            \n",
    "            # Process batch\n",
    "            batch_results = process_merchant_data(batch, merchant_matcher)\n",
    "            results.append(batch_results)\n",
    "            \n",
    "            # Log progress\n",
    "            processed_so_far = end_idx\n",
    "            print(f\"Processed {processed_so_far}/{total_rows} records ({processed_so_far/total_rows*100:.1f}%)\")\n",
    "        \n",
    "        # Combine results\n",
    "        results_df = pd.concat(results)\n",
    "        \n",
    "        # Add match categories\n",
    "        results_df = add_match_categories(results_df, thresholds)\n",
    "        \n",
    "        # Save results\n",
    "        if output_file.lower().endswith('.csv'):\n",
    "            results_df.to_csv(output_file, index=False)\n",
    "        else:\n",
    "            results_df.to_excel(output_file, index=False)\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        return {\n",
    "            \"input_file\": input_file,\n",
    "            \"output_file\": output_file,\n",
    "            \"records_processed\": len(results_df),\n",
    "            \"processing_time\": processing_time,\n",
    "            \"records_per_second\": len(results_df) / processing_time\n",
    "        }\n",
    "\n",
    "print(\"Batch processing functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ef6c46b-20ed-4938-8d1c-4e9605a71a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation and testing functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Evaluation and Testing Functions\n",
    "\n",
    "def evaluate_merchant_matcher(test_data_path=None, gold_standard_column='Expected_Match'):\n",
    "    \"\"\"\n",
    "    Evaluate the merchant matcher against a gold standard dataset\n",
    "    \n",
    "    Args:\n",
    "        test_data_path: Path to test data file (with gold standard annotations)\n",
    "        gold_standard_column: Column name for the gold standard match status\n",
    "        \n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    print(\"Evaluating merchant matcher performance...\")\n",
    "    \n",
    "    # If no test data provided, use built-in test cases\n",
    "    if test_data_path is None:\n",
    "        print(\"No test data provided, creating synthetic test data...\")\n",
    "        \n",
    "        # Create synthetic test data with known expected outcomes\n",
    "        test_data = {\n",
    "            'Acronym': [\n",
    "                # True matches - should get high scores\n",
    "                'BoA', 'JPMC', 'WF', 'MCD', 'SBUX', 'TGT', 'MSFT', 'AMZN',\n",
    "                'WMT', 'HD', 'TM', 'GM', 'GS', 'MS', 'BBY',\n",
    "                \n",
    "                # Partial matches - could go either way\n",
    "                'BofA', 'McDon', 'Micky Ds', 'Wmart', 'Tgt Stores',\n",
    "                'Msft Corp', 'Amaz', 'JPM Co', 'Home Dep',\n",
    "                \n",
    "                # False matches - should get low scores\n",
    "                'BOA', 'JPM', 'WF Bank', 'MCD Restaurant', 'SB Coffee',\n",
    "                'MSFT Solutions', 'GMC Trucks', 'TGT Brands'\n",
    "            ],\n",
    "            'Full_Name': [\n",
    "                # Matches for true matches\n",
    "                'Bank of America', 'JPMorgan Chase', 'Wells Fargo', 'McDonalds',\n",
    "                'Starbucks', 'Target', 'Microsoft', 'Amazon',\n",
    "                'Walmart', 'Home Depot', 'Toyota Motors', 'General Motors',\n",
    "                'Goldman Sachs', 'Morgan Stanley', 'Best Buy',\n",
    "                \n",
    "                # Matches for partial matches\n",
    "                'Bank of America Corp', 'McDonalds Corporation', 'McDonalds Restaurants',\n",
    "                'Walmart Stores', 'Target Corporation', 'Microsoft Inc',\n",
    "                'Amazon.com Inc', 'JP Morgan', 'The Home Depot',\n",
    "                \n",
    "                # Non-matches\n",
    "                'Bank of Australia', 'Johnson & Johnson', 'Western Family',\n",
    "                'Michaels Craft Store', 'Seattle Bread Company',\n",
    "                'Micro Soft Tech', 'General Mills', 'Tarjay Brands'\n",
    "            ],\n",
    "            'Merchant_Category': [\n",
    "                # Categories for true matches\n",
    "                'Banking', 'Banking', 'Banking', 'Restaurant', 'Restaurant',\n",
    "                'Retail', 'Technology', 'Technology', 'Retail', 'Retail',\n",
    "                'Automotive', 'Automotive', 'Banking', 'Banking', 'Retail',\n",
    "                \n",
    "                # Categories for partial matches\n",
    "                'Banking', 'Restaurant', 'Restaurant', 'Retail', 'Retail',\n",
    "                'Technology', 'Technology', 'Banking', 'Retail',\n",
    "                \n",
    "                # Categories for false matches\n",
    "                'Banking', 'Healthcare', 'Retail', 'Restaurant', 'Restaurant',\n",
    "                'Technology', 'Food', 'Retail'\n",
    "            ],\n",
    "            'Expected_Match': [\n",
    "                # Expected outcomes for true matches\n",
    "                True, True, True, True, True, True, True, True, \n",
    "                True, True, True, True, True, True, True,\n",
    "                \n",
    "                # Expected outcomes for partial matches\n",
    "                True, True, True, True, True, True, True, True, True,\n",
    "                \n",
    "                # Expected outcomes for false matches\n",
    "                False, False, False, False, False, False, False, False\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        test_df = pd.DataFrame(test_data)\n",
    "        print(f\"Created synthetic test dataset with {len(test_df)} entries\")\n",
    "    else:\n",
    "        # Load test data from file\n",
    "        try:\n",
    "            if test_data_path.lower().endswith('.csv'):\n",
    "                test_df = pd.read_csv(test_data_path)\n",
    "            else:\n",
    "                test_df = pd.read_excel(test_data_path)\n",
    "            \n",
    "            print(f\"Loaded test data from {test_data_path} with {len(test_df)} entries\")\n",
    "            \n",
    "            # Verify that gold standard column exists\n",
    "            if gold_standard_column not in test_df.columns:\n",
    "                raise ValueError(f\"Gold standard column '{gold_standard_column}' not found in test data\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading test data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Preprocess test data\n",
    "    processed_df = preprocess_merchant_data(test_df)\n",
    "    \n",
    "    # Compute scores\n",
    "    results_df = process_merchant_data(processed_df, merchant_matcher)\n",
    "    \n",
    "    # Add binary prediction based on threshold\n",
    "    match_threshold = 0.75  # This is the \"Probable Match\" threshold\n",
    "    results_df['Predicted_Match'] = results_df['Enhanced_Score'] >= match_threshold\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    try:\n",
    "        from sklearn.metrics import precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "        \n",
    "        # Convert expected values to boolean\n",
    "        results_df['Expected_Match'] = results_df[gold_standard_column].astype(bool)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            results_df['Expected_Match'], \n",
    "            results_df['Predicted_Match'],\n",
    "            average='binary'\n",
    "        )\n",
    "        \n",
    "        accuracy = accuracy_score(results_df['Expected_Match'], results_df['Predicted_Match'])\n",
    "        \n",
    "        # Calculate confusion matrix\n",
    "        tn, fp, fn, tp = confusion_matrix(results_df['Expected_Match'], results_df['Predicted_Match']).ravel()\n",
    "        \n",
    "        print(\"\\nEvaluation Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"True Positives: {tp}\")\n",
    "        print(f\"True Negatives: {tn}\")\n",
    "        print(f\"False Positives: {fp}\")\n",
    "        print(f\"False Negatives: {fn}\")\n",
    "        \n",
    "        # Analyze errors\n",
    "        print(\"\\nAnalyzing errors...\")\n",
    "        \n",
    "        # False positives\n",
    "        fp_df = results_df[(results_df['Predicted_Match'] == True) & (results_df['Expected_Match'] == False)]\n",
    "        if len(fp_df) > 0:\n",
    "            print(f\"\\nFalse Positives ({len(fp_df)}):\")\n",
    "            for _, row in fp_df.iterrows():\n",
    "                print(f\"  {row['Acronym']} <-> {row['Full_Name']} (Score: {row['Enhanced_Score']:.4f})\")\n",
    "        \n",
    "        # False negatives\n",
    "        fn_df = results_df[(results_df['Predicted_Match'] == False) & (results_df['Expected_Match'] == True)]\n",
    "        if len(fn_df) > 0:\n",
    "            print(f\"\\nFalse Negatives ({len(fn_df)}):\")\n",
    "            for _, row in fn_df.iterrows():\n",
    "                print(f\"  {row['Acronym']} <-> {row['Full_Name']} (Score: {row['Enhanced_Score']:.4f})\")\n",
    "        \n",
    "        # Return metrics\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'true_positives': tp,\n",
    "            'true_negatives': tn,\n",
    "            'false_positives': fp,\n",
    "            'false_negatives': fn,\n",
    "            'results_df': results_df\n",
    "        }\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"Warning: scikit-learn not available. Computing basic metrics...\")\n",
    "        \n",
    "        # Convert expected values to boolean\n",
    "        results_df['Expected_Match'] = results_df[gold_standard_column].astype(bool)\n",
    "        \n",
    "        # Calculate basic metrics\n",
    "        tp = sum((results_df['Predicted_Match'] == True) & (results_df['Expected_Match'] == True))\n",
    "        tn = sum((results_df['Predicted_Match'] == False) & (results_df['Expected_Match'] == False))\n",
    "        fp = sum((results_df['Predicted_Match'] == True) & (results_df['Expected_Match'] == False))\n",
    "        fn = sum((results_df['Predicted_Match'] == False) & (results_df['Expected_Match'] == True))\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        print(\"\\nBasic Evaluation Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'true_positives': tp,\n",
    "            'true_negatives': tn,\n",
    "            'false_positives': fp,\n",
    "            'false_negatives': fn,\n",
    "            'results_df': results_df\n",
    "        }\n",
    "\n",
    "def find_optimal_threshold(test_data_path=None, gold_standard_column='Expected_Match'):\n",
    "    \"\"\"\n",
    "    Find the optimal threshold for classifying merchant matches\n",
    "    \n",
    "    Args:\n",
    "        test_data_path: Path to test data file\n",
    "        gold_standard_column: Column name for the gold standard match status\n",
    "        \n",
    "    Returns:\n",
    "        float: Optimal threshold value\n",
    "    \"\"\"\n",
    "    print(\"Finding optimal threshold for merchant matching...\")\n",
    "    \n",
    "    # Get test data\n",
    "    if test_data_path is None:\n",
    "        # Call evaluate_merchant_matcher which will create synthetic data\n",
    "        eval_results = evaluate_merchant_matcher(None, gold_standard_column)\n",
    "        results_df = eval_results['results_df']\n",
    "    else:\n",
    "        # Load test data from file\n",
    "        try:\n",
    "            if test_data_path.lower().endswith('.csv'):\n",
    "                test_df = pd.read_csv(test_data_path)\n",
    "            else:\n",
    "                test_df = pd.read_excel(test_data_path)\n",
    "            \n",
    "            print(f\"Loaded test data from {test_data_path} with {len(test_df)} entries\")\n",
    "            \n",
    "            # Verify that gold standard column exists\n",
    "            if gold_standard_column not in test_df.columns:\n",
    "                raise ValueError(f\"Gold standard column '{gold_standard_column}' not found in test data\")\n",
    "                \n",
    "            # Preprocess test data\n",
    "            processed_df = preprocess_merchant_data(test_df)\n",
    "            \n",
    "            # Compute scores\n",
    "            results_df = process_merchant_data(processed_df, merchant_matcher)\n",
    "            \n",
    "            # Convert expected values to boolean\n",
    "            results_df['Expected_Match'] = results_df[gold_standard_column].astype(bool)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading or processing test data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Test different threshold values\n",
    "    try:\n",
    "        from sklearn.metrics import precision_recall_curve, f1_score\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        thresholds = np.linspace(0.1, 1.0, 37)  # Test thresholds from 0.1 to 1.0\n",
    "        f1_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        \n",
    "        # Calculate F1 score for each threshold\n",
    "        for threshold in thresholds:\n",
    "            predictions = results_df['Enhanced_Score'] >= threshold\n",
    "            precision = sum(predictions & results_df['Expected_Match']) / sum(predictions) if sum(predictions) > 0 else 0\n",
    "            recall = sum(predictions & results_df['Expected_Match']) / sum(results_df['Expected_Match']) if sum(results_df['Expected_Match']) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "        # Find optimal threshold (maximizing F1 score)\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        optimal_f1 = f1_scores[optimal_idx]\n",
    "        \n",
    "        print(f\"\\nOptimal threshold: {optimal_threshold:.4f} (F1 score: {optimal_f1:.4f})\")\n",
    "        print(f\"At this threshold:\")\n",
    "        print(f\"  Precision: {precision_scores[optimal_idx]:.4f}\")\n",
    "        print(f\"  Recall: {recall_scores[optimal_idx]:.4f}\")\n",
    "        \n",
    "        # Plot the results\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(thresholds, precision_scores, label='Precision')\n",
    "            plt.plot(thresholds, recall_scores, label='Recall')\n",
    "            plt.plot(thresholds, f1_scores, label='F1 Score')\n",
    "            plt.axvline(x=optimal_threshold, color='k', linestyle='--', label=f'Optimal Threshold = {optimal_threshold:.2f}')\n",
    "            plt.xlabel('Threshold')\n",
    "            plt.ylabel('Score')\n",
    "            plt.title('Precision, Recall, and F1 Score vs. Threshold')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error creating plot: {e}\")\n",
    "        \n",
    "        # Also try precision-recall curve\n",
    "        try:\n",
    "            # Get precision-recall curve\n",
    "            precision, recall, pr_thresholds = precision_recall_curve(\n",
    "                results_df['Expected_Match'], \n",
    "                results_df['Enhanced_Score']\n",
    "            )\n",
    "            \n",
    "            # Plot precision-recall curve\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(recall, precision, marker='.', label='Precision-Recall curve')\n",
    "            plt.xlabel('Recall')\n",
    "            plt.ylabel('Precision')\n",
    "            plt.title('Precision-Recall Curve')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Error creating precision-recall plot: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'optimal_threshold': optimal_threshold,\n",
    "            'optimal_f1': optimal_f1,\n",
    "            'thresholds': thresholds,\n",
    "            'precision_scores': precision_scores,\n",
    "            'recall_scores': recall_scores,\n",
    "            'f1_scores': f1_scores\n",
    "        }\n",
    "    \n",
    "    except ImportError:\n",
    "        print(\"Warning: scikit-learn or matplotlib not available. Computing basic optimization...\")\n",
    "        \n",
    "        # Test different threshold values without plotting\n",
    "        thresholds = np.linspace(0.1, 1.0, 19)  # Test thresholds from 0.1 to 1.0\n",
    "        f1_scores = []\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        \n",
    "        # Calculate F1 score for each threshold\n",
    "        for threshold in thresholds:\n",
    "            predictions = results_df['Enhanced_Score'] >= threshold\n",
    "            precision = sum(predictions & results_df['Expected_Match']) / sum(predictions) if sum(predictions) > 0 else 0\n",
    "            recall = sum(predictions & results_df['Expected_Match']) / sum(results_df['Expected_Match']) if sum(results_df['Expected_Match']) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "        # Find optimal threshold (maximizing F1 score)\n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        optimal_f1 = f1_scores[optimal_idx]\n",
    "        \n",
    "        print(f\"\\nOptimal threshold: {optimal_threshold:.4f} (F1 score: {optimal_f1:.4f})\")\n",
    "        print(f\"At this threshold:\")\n",
    "        print(f\"  Precision: {precision_scores[optimal_idx]:.4f}\")\n",
    "        print(f\"  Recall: {recall_scores[optimal_idx]:.4f}\")\n",
    "        \n",
    "        # Print table of results\n",
    "        print(\"\\nThreshold\\tPrecision\\tRecall\\t\\tF1 Score\")\n",
    "        print(\"-\" * 60)\n",
    "        for i, t in enumerate(thresholds):\n",
    "            print(f\"{t:.2f}\\t\\t{precision_scores[i]:.4f}\\t\\t{recall_scores[i]:.4f}\\t\\t{f1_scores[i]:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'optimal_threshold': optimal_threshold,\n",
    "            'optimal_f1': optimal_f1,\n",
    "            'thresholds': thresholds,\n",
    "            'precision_scores': precision_scores,\n",
    "            'recall_scores': recall_scores,\n",
    "            'f1_scores': f1_scores\n",
    "        }\n",
    "\n",
    "def compare_algorithms(test_data_path=None, gold_standard_column='Expected_Match'):\n",
    "    \"\"\"\n",
    "    Compare different matching algorithms on the same test data\n",
    "    \n",
    "    Args:\n",
    "        test_data_path: Path to test data file\n",
    "        gold_standard_column: Column name for the gold standard match status\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Comparison results\n",
    "    \"\"\"\n",
    "    print(\"Comparing matching algorithms...\")\n",
    "    \n",
    "    # Get test data\n",
    "    if test_data_path is None:\n",
    "        # Create synthetic test data\n",
    "        eval_results = evaluate_merchant_matcher(None, gold_standard_column)\n",
    "        test_df = eval_results['results_df'][['Acronym', 'Full_Name', 'Merchant_Category', 'Expected_Match']]\n",
    "    else:\n",
    "        # Load test data from file\n",
    "        try:\n",
    "            if test_data_path.lower().endswith('.csv'):\n",
    "                test_df = pd.read_csv(test_data_path)\n",
    "            else:\n",
    "                test_df = pd.read_excel(test_data_path)\n",
    "                \n",
    "            # Verify that gold standard column exists\n",
    "            if gold_standard_column not in test_df.columns:\n",
    "                raise ValueError(f\"Gold standard column '{gold_standard_column}' not found in test data\")\n",
    "                \n",
    "            # Convert expected values to boolean\n",
    "            test_df['Expected_Match'] = test_df[gold_standard_column].astype(bool)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading test data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Preprocess test data\n",
    "    processed_df = preprocess_merchant_data(test_df)\n",
    "    \n",
    "    # Define algorithms to compare\n",
    "    algorithms = {\n",
    "        'Jaro-Winkler': lambda a, f, d: merchant_matcher.jaro_winkler_similarity(a, f, d),\n",
    "        'Damerau-Levenshtein': lambda a, f, d: merchant_matcher.damerau_levenshtein_similarity(a, f, d),\n",
    "        'TF-IDF Cosine': lambda a, f, d: merchant_matcher.tfidf_cosine_similarity(a, f, d),\n",
    "        'Jaccard Bigram': lambda a, f, d: merchant_matcher.jaccard_bigram_similarity(a, f, d),\n",
    "        'Soundex': lambda a, f, d: merchant_matcher.soundex_similarity(a, f, d),\n",
    "        'Token Sort Ratio': lambda a, f, d: merchant_matcher.token_sort_ratio_similarity(a, f, d),\n",
    "        'Acronym Formation': lambda a, f, d: merchant_matcher.enhanced_acronym_formation_score(a, f, d),\n",
    "        'BERT Similarity': lambda a, f, d: merchant_matcher.bert_similarity(a, f, d) if hasattr(merchant_matcher, 'bert_similarity') else 0,\n",
    "        'Weighted Score': lambda a, f, d: merchant_matcher.compute_weighted_score(a, f, d),\n",
    "        'Enhanced Score': lambda a, f, d: merchant_matcher.compute_enhanced_score(a, f, d)\n",
    "    }\n",
    "    \n",
    "    # Evaluate each algorithm\n",
    "    algorithm_results = {}\n",
    "    algorithm_metrics = {}\n",
    "    \n",
    "    for name, algorithm in algorithms.items():\n",
    "        print(f\"Evaluating {name}...\")\n",
    "        scores = []\n",
    "        \n",
    "        # Calculate scores for each pair\n",
    "        for _, row in processed_df.iterrows():\n",
    "            acronym = row['Acronym']\n",
    "            full_name = row['Full_Name']\n",
    "            domain = row['Merchant_Category'] if 'Merchant_Category' in row else None\n",
    "            score = algorithm(acronym, full_name, domain)\n",
    "            scores.append(score)\n",
    "        \n",
    "        # Add scores to results\n",
    "        processed_df[f'{name}_Score'] = scores\n",
    "        \n",
    "        # Find optimal threshold for this algorithm\n",
    "        thresholds = np.linspace(0.1, 1.0, 19)\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            predictions = np.array(scores) >= threshold\n",
    "            true_labels = processed_df['Expected_Match'].values\n",
    "            \n",
    "            # Calculate metrics\n",
    "            tp = sum(predictions & true_labels)\n",
    "            fp = sum(predictions & ~true_labels)\n",
    "            fn = sum(~predictions & true_labels)\n",
    "            \n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        # Calculate final metrics at optimal threshold\n",
    "        predictions = np.array(scores) >= best_threshold\n",
    "        true_labels = processed_df['Expected_Match'].values\n",
    "        \n",
    "        tp = sum(predictions & true_labels)\n",
    "        fp = sum(predictions & ~true_labels)\n",
    "        fn = sum(~predictions & true_labels)\n",
    "        tn = sum(~predictions & ~true_labels)\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = (tp + tn) / len(true_labels) if len(true_labels) > 0 else 0\n",
    "        \n",
    "        # Store metrics\n",
    "        algorithm_metrics[name] = {\n",
    "            'threshold': best_threshold,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'false_negatives': fn,\n",
    "            'true_negatives': tn\n",
    "        }\n",
    "        \n",
    "        # Store predictions\n",
    "        algorithm_results[name] = predictions\n",
    "    \n",
    "    # Create comparison table\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Algorithm': list(algorithm_metrics.keys()),\n",
    "        'Threshold': [m['threshold'] for m in algorithm_metrics.values()],\n",
    "        'Accuracy': [m['accuracy'] for m in algorithm_metrics.values()],\n",
    "        'Precision': [m['precision'] for m in algorithm_metrics.values()],\n",
    "        'Recall': [m['recall'] for m in algorithm_metrics.values()],\n",
    "        'F1 Score': [m['f1_score'] for m in algorithm_metrics.values()]\n",
    "    })\n",
    "    \n",
    "    # Sort by F1 score\n",
    "    metrics_df = metrics_df.sort_values('F1 Score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    # Print comparison table\n",
    "    print(\"\\nAlgorithm Comparison Results:\")\n",
    "    print(metrics_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "    # Plot comparison if matplotlib is available\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # Bar chart for F1 scores\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        bars = plt.bar(metrics_df['Algorithm'], metrics_df['F1 Score'])\n",
    "        plt.xlabel('Algorithm')\n",
    "        plt.ylabel('F1 Score')\n",
    "        plt.title('Algorithm F1 Score Comparison')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{height:.4f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Precision-Recall comparison for top 5 algorithms\n",
    "        top_algorithms = metrics_df['Algorithm'].head(5).tolist()\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        for algorithm in top_algorithms:\n",
    "            precision = algorithm_metrics[algorithm]['precision']\n",
    "            recall = algorithm_metrics[algorithm]['recall']\n",
    "            plt.scatter(recall, precision, label=f\"{algorithm} (F1={algorithm_metrics[algorithm]['f1_score']:.4f})\", s=100)\n",
    "        \n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision vs Recall for Top Algorithms')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available for visualization.\")\n",
    "    \n",
    "    return {\n",
    "        'metrics_df': metrics_df,\n",
    "        'algorithm_metrics': algorithm_metrics,\n",
    "        'algorithm_results': algorithm_results,\n",
    "        'processed_df': processed_df\n",
    "    }\n",
    "\n",
    "print(\"Evaluation and testing functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eae95210-56e8-408f-9ad1-63a47bedac94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation and error analysis functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Cross-Validation and Error Analysis Functions\n",
    "\n",
    "def visualize_error_cases(results_df, num_cases=5):\n",
    "    \"\"\"\n",
    "    Visualize and analyze error cases to understand why they're misclassified\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with matching results\n",
    "        num_cases: Number of error cases to visualize\n",
    "        \n",
    "    Returns:\n",
    "        dict: Analysis of error cases\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing top {num_cases} error cases...\")\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    required_cols = ['Acronym', 'Full_Name', 'Enhanced_Score', 'Expected_Match', 'Predicted_Match']\n",
    "    if not all(col in results_df.columns for col in required_cols):\n",
    "        print(\"Error: Required columns missing from results DataFrame\")\n",
    "        return None\n",
    "    \n",
    "    # Find false positives (predicted match but actually not a match)\n",
    "    fp_df = results_df[(results_df['Predicted_Match'] == True) & (results_df['Expected_Match'] == False)]\n",
    "    fp_df = fp_df.sort_values('Enhanced_Score', ascending=False).head(num_cases)\n",
    "    \n",
    "    # Find false negatives (predicted not a match but actually a match)\n",
    "    fn_df = results_df[(results_df['Predicted_Match'] == False) & (results_df['Expected_Match'] == True)]\n",
    "    fn_df = fn_df.sort_values('Enhanced_Score', ascending=True).head(num_cases)\n",
    "    \n",
    "    # Analyze false positives\n",
    "    print(\"\\nFalse Positive Analysis (Incorrectly Predicted as Match):\")\n",
    "    fp_analysis = {}\n",
    "    \n",
    "    for i, (_, row) in enumerate(fp_df.iterrows()):\n",
    "        acronym = row['Acronym']\n",
    "        full_name = row['Full_Name']\n",
    "        score = row['Enhanced_Score']\n",
    "        \n",
    "        print(f\"\\nError Case {i+1}: {acronym} <-> {full_name} (Score: {score:.4f})\")\n",
    "        \n",
    "        # Get all similarity scores\n",
    "        scores = merchant_matcher.get_all_similarity_scores(acronym, full_name)\n",
    "        \n",
    "        # Display top scores\n",
    "        top_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        print(\"Top Individual Algorithm Scores:\")\n",
    "        for algo, algo_score in top_scores:\n",
    "            print(f\"  {algo.replace('_', ' ').title()}: {algo_score:.4f}\")\n",
    "        \n",
    "        # Check for patterns\n",
    "        patterns = merchant_matcher.detect_complex_business_patterns(acronym, full_name)\n",
    "        if patterns:\n",
    "            print(\"Detected Business Patterns:\")\n",
    "            for pattern, pattern_score in patterns.items():\n",
    "                print(f\"  {pattern.replace('_', ' ').title()}: {pattern_score:.4f}\")\n",
    "        \n",
    "        # Explain issue\n",
    "        print(\"Possible reason for misclassification:\")\n",
    "        if any(pattern in ['inverted_agency_structure', 'bank_name_inversion'] for pattern in patterns):\n",
    "            print(\"  Structure pattern detection may be too aggressive\")\n",
    "        \n",
    "        if any(score > 0.9 for algo, score in scores.items() if 'bert' in algo):\n",
    "            print(\"  BERT semantic similarity may be overvaluing similar contexts\")\n",
    "        \n",
    "        if any(score > 0.9 for algo, score in scores.items() if 'acronym' in algo):\n",
    "            print(\"  Acronym formation detection may be too lenient\")\n",
    "        \n",
    "        # Store analysis\n",
    "        fp_analysis[i] = {\n",
    "            'acronym': acronym,\n",
    "            'full_name': full_name,\n",
    "            'score': score,\n",
    "            'top_scores': top_scores,\n",
    "            'patterns': patterns\n",
    "        }\n",
    "    \n",
    "    # Analyze false negatives\n",
    "    print(\"\\nFalse Negative Analysis (Incorrectly Predicted as Non-Match):\")\n",
    "    fn_analysis = {}\n",
    "    \n",
    "    for i, (_, row) in enumerate(fn_df.iterrows()):\n",
    "        acronym = row['Acronym']\n",
    "        full_name = row['Full_Name']\n",
    "        score = row['Enhanced_Score']\n",
    "        \n",
    "        print(f\"\\nError Case {i+1}: {acronym} <-> {full_name} (Score: {score:.4f})\")\n",
    "        \n",
    "        # Get all similarity scores\n",
    "        scores = merchant_matcher.get_all_similarity_scores(acronym, full_name)\n",
    "        \n",
    "        # Display top scores\n",
    "        top_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        print(\"Top Individual Algorithm Scores:\")\n",
    "        for algo, algo_score in top_scores:\n",
    "            print(f\"  {algo.replace('_', ' ').title()}: {algo_score:.4f}\")\n",
    "        \n",
    "        # Check for patterns\n",
    "        patterns = merchant_matcher.detect_complex_business_patterns(acronym, full_name)\n",
    "        if patterns:\n",
    "            print(\"Detected Business Patterns:\")\n",
    "            for pattern, pattern_score in patterns.items():\n",
    "                print(f\"  {pattern.replace('_', ' ').title()}: {pattern_score:.4f}\")\n",
    "        \n",
    "        # Explain issue\n",
    "        print(\"Possible reason for misclassification:\")\n",
    "        if all(score < 0.5 for algo, score in scores.items() if 'acronym' in algo):\n",
    "            print(\"  No strong acronym formation detected\")\n",
    "        \n",
    "        if all(score < 0.7 for algo, score in scores.items() if 'jaro' in algo or 'levenshtein' in algo):\n",
    "            print(\"  Low string similarity scores\")\n",
    "        \n",
    "        if not patterns:\n",
    "            print(\"  No business patterns detected\")\n",
    "        \n",
    "        # Store analysis\n",
    "        fn_analysis[i] = {\n",
    "            'acronym': acronym,\n",
    "            'full_name': full_name,\n",
    "            'score': score,\n",
    "            'top_scores': top_scores,\n",
    "            'patterns': patterns\n",
    "        }\n",
    "    \n",
    "    # Return analysis results\n",
    "    return {\n",
    "        'false_positives': fp_analysis,\n",
    "        'false_negatives': fn_analysis,\n",
    "        'fp_df': fp_df,\n",
    "        'fn_df': fn_df\n",
    "    }\n",
    "\n",
    "def cross_validate_merchant_matcher(test_data_path=None, gold_standard_column='Expected_Match', n_folds=5):\n",
    "    \"\"\"\n",
    "    Perform cross-validation to assess model stability\n",
    "    \n",
    "    Args:\n",
    "        test_data_path: Path to test data file\n",
    "        gold_standard_column: Column name for the gold standard match status\n",
    "        n_folds: Number of cross-validation folds\n",
    "        \n",
    "    Returns:\n",
    "        dict: Cross-validation results\n",
    "    \"\"\"\n",
    "    print(f\"Performing {n_folds}-fold cross-validation...\")\n",
    "    \n",
    "    # Get test data\n",
    "    if test_data_path is None:\n",
    "        # Create synthetic test data\n",
    "        eval_results = evaluate_merchant_matcher(None, gold_standard_column)\n",
    "        test_df = eval_results['results_df'][['Acronym', 'Full_Name', 'Merchant_Category', 'Expected_Match']]\n",
    "    else:\n",
    "        # Load test data from file\n",
    "        try:\n",
    "            if test_data_path.lower().endswith('.csv'):\n",
    "                test_df = pd.read_csv(test_data_path)\n",
    "            else:\n",
    "                test_df = pd.read_excel(test_data_path)\n",
    "                \n",
    "            # Verify that gold standard column exists\n",
    "            if gold_standard_column not in test_df.columns:\n",
    "                raise ValueError(f\"Gold standard column '{gold_standard_column}' not found in test data\")\n",
    "                \n",
    "            # Convert expected values to boolean\n",
    "            test_df['Expected_Match'] = test_df[gold_standard_column].astype(bool)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading test data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Preprocess test data\n",
    "    processed_df = preprocess_merchant_data(test_df)\n",
    "    \n",
    "    # Check for sufficient data\n",
    "    if len(processed_df) < n_folds * 2:\n",
    "        print(f\"Warning: Not enough data for {n_folds} folds. Need at least {n_folds * 2} samples.\")\n",
    "        n_folds = max(2, len(processed_df) // 2)\n",
    "        print(f\"Reducing to {n_folds} folds.\")\n",
    "    \n",
    "    # Create folds\n",
    "    try:\n",
    "        from sklearn.model_selection import KFold\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "        folds = list(kf.split(processed_df))\n",
    "    except ImportError:\n",
    "        print(\"Warning: scikit-learn not available. Using manual fold creation.\")\n",
    "        # Manual fold creation\n",
    "        indices = np.random.permutation(len(processed_df))\n",
    "        fold_size = len(processed_df) // n_folds\n",
    "        folds = []\n",
    "        for i in range(n_folds):\n",
    "            test_indices = indices[i*fold_size:(i+1)*fold_size]\n",
    "            train_indices = np.setdiff1d(indices, test_indices)\n",
    "            folds.append((train_indices, test_indices))\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(folds):\n",
    "        print(f\"\\nProcessing fold {fold+1}/{n_folds}...\")\n",
    "        \n",
    "        # Split data\n",
    "        train_df = processed_df.iloc[train_idx]\n",
    "        test_df = processed_df.iloc[test_idx]\n",
    "        \n",
    "        # Process data\n",
    "        results_df = process_merchant_data(test_df, merchant_matcher)\n",
    "        \n",
    "        # Find optimal threshold using training data\n",
    "        train_results = process_merchant_data(train_df, merchant_matcher)\n",
    "        thresholds = np.linspace(0.1, 1.0, 19)\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0.5\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            predictions = train_results['Enhanced_Score'] >= threshold\n",
    "            true_labels = train_df['Expected_Match'].values\n",
    "            \n",
    "            # Calculate metrics\n",
    "            tp = sum(predictions & true_labels)\n",
    "            fp = sum(predictions & ~true_labels)\n",
    "            fn = sum(~predictions & true_labels)\n",
    "            \n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "        \n",
    "        print(f\"  Optimal threshold for fold {fold+1}: {best_threshold:.4f}\")\n",
    "        \n",
    "        # Evaluate on test data\n",
    "        results_df['Predicted_Match'] = results_df['Enhanced_Score'] >= best_threshold\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tp = sum((results_df['Predicted_Match'] == True) & (test_df['Expected_Match'] == True))\n",
    "        tn = sum((results_df['Predicted_Match'] == False) & (test_df['Expected_Match'] == False))\n",
    "        fp = sum((results_df['Predicted_Match'] == True) & (test_df['Expected_Match'] == False))\n",
    "        fn = sum((results_df['Predicted_Match'] == False) & (test_df['Expected_Match'] == True))\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        # Store fold results\n",
    "        fold_results.append({\n",
    "            'fold': fold + 1,\n",
    "            'threshold': best_threshold,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'true_positives': tp,\n",
    "            'false_positives': fp,\n",
    "            'false_negatives': fn,\n",
    "            'true_negatives': tn\n",
    "        })\n",
    "        \n",
    "        print(f\"  Fold {fold+1} Results:\")\n",
    "        print(f\"    Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"    Precision: {precision:.4f}\")\n",
    "        print(f\"    Recall: {recall:.4f}\")\n",
    "        print(f\"    F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {\n",
    "        'accuracy': np.mean([r['accuracy'] for r in fold_results]),\n",
    "        'precision': np.mean([r['precision'] for r in fold_results]),\n",
    "        'recall': np.mean([r['recall'] for r in fold_results]),\n",
    "        'f1_score': np.mean([r['f1_score'] for r in fold_results]),\n",
    "        'threshold': np.mean([r['threshold'] for r in fold_results])\n",
    "    }\n",
    "    \n",
    "    std_metrics = {\n",
    "        'accuracy': np.std([r['accuracy'] for r in fold_results]),\n",
    "        'precision': np.std([r['precision'] for r in fold_results]),\n",
    "        'recall': np.std([r['recall'] for r in fold_results]),\n",
    "        'f1_score': np.std([r['f1_score'] for r in fold_results]),\n",
    "        'threshold': np.std([r['threshold'] for r in fold_results])\n",
    "    }\n",
    "    \n",
    "    print(\"\\nCross-Validation Summary:\")\n",
    "    print(f\"  Average Accuracy: {avg_metrics['accuracy']:.4f} ({std_metrics['accuracy']:.4f})\")\n",
    "    print(f\"  Average Precision: {avg_metrics['precision']:.4f} ({std_metrics['precision']:.4f})\")\n",
    "    print(f\"  Average Recall: {avg_metrics['recall']:.4f} ({std_metrics['recall']:.4f})\")\n",
    "    print(f\"  Average F1 Score: {avg_metrics['f1_score']:.4f} ({std_metrics['f1_score']:.4f})\")\n",
    "    print(f\"  Average Threshold: {avg_metrics['threshold']:.4f} ({std_metrics['threshold']:.4f})\")\n",
    "    \n",
    "    # Check for potential overfitting\n",
    "    if std_metrics['f1_score'] > 0.15:\n",
    "        print(\"\\nWarning: High variance in F1 scores across folds.\")\n",
    "        print(\"This may indicate that the model's performance is unstable.\")\n",
    "        print(\"Consider using a larger dataset or a simpler model.\")\n",
    "    \n",
    "    # Check if thresholds vary significantly\n",
    "    if std_metrics['threshold'] > 0.1:\n",
    "        print(\"\\nWarning: High variance in optimal thresholds across folds.\")\n",
    "        print(\"This may indicate that the optimal threshold is dataset-dependent.\")\n",
    "        print(\"Consider using a fixed threshold based on business requirements.\")\n",
    "    \n",
    "    return {\n",
    "        'fold_results': fold_results,\n",
    "        'avg_metrics': avg_metrics,\n",
    "        'std_metrics': std_metrics\n",
    "    }\n",
    "\n",
    "print(\"Cross-validation and error analysis functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4feec94-f0b7-4dbd-830e-1aa1a65b2411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive testing and analysis functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Comprehensive Testing and Analysis\n",
    "\n",
    "def run_comprehensive_evaluation(test_data_path=None, gold_standard_column='Expected_Match'):\n",
    "    \"\"\"\n",
    "    Run a comprehensive evaluation of the merchant matcher\n",
    "    \n",
    "    Args:\n",
    "        test_data_path: Path to test data file\n",
    "        gold_standard_column: Column name for the gold standard match status\n",
    "        \n",
    "    Returns:\n",
    "        dict: Comprehensive evaluation results\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Running comprehensive evaluation of merchant matcher...\")\n",
    "    \n",
    "    # Step 1: Basic Evaluation\n",
    "    print(\"\\n=== Step 1: Basic Evaluation ===\")\n",
    "    basic_eval = evaluate_merchant_matcher(test_data_path, gold_standard_column)\n",
    "    \n",
    "    # Step 2: Find Optimal Threshold\n",
    "    print(\"\\n=== Step 2: Finding Optimal Threshold ===\")\n",
    "    threshold_results = find_optimal_threshold(test_data_path, gold_standard_column)\n",
    "    \n",
    "    # Step 3: Algorithm Comparison\n",
    "    print(\"\\n=== Step 3: Algorithm Comparison ===\")\n",
    "    algorithm_comparison = compare_algorithms(test_data_path, gold_standard_column)\n",
    "    \n",
    "    # Step 4: Error Analysis\n",
    "    print(\"\\n=== Step 4: Error Analysis ===\")\n",
    "    error_analysis = visualize_error_cases(basic_eval['results_df'])\n",
    "    \n",
    "    # Step 5: Cross-Validation\n",
    "    print(\"\\n=== Step 5: Cross-Validation ===\")\n",
    "    cv_results = cross_validate_merchant_matcher(test_data_path, gold_standard_column)\n",
    "    \n",
    "    # Calculate total execution time\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nComprehensive evaluation completed in {total_time:.2f} seconds\")\n",
    "    \n",
    "    # Return all results\n",
    "    return {\n",
    "        'basic_evaluation': basic_eval,\n",
    "        'threshold_optimization': threshold_results,\n",
    "        'algorithm_comparison': algorithm_comparison,\n",
    "        'error_analysis': error_analysis,\n",
    "        'cross_validation': cv_results,\n",
    "        'execution_time': total_time\n",
    "    }\n",
    "\n",
    "def run_example_pipeline():\n",
    "    \"\"\"\n",
    "    Run an example merchant matching pipeline demonstration\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Enhanced Merchant Name Matching - Pipeline Demonstration\".center(80))\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # Example 1: Process sample input file\n",
    "    print(\"\\n1. Processing a sample merchant file:\")\n",
    "    # Create a sample file for demonstration\n",
    "    sample_data = pd.DataFrame({\n",
    "        'Acronym': ['BOA', 'MCD', 'SBUX', 'TGT', 'MSFT'],\n",
    "        'Full_Name': ['Bank of America', 'McDonalds Corporation', 'Starbucks Coffee', 'Target', 'Microsoft'],\n",
    "        'Merchant_Category': ['Banking', 'Restaurant', 'Restaurant', 'Retail', 'Technology']\n",
    "    })\n",
    "    \n",
    "    sample_file = \"Acronym_Categorized.xlsx\"\n",
    "    sample_data.to_excel(sample_file, index=False)\n",
    "    \n",
    "    # Process the sample file\n",
    "    results = run_merchant_matching_pipeline(sample_file, \"sample_results.xlsx\")\n",
    "    \n",
    "    # Example 2: Interactive testing\n",
    "    print(\"\\n2. Interactive Merchant Matcher:\")\n",
    "    print(\"   (Skipped in automated demo - run interactive_merchant_matcher() separately)\")\n",
    "    \n",
    "    # Example 3: Algorithm comparison\n",
    "    print(\"\\n3. Algorithm Comparison:\")\n",
    "    algorithms = ['Jaro-Winkler', 'BERT Similarity', 'Acronym Formation', 'Enhanced Score']\n",
    "    print(f\"   Top algorithms: {', '.join(algorithms)}\")\n",
    "    \n",
    "    # Example 4: Batch processing\n",
    "    print(\"\\n4. Batch Processing Capability:\")\n",
    "    print(\"   System can process large files in batches to manage memory\")\n",
    "    print(\"   For PySpark integration, call adapt_for_pyspark()\")\n",
    "    \n",
    "    # Clean up sample files\n",
    "    try:\n",
    "        import os\n",
    "        os.remove(sample_file)\n",
    "        os.remove(\"Acronym_Categorized.xlsx\")\n",
    "        print(\"\\nCleaned up sample files\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"\\nDemonstration complete!\")\n",
    "\n",
    "# Example usage to run the comprehensive evaluation:\n",
    "# evaluation_results = run_comprehensive_evaluation()\n",
    "\n",
    "# Example usage to process a specific file:\n",
    "# results_df = process_acronym_file_and_export_results(\"Acronym_Categorized.xlsx\", \"Acronym_Matching_Results.xlsx\")\n",
    "\n",
    "print(\"Comprehensive testing and analysis functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c109612-1324-41bb-b1dc-59ed5e199530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                     Enhanced Merchant Name Matching System                     \n",
      "================================================================================\n",
      "\n",
      "\n",
      "Processing Acronym_Categorized.xlsx file...\n",
      "Loading and processing data from Acronym_Categorized.xlsx...\n",
      "Successfully loaded 100 records from Acronym_Categorized.xlsx\n",
      "Columns found: ['Acronym', 'Full Name', 'Merchant Category']\n",
      "\n",
      "Sample data (first 3 rows):\n",
      "   Acronym                                          Full Name  \\\n",
      "0      ANZ            Australia and New Zealand Banking Group   \n",
      "1   Qantas  Queensland and Northern Territory Aerial Services   \n",
      "2  Telstra                                  Telecom Australia   \n",
      "\n",
      "  Merchant Category  \n",
      "0           Banking  \n",
      "1           Banking  \n",
      "2           Telecom  \n",
      "\n",
      "Preprocessing merchant data...\n",
      "Category distribution after preprocessing:\n",
      "Merchant_Category\n",
      "Government         43\n",
      "Banking             8\n",
      "Retail              6\n",
      "Misc Speciality     6\n",
      "Technology          6\n",
      "Automotive          5\n",
      "Restaurant          5\n",
      "Clothing            4\n",
      "Medical             3\n",
      "Telecom             2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Calculating similarity scores using enhanced merchant matcher...\n",
      "Processing 100 merchant entries with enhanced matcher...\n",
      "Progress: 1.0% (1/100) - Elapsed: 0.2s - Est. remaining: 0.0s\n",
      "Progress: 11.0% (11/100) - Elapsed: 2.1s - Est. remaining: 17.2s\n",
      "Progress: 21.0% (21/100) - Elapsed: 4.2s - Est. remaining: 16.0s\n",
      "Progress: 31.0% (31/100) - Elapsed: 6.1s - Est. remaining: 13.6s\n",
      "Progress: 41.0% (41/100) - Elapsed: 8.1s - Est. remaining: 11.7s\n",
      "Progress: 51.0% (51/100) - Elapsed: 10.4s - Est. remaining: 10.0s\n",
      "Progress: 61.0% (61/100) - Elapsed: 12.0s - Est. remaining: 7.7s\n",
      "Progress: 71.0% (71/100) - Elapsed: 14.1s - Est. remaining: 5.7s\n",
      "Progress: 91.0% (91/100) - Elapsed: 17.1s - Est. remaining: 1.7s\n",
      "Progress: 100.0% (100/100) - Elapsed: 18.5s - Est. remaining: 0.0s\n",
      "Processing completed in 18.49 seconds\n",
      "\n",
      "Categorizing matches based on thresholds...\n",
      "\n",
      "Match category distribution:\n",
      "  No Match: 100 (100.0%)\n",
      "\n",
      "Exporting results to Acronym_Matching_Results.xlsx...\n",
      "Results successfully exported to Acronym_Matching_Results.xlsx\n",
      "\n",
      "Summary of exported data:\n",
      "   Total merchant entries: 100\n",
      "\n",
      "Match Category Distribution:\n",
      "   No Match: 100 entries (100.0%)\n",
      "\n",
      "Total processing time: 24.03 seconds\n",
      "Processing complete! Results saved to Acronym_Matching_Results.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Usage Examples and Main Execution\n",
    "\n",
    "# This cell contains usage examples and demonstrations\n",
    "\n",
    "# This cell contains usage examples and demonstrations\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function with usage examples\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Enhanced Merchant Name Matching System\".center(80))\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # [rest of the main function code]\n",
    "\n",
    "# Call the main function to demonstrate the system\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# Process the Acronym_Categorized.xlsx file and export results\n",
    "print(\"\\nProcessing Acronym_Categorized.xlsx file...\")\n",
    "results = process_acronym_file_and_export_results(\n",
    "    input_file=\"Acronym_Categorized.xlsx\", \n",
    "    output_file=\"Acronym_Matching_Results.xlsx\"\n",
    ")\n",
    "print(f\"Processing complete! Results saved to Acronym_Matching_Results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e440b285-b4a6-4f4b-95c2-7bf35c084fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
