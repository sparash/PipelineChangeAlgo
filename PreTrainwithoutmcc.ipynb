{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea5ed1a8-a964-4162-8917-3a8ba21054ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hybrid Acronym Matcher prototype with data from Acronym.xlsx...\n",
      "Loading data from Acronym.xlsx...\n",
      "Loaded 85 unique full forms and 98 test cases.\n",
      "Optimizing thresholds for the hybrid approach...\n",
      "Starting threshold optimization...\n",
      "Testing up to 25 threshold combinations...\n",
      "Testing combination 1: [0.75, 0.5, 0.75, 0.5]\n",
      "Found better thresholds: (0.75, 0.5, 0.75, 0.5) with accuracy: 0.5510\n",
      "Testing combination 25: [0.75, 0.55, 0.75, 0.7]]\n",
      "Final best thresholds: (0.75, 0.5, 0.75, 0.5) with accuracy: 0.5510\n",
      "Initializing hybrid matcher with optimized thresholds...\n",
      "\n",
      "Evaluating all algorithms...\n",
      "Evaluating 12 algorithms on 98 test cases...\n",
      "Processed 20/98 test cases...\n",
      "Processed 40/98 test cases...\n",
      "Processed 60/98 test cases...\n",
      "Processed 80/98 test cases...\n",
      "\n",
      "Accuracy Scores:\n",
      "Hybrid: 0.5510, F1: 0.7105\n",
      "Jaro-Winkler: 0.3673, F1: 0.5373\n",
      "Embedding Similarity: 0.3673, F1: 0.5373\n",
      "Trie Approximate: 0.3061, F1: 0.4687\n",
      "Damerau-Levenshtein: 0.2857, F1: 0.4444\n",
      "Fuzzy Levenshtein: 0.2857, F1: 0.4444\n",
      "Token Sort Ratio: 0.2653, F1: 0.4194\n",
      "Jaccard Bigram: 0.2449, F1: 0.3934\n",
      "TF-IDF Cosine: 0.1020, F1: 0.1852\n",
      "Aho-Corasick: 0.0816, F1: 0.1509\n",
      "Contains Ratio: 0.0612, F1: 0.1154\n",
      "Soundex: 0.0408, F1: 0.0784\n",
      "Results written to acronym_matching_results.csv\n",
      "Predictions written to acronym_matching_predictions.csv\n",
      "\n",
      "Results have been written to CSV files.\n",
      "\n",
      "Example matches using the optimized hybrid matcher:\n",
      "Acronym: BofA\n",
      "Matched to: Bank of America\n",
      "Confidence: 1.0000\n",
      "Method used: rule_based\n",
      "Decision: accept\n",
      "----------------------------------------\n",
      "Acronym: 7-11\n",
      "Matched to: 7-Eleven\n",
      "Confidence: 1.0000\n",
      "Method used: rule_based\n",
      "Decision: accept\n",
      "----------------------------------------\n",
      "Acronym: StarBucks\n",
      "Matched to: Starbucks Coffee\n",
      "Confidence: 1.0000\n",
      "Method used: rule_based\n",
      "Decision: accept\n",
      "----------------------------------------\n",
      "Acronym: MCD\n",
      "Matched to: McDonald's\n",
      "Confidence: 1.0000\n",
      "Method used: rule_based\n",
      "Decision: accept\n",
      "----------------------------------------\n",
      "Acronym: WLMRT\n",
      "Matched to: Walmart Supercenter\n",
      "Confidence: 1.0000\n",
      "Method used: rule_based\n",
      "Decision: accept\n",
      "----------------------------------------\n",
      "Acronym: CBA\n",
      "Matched to: Commonwealth Bank of Australia\n",
      "Confidence: 1.0000\n",
      "Method used: rule_based\n",
      "Decision: accept\n",
      "----------------------------------------\n",
      "Acronym: IBM\n",
      "Matched to: International Business Machines\n",
      "Confidence: 1.0000\n",
      "Method used: rule_based\n",
      "Decision: accept\n",
      "----------------------------------------\n",
      "Acronym: ACCC\n",
      "Matched to: Australian Competition and Consumer Commission\n",
      "Confidence: 1.0000\n",
      "Method used: rule_based\n",
      "Decision: accept\n",
      "----------------------------------------\n",
      "Prototype execution completed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "# For fuzzy matching\n",
    "from fuzzywuzzy import fuzz\n",
    "import Levenshtein\n",
    "from jellyfish import jaro_winkler_similarity, soundex\n",
    "import difflib\n",
    "\n",
    "# For embedding-based matching\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# For NLP operations\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# DATA LOADING\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def load_data_from_excel(file_path=\"Acronym.xlsx\"):\n",
    "    \"\"\"\n",
    "    Load acronym data from the Excel file.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file containing acronym data.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (full_forms, test_data) where full_forms is a list of all full forms\n",
    "               and test_data is a list of tuples (acronym, correct_full_form, context).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Loading data from {file_path}...\")\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Check if the required columns exist\n",
    "        required_columns = [\"Acronym\", \"Full Name\"]\n",
    "        if not all(col in df.columns for col in required_columns):\n",
    "            print(f\"Error: Excel file must contain columns {required_columns}\")\n",
    "            print(f\"Found columns: {df.columns.tolist()}\")\n",
    "            return [], []\n",
    "        \n",
    "        # Extract unique full forms to use as our reference list\n",
    "        full_forms = df[\"Full Name\"].unique().tolist()\n",
    "        \n",
    "        # Create test data in the format (acronym, correct_full_form, context)\n",
    "        test_data = []\n",
    "        for _, row in df.iterrows():\n",
    "            acronym = row[\"Acronym\"]\n",
    "            full_form = row[\"Full Name\"]\n",
    "            \n",
    "            # Determine context based on the full form\n",
    "            context = determine_context(full_form)\n",
    "            \n",
    "            test_data.append((acronym, full_form, context))\n",
    "        \n",
    "        print(f\"Loaded {len(full_forms)} unique full forms and {len(test_data)} test cases.\")\n",
    "        return full_forms, test_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data from Excel file: {str(e)}\")\n",
    "        return [], []\n",
    "\n",
    "def determine_context(full_form):\n",
    "    \"\"\"\n",
    "    Determine the context of a full form based on keywords.\n",
    "    \n",
    "    Args:\n",
    "        full_form (str): The full form to analyze.\n",
    "        \n",
    "    Returns:\n",
    "        str: The determined context or None if no context can be determined.\n",
    "    \"\"\"\n",
    "    full_form_lower = full_form.lower()\n",
    "    \n",
    "    # Define context categories and their keywords\n",
    "    context_keywords = {\n",
    "        \"finance\": [\"bank\", \"financial\", \"insurance\", \"investment\", \"provident\", \"securities\", \"credit\"],\n",
    "        \"food\": [\"food\", \"restaurant\", \"coffee\", \"mcdonalds\", \"starbucks\", \"cafe\"],\n",
    "        \"retail\": [\"retail\", \"store\", \"market\", \"walmart\", \"depot\", \"shopping\", \"supermarket\", \"pharmacy\"],\n",
    "        \"technology\": [\"technology\", \"computer\", \"electronic\", \"digital\", \"software\", \"systems\", \"aws\", \"ibm\", \"hp\"],\n",
    "        \"government\": [\"government\", \"municipal\", \"authority\", \"commission\", \"public\", \"national\", \"federal\", \"agency\"],\n",
    "        \"transportation\": [\"automobile\", \"transport\", \"aviation\", \"airlines\", \"aerial\", \"travel\", \"road\"],\n",
    "        \"healthcare\": [\"health\", \"medical\", \"hospital\", \"pharmaceutical\", \"laboratories\", \"medicine\"],\n",
    "        \"education\": [\"education\", \"university\", \"school\", \"college\", \"institute\", \"research\", \"academic\"],\n",
    "        \"entertainment\": [\"broadcasting\", \"entertainment\", \"media\", \"television\", \"radio\", \"sport\"]\n",
    "    }\n",
    "    \n",
    "    # Check each context category\n",
    "    for context, keywords in context_keywords.items():\n",
    "        if any(keyword in full_form_lower for keyword in keywords):\n",
    "            return context\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_example_data():\n",
    "    \"\"\"Create example data for demonstration and testing when no Excel file is available.\"\"\"\n",
    "    # Example full forms\n",
    "    full_forms = [\n",
    "        \"McDonald's\",\n",
    "        \"Bank of America\",\n",
    "        \"Walmart\",\n",
    "        \"Starbucks Coffee\",\n",
    "        \"Microsoft\",\n",
    "        \"Amazon\",\n",
    "        \"Google\",\n",
    "        \"Facebook\",\n",
    "        \"Apple\",\n",
    "        \"International Business Machines\",\n",
    "        \"Intel Corporation\",\n",
    "        \"CVS Pharmacy\",\n",
    "        \"Target\",\n",
    "        \"Coca-Cola\",\n",
    "        \"PepsiCo\",\n",
    "        \"Johnson & Johnson\",\n",
    "        \"Procter & Gamble\",\n",
    "        \"Municipal Corporation Delhi\",\n",
    "        \"Artificial Intelligence\",\n",
    "        \"Machine Learning\",\n",
    "        \"Natural Language Processing\",\n",
    "        \"Deep Learning\",\n",
    "        \"Central Processing Unit\",\n",
    "        \"Graphics Processing Unit\",\n",
    "        \"Random Access Memory\",\n",
    "        \"Hard Drive\",\n",
    "        \"Solid State Drive\",\n",
    "        \"7-Eleven\",\n",
    "        \"Home Depot\",\n",
    "        \"Walmart Supercenter\"\n",
    "    ]\n",
    "    \n",
    "    # Example test data\n",
    "    test_data = [\n",
    "        (\"MCD\", \"McDonald's\", \"food\"),\n",
    "        (\"BOFA\", \"Bank of America\", \"finance\"),\n",
    "        (\"WM\", \"Walmart\", \"retail\"),\n",
    "        (\"SBUX\", \"Starbucks Coffee\", \"food\"),\n",
    "        (\"MSFT\", \"Microsoft\", \"technology\"),\n",
    "        (\"AMZN\", \"Amazon\", \"retail\"),\n",
    "        (\"GOOG\", \"Google\", \"technology\"),\n",
    "        (\"FB\", \"Facebook\", \"technology\"),\n",
    "        (\"AAPL\", \"Apple\", \"technology\"),\n",
    "        (\"IBM\", \"International Business Machines\", \"technology\"),\n",
    "        (\"INTC\", \"Intel Corporation\", \"technology\"),\n",
    "        (\"CVS\", \"CVS Pharmacy\", \"retail\"),\n",
    "        (\"TGT\", \"Target\", \"retail\"),\n",
    "        (\"KO\", \"Coca-Cola\", \"food\"),\n",
    "        (\"PEP\", \"PepsiCo\", \"food\"),\n",
    "        (\"JNJ\", \"Johnson & Johnson\", \"health\"),\n",
    "        (\"PG\", \"Procter & Gamble\", \"retail\"),\n",
    "        (\"MCD GOV\", \"Municipal Corporation Delhi\", \"government\"),\n",
    "        (\"AI\", \"Artificial Intelligence\", \"technology\"),\n",
    "        (\"ML\", \"Machine Learning\", \"technology\"),\n",
    "        (\"NLP\", \"Natural Language Processing\", \"technology\"),\n",
    "        (\"DL\", \"Deep Learning\", \"technology\"),\n",
    "        (\"CPU\", \"Central Processing Unit\", \"technology\"),\n",
    "        (\"GPU\", \"Graphics Processing Unit\", \"technology\"),\n",
    "        (\"RAM\", \"Random Access Memory\", \"technology\"),\n",
    "        (\"HD\", \"Hard Drive\", \"technology\"),\n",
    "        (\"SSD\", \"Solid State Drive\", \"technology\"),\n",
    "        (\"McDnlds\", \"McDonald's\", \"food\"),\n",
    "        (\"B of A\", \"Bank of America\", \"finance\"),\n",
    "        (\"Wlmrt\", \"Walmart\", \"retail\"),\n",
    "        (\"Strbcks\", \"Starbucks Coffee\", \"food\"),\n",
    "        (\"Mcrsft\", \"Microsoft\", \"technology\"),\n",
    "        (\"7-11\", \"7-Eleven\", \"retail\"),\n",
    "        (\"7-Thirteen\", \"7-Eleven\", \"retail\"),\n",
    "        (\"Seven Eleven\", \"7-Eleven\", \"retail\"),\n",
    "        (\"Home Depot Inc\", \"Home Depot\", \"retail\"),\n",
    "        (\"WLMRT\", \"Walmart Supercenter\", \"retail\"),\n",
    "        (\"Wal-Mart\", \"Walmart Supercenter\", \"retail\"),\n",
    "        (\"MD\", \"McDonald's\", \"food\"),\n",
    "        (\"MLD\", \"McDonald's\", \"food\")\n",
    "    ]\n",
    "    \n",
    "    return full_forms, test_data\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# RULE-BASED MATCHING\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class RuleBasedMatcher:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the rule-based matcher with a dictionary of known acronyms.\n",
    "        This is the fastest matching component and handles exact matches.\n",
    "        \"\"\"\n",
    "        # Initialize with known acronym mappings from the dataset\n",
    "        self.acronym_dict = {\n",
    "            # Food & Restaurants\n",
    "            \"MCD\": \"McDonald's\",\n",
    "            \"MD\": \"McDonald's\",\n",
    "            \"MLD\": \"McDonald's\",\n",
    "            \"MCDNLDS\": \"McDonald's\",\n",
    "            \"SBUX\": \"Starbucks Coffee\",\n",
    "            \"STARBUCKS\": \"Starbucks Coffee\",\n",
    "            \"KO\": \"Coca-Cola\",\n",
    "            \"PEP\": \"PepsiCo\",\n",
    "            \n",
    "            # Retail\n",
    "            \"WLMRT\": \"Walmart Supercenter\",\n",
    "            \"WAL-MART\": \"Walmart Supercenter\",\n",
    "            \"WM\": \"Walmart\",\n",
    "            \"WMT\": \"Walmart\",\n",
    "            \"TGT\": \"Target\",\n",
    "            \"CVS\": \"CVS Pharmacy\",\n",
    "            \"CONSUMER VALUE STORE PHARMACY\": \"CVS Pharmacy\",\n",
    "            \"THE HOME DEPOT\": \"Home Depot\",\n",
    "            \"HOME DEPOT INC\": \"Home Depot\",\n",
    "            \"HD\": \"Home Depot\",\n",
    "            \"7-ONE ONE\": \"7-Eleven\",\n",
    "            \"7-THIRTEEN\": \"7-Eleven\",\n",
    "            \"9-18\": \"7-Eleven\",\n",
    "            \"7-12\": \"7-Eleven\",\n",
    "            \"7-11\": \"7-Eleven\",\n",
    "            \"SEVEN ELEVEN\": \"7-Eleven\",\n",
    "            \n",
    "            # Finance\n",
    "            \"BOFA\": \"Bank of America\",\n",
    "            \"BANK OF AMERICA CORP\": \"Bank of America\",\n",
    "            \"BOA BANK\": \"Bank of America\",\n",
    "            \"B OF A\": \"Bank of America\",\n",
    "            \"NAB\": \"National Australia Bank\",\n",
    "            \"CBA\": \"Commonwealth Bank of Australia\",\n",
    "            \"ANZ\": \"Australia and New Zealand Banking Group\",\n",
    "            \"WESTPAC\": \"Western Pacific Banking Corporation\",\n",
    "            \"RBA\": \"Reserve Bank of Australia\",\n",
    "            \"AMP\": \"Australian Mutual Provident Society\",\n",
    "            \"HDFC\": \"Housing Development Finance Corporation\",\n",
    "            \"ICICI\": \"Industrial Credit and Investment Corporation of India\",\n",
    "            \n",
    "            # Technology\n",
    "            \"IBM\": \"International Business Machines\",\n",
    "            \"MSFT\": \"Microsoft\",\n",
    "            \"AAPL\": \"Apple\",\n",
    "            \"GOOG\": \"Google\",\n",
    "            \"AMZN\": \"Amazon\",\n",
    "            \"FB\": \"Facebook\",\n",
    "            \"INTC\": \"Intel Corporation\",\n",
    "            \"HP\": \"Hewlett-Packard\",\n",
    "            \"TCS\": \"Tata Consultancy Services\",\n",
    "            \"AWS\": \"Amazon Web Services\",\n",
    "            \"MYOB\": \"Mind Your Own Business\",\n",
    "            \"CPU\": \"Central Processing Unit\",\n",
    "            \"GPU\": \"Graphics Processing Unit\",\n",
    "            \"RAM\": \"Random Access Memory\",\n",
    "            \"HD\": \"Hard Drive\",\n",
    "            \"SSD\": \"Solid State Drive\",\n",
    "            \n",
    "            # Government & Organizations\n",
    "            \"MCD GOV\": \"Municipal Corporation Delhi\",\n",
    "            \"ACCC\": \"Australian Competition and Consumer Commission\",\n",
    "            \"ASIC\": \"Australian Securities and Investments Commission\",\n",
    "            \"ATO\": \"Australian Taxation Office\",\n",
    "            \"DFAT\": \"Department of Foreign Affairs and Trade\",\n",
    "            \"EU\": \"European Union\",\n",
    "            \"NASA\": \"National Aeronautics and Space Administration\",\n",
    "            \n",
    "            # Other\n",
    "            \"AI\": \"Artificial Intelligence\",\n",
    "            \"ML\": \"Machine Learning\",\n",
    "            \"NLP\": \"Natural Language Processing\",\n",
    "            \"DL\": \"Deep Learning\",\n",
    "            \"JNJ\": \"Johnson & Johnson\",\n",
    "            \"PG\": \"Procter & Gamble\",\n",
    "            \"GE\": \"General Electric\",\n",
    "            \"3M\": \"Minnesota Mining and Manufacturing\",\n",
    "            \"BYD\": \"Build Your Dreams\",\n",
    "            \"LG\": \"Life is Good\",\n",
    "            \"BHP\": \"Broken Hill Proprietary Company\",\n",
    "            \"CSL\": \"Commonwealth Serum Laboratories\",\n",
    "            \"KPMG\": \"Klynveld Peat Marwick Goerdeler\",\n",
    "            \"ABC\": \"Australian Broadcasting Corporation\",\n",
    "            \"SBS\": \"Special Broadcasting Service\",\n",
    "            \"AFL\": \"Australian Football League\",\n",
    "            \"ASX\": \"Australian Securities Exchange\",\n",
    "            \"FOXTEL\": \"Fox News Corporation & Telstra\"\n",
    "        }\n",
    "        \n",
    "    def match(self, acronym):\n",
    "        \"\"\"\n",
    "        Match an acronym using the rule-based approach.\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (matched_full_form, confidence_score)\n",
    "        \"\"\"\n",
    "        # Convert to uppercase to ensure case-insensitive matching\n",
    "        acronym_upper = acronym.upper()\n",
    "        \n",
    "        # Check if the acronym exists in our dictionary\n",
    "        if acronym_upper in self.acronym_dict:\n",
    "            return self.acronym_dict[acronym_upper], 1.0  # Return match with 100% confidence\n",
    "        \n",
    "        return None, 0.0  # No match found, 0% confidence\n",
    "    \n",
    "    def add_acronym(self, acronym, full_form):\n",
    "        \"\"\"Add a new acronym to the dictionary.\"\"\"\n",
    "        self.acronym_dict[acronym.upper()] = full_form\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# FUZZY MATCHING\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class FuzzyMatcher:\n",
    "    def __init__(self, known_full_forms):\n",
    "        \"\"\"\n",
    "        Initialize the fuzzy matcher with a list of known full forms.\n",
    "        This handles spelling variations and misspellings.\n",
    "        \n",
    "        Args:\n",
    "            known_full_forms (list): List of known full forms to match against.\n",
    "        \"\"\"\n",
    "        self.known_full_forms = known_full_forms\n",
    "        self.threshold_high = 0.85  # High confidence threshold\n",
    "        self.threshold_low = 0.60   # Low confidence threshold\n",
    "        \n",
    "    def match(self, acronym):\n",
    "        \"\"\"\n",
    "        Match an acronym using fuzzy matching techniques.\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (matched_full_form, confidence_score, confidence_level)\n",
    "        \"\"\"\n",
    "        best_match = None\n",
    "        best_score = 0\n",
    "        \n",
    "        # Check similarity against each known full form\n",
    "        for full_form in self.known_full_forms:\n",
    "            # Try different fuzzy matching methods and take the highest score\n",
    "            jw_score = jaro_winkler_similarity(acronym.lower(), full_form.lower())\n",
    "            lev_ratio = Levenshtein.ratio(acronym.lower(), full_form.lower())\n",
    "            token_sort_ratio = fuzz.token_sort_ratio(acronym, full_form) / 100.0\n",
    "            \n",
    "            # Take the highest score from the different methods\n",
    "            score = max(jw_score, lev_ratio, token_sort_ratio)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_match = full_form\n",
    "                best_score = score\n",
    "        \n",
    "        # Decision based on confidence thresholds\n",
    "        if best_score >= self.threshold_high:\n",
    "            confidence = \"high\"\n",
    "        elif best_score >= self.threshold_low:\n",
    "            confidence = \"medium\"\n",
    "        else:\n",
    "            confidence = \"low\"\n",
    "            \n",
    "        return best_match, best_score, confidence\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# EMBEDDING-BASED MATCHING\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class EmbeddingMatcher:\n",
    "    def __init__(self, known_full_forms, context_examples=None):\n",
    "        \"\"\"\n",
    "        Initialize the embedding matcher with a list of known full forms and context examples.\n",
    "        This handles context-aware matching and semantic understanding.\n",
    "        \n",
    "        Args:\n",
    "            known_full_forms (list): List of known full forms to match against.\n",
    "            context_examples (dict, optional): Dictionary mapping contexts to lists of examples.\n",
    "        \"\"\"\n",
    "        # Load a pre-trained sentence transformer model\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        \n",
    "        # Generate embeddings for known full forms\n",
    "        self.known_full_forms = known_full_forms\n",
    "        self.known_embeddings = self.model.encode(known_full_forms)\n",
    "        \n",
    "        # Store context examples if provided\n",
    "        self.context_examples = context_examples or {}\n",
    "        self.context_embeddings = {}\n",
    "        \n",
    "        # Set default thresholds\n",
    "        self.threshold_high = 0.9\n",
    "        self.threshold_low = 0.6\n",
    "        \n",
    "        # Generate embeddings for context examples\n",
    "        for context, examples in self.context_examples.items():\n",
    "            if examples:  # Check if there are examples for this context\n",
    "                self.context_embeddings[context] = self.model.encode(\" \".join(examples))\n",
    "    \n",
    "    def match(self, acronym, context=None):\n",
    "        \"\"\"\n",
    "        Match an acronym using embedding-based semantic similarity.\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match.\n",
    "            context (str, optional): Context to help disambiguation.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (matched_full_form, confidence_score, confidence_level)\n",
    "        \"\"\"\n",
    "        # Generate embedding for the acronym\n",
    "        acronym_embedding = self.model.encode([acronym])[0].reshape(1, -1)\n",
    "        \n",
    "        # Calculate similarity with all known full forms\n",
    "        similarities = cosine_similarity(acronym_embedding, self.known_embeddings)\n",
    "        best_idx = np.argmax(similarities)\n",
    "        best_score = similarities[0][best_idx]\n",
    "        best_match = self.known_full_forms[best_idx]\n",
    "        \n",
    "        # If context is provided, adjust the matching based on context\n",
    "        if context and context in self.context_embeddings:\n",
    "            context_embedding = self.context_embeddings[context].reshape(1, -1)\n",
    "            context_similarities = cosine_similarity(acronym_embedding, context_embedding)\n",
    "            context_score = context_similarities[0][0]\n",
    "            \n",
    "            # If context is strongly relevant, adjust the matching\n",
    "            if context_score > 0.7:\n",
    "                # Find full forms that are contextually relevant\n",
    "                context_relevant_forms = []\n",
    "                for i, full_form in enumerate(self.known_full_forms):\n",
    "                    full_form_embedding = self.known_embeddings[i].reshape(1, -1)\n",
    "                    relevance = cosine_similarity(full_form_embedding, context_embedding)[0][0]\n",
    "                    if relevance > 0.7:\n",
    "                        context_relevant_forms.append((full_form, similarities[0][i], relevance))\n",
    "                \n",
    "                # If we have context-relevant forms, choose the best one\n",
    "                if context_relevant_forms:\n",
    "                    # Sort by combined score (similarity to acronym * relevance to context)\n",
    "                    context_relevant_forms.sort(key=lambda x: x[1] * x[2], reverse=True)\n",
    "                    best_match = context_relevant_forms[0][0]\n",
    "                    best_score = context_relevant_forms[0][1]  # Using just similarity to acronym as score\n",
    "        \n",
    "        # Decision based on confidence thresholds\n",
    "        if best_score >= self.threshold_high:\n",
    "            confidence = \"high\"\n",
    "        elif best_score >= self.threshold_low:\n",
    "            confidence = \"medium\"\n",
    "        else:\n",
    "            confidence = \"low\"\n",
    "            \n",
    "        return best_match, best_score, confidence\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# HYBRID APPROACH\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "class HybridAcronymMatcher:\n",
    "    def __init__(self, known_full_forms, context_examples=None):\n",
    "        \"\"\"\n",
    "        Initialize the hybrid acronym matcher that combines rule-based, fuzzy, and embedding-based matching.\n",
    "        \n",
    "        Args:\n",
    "            known_full_forms (list): List of known full forms to match against.\n",
    "            context_examples (dict, optional): Dictionary mapping contexts to lists of examples.\n",
    "        \"\"\"\n",
    "        # Initialize the three matching components\n",
    "        self.rule_based = RuleBasedMatcher()\n",
    "        self.fuzzy = FuzzyMatcher(known_full_forms)\n",
    "        self.embedding = EmbeddingMatcher(known_full_forms, context_examples)\n",
    "        \n",
    "        # Keep track of all known full forms\n",
    "        self.known_full_forms = known_full_forms\n",
    "    \n",
    "    def match(self, acronym, context=None):\n",
    "        \"\"\"\n",
    "        Perform hybrid matching on the given acronym.\n",
    "        \n",
    "        Args:\n",
    "            acronym (str): The acronym to match.\n",
    "            context (str, optional): Context information for disambiguation.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (matched_full_form, confidence_score, method_used, decision)\n",
    "        \"\"\"\n",
    "        # Step 1: Try rule-based matching first (fastest)\n",
    "        rule_match, rule_score = self.rule_based.match(acronym)\n",
    "        \n",
    "        if rule_match:\n",
    "            return rule_match, rule_score, \"rule_based\", \"accept\"\n",
    "        \n",
    "        # Step 2: If rule-based fails, try fuzzy matching\n",
    "        fuzzy_match, fuzzy_score, fuzzy_confidence = self.fuzzy.match(acronym)\n",
    "        \n",
    "        # Step 3: If fuzzy matching gives high confidence, use it\n",
    "        if fuzzy_confidence == \"high\":\n",
    "            return fuzzy_match, fuzzy_score, \"fuzzy\", \"accept\"\n",
    "        \n",
    "        # Step 4: If fuzzy matching is uncertain, try embedding-based matching\n",
    "        embedding_match, embedding_score, embedding_confidence = self.embedding.match(acronym, context)\n",
    "        \n",
    "        # Step 5: Make a decision based on confidence scores\n",
    "        if embedding_confidence == \"high\":\n",
    "            return embedding_match, embedding_score, \"embedding\", \"accept\"\n",
    "        \n",
    "        # Step 6: If both fuzzy and embedding have medium confidence, choose the one with higher score\n",
    "        if fuzzy_confidence == \"medium\" and embedding_confidence == \"medium\":\n",
    "            if fuzzy_score >= embedding_score:\n",
    "                return fuzzy_match, fuzzy_score, \"fuzzy\", \"review\"\n",
    "            else:\n",
    "                return embedding_match, embedding_score, \"embedding\", \"review\"\n",
    "        \n",
    "        # Step 7: If one has medium confidence and the other has low, choose the medium one\n",
    "        if fuzzy_confidence == \"medium\":\n",
    "            return fuzzy_match, fuzzy_score, \"fuzzy\", \"review\"\n",
    "        \n",
    "        if embedding_confidence == \"medium\":\n",
    "            return embedding_match, embedding_score, \"embedding\", \"review\"\n",
    "        \n",
    "        # Step 8: If both have low confidence, reject\n",
    "        return \"No match\", max(fuzzy_score, embedding_score), \"hybrid\", \"reject\"\n",
    "    \n",
    "    def add_known_full_form(self, full_form):\n",
    "        \"\"\"Add a new full form to the known full forms list.\"\"\"\n",
    "        if full_form not in self.known_full_forms:\n",
    "            self.known_full_forms.append(full_form)\n",
    "            # Update the fuzzy and embedding matchers\n",
    "            self.fuzzy = FuzzyMatcher(self.known_full_forms)\n",
    "            self.embedding = EmbeddingMatcher(self.known_full_forms, self.embedding.context_examples)\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# ALTERNATIVE IMPLEMENTATIONS OF COMPARISON ALGORITHMS\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def jaro_winkler_similarity_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    Match an acronym using Jaro-Winkler similarity.\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for full_form in full_forms:\n",
    "        score = jaro_winkler_similarity(acronym.lower(), full_form.lower())\n",
    "        if score > best_score:\n",
    "            best_match = full_form\n",
    "            best_score = score\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "def damerau_levenshtein_similarity_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    Match an acronym using Damerau-Levenshtein similarity (handles transpositions).\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for full_form in full_forms:\n",
    "        # Damerau-Levenshtein distance considers transpositions\n",
    "        distance = Levenshtein.distance(acronym.lower(), full_form.lower())\n",
    "        max_len = max(len(acronym), len(full_form))\n",
    "        score = 1 - (distance / max_len)  # Normalize to [0, 1]\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_match = full_form\n",
    "            best_score = score\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "def tfidf_cosine_similarity_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    Match an acronym using TF-IDF cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    \n",
    "    # Create a corpus with the acronym and all full forms\n",
    "    corpus = [acronym] + full_forms\n",
    "    \n",
    "    # Create TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    # Compute cosine similarity between acronym and full forms\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()\n",
    "    \n",
    "    # Find the best match\n",
    "    best_idx = np.argmax(cosine_similarities)\n",
    "    best_score = cosine_similarities[best_idx]\n",
    "    best_match = full_forms[best_idx]\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "def jaccard_bigram_similarity_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    Match an acronym using Jaccard similarity on character bigrams.\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    def get_bigrams(text):\n",
    "        return [text[i:i+2] for i in range(len(text)-1)]\n",
    "    \n",
    "    def jaccard_similarity(set1, set2):\n",
    "        intersection = len(set1.intersection(set2))\n",
    "        union = len(set1) + len(set2) - intersection\n",
    "        return intersection / union if union > 0 else 0\n",
    "    \n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    # Get bigrams for the acronym\n",
    "    acronym_bigrams = set(get_bigrams(acronym.lower()))\n",
    "    \n",
    "    for full_form in full_forms:\n",
    "        # Get bigrams for the full form\n",
    "        full_form_bigrams = set(get_bigrams(full_form.lower()))\n",
    "        \n",
    "        # Calculate Jaccard similarity\n",
    "        score = jaccard_similarity(acronym_bigrams, full_form_bigrams)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_match = full_form\n",
    "            best_score = score\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "def soundex_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    Match an acronym using Soundex phonetic matching.\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    acronym_soundex = soundex(acronym)\n",
    "    \n",
    "    for full_form in full_forms:\n",
    "        # For multi-word full forms, check each word\n",
    "        words = full_form.split()\n",
    "        \n",
    "        # Check if any word's soundex matches the acronym's soundex\n",
    "        soundex_matches = [1 if soundex(word) == acronym_soundex else 0 for word in words]\n",
    "        \n",
    "        # If any word matches, score is 1, otherwise 0\n",
    "        score = 1 if any(soundex_matches) else 0\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_match = full_form\n",
    "            best_score = score\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "def token_sort_ratio_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    Match an acronym using token sort ratio (handles word order differences).\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for full_form in full_forms:\n",
    "        # Calculate token sort ratio\n",
    "        score = fuzz.token_sort_ratio(acronym, full_form) / 100.0\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_match = full_form\n",
    "            best_score = score\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "def contains_ratio_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    Match an acronym based on whether it's contained in a full form.\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for full_form in full_forms:\n",
    "        # Check if acronym is contained in full form\n",
    "        if acronym.lower() in full_form.lower():\n",
    "            # Calculate ratio of acronym length to full form length\n",
    "            score = len(acronym) / len(full_form)\n",
    "        else:\n",
    "            score = 0\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_match = full_form\n",
    "            best_score = score\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "def fuzzy_levenshtein_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    Match an acronym using difflib's SequenceMatcher (similar to Levenshtein).\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for full_form in full_forms:\n",
    "        # Calculate similarity using difflib's SequenceMatcher\n",
    "        score = difflib.SequenceMatcher(None, acronym.lower(), full_form.lower()).ratio()\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_match = full_form\n",
    "            best_score = score\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "def trie_approximate_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    A simplified version of trie approximate matching that uses prefix matching.\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    # Lowercase the acronym for comparison\n",
    "    acronym_lower = acronym.lower()\n",
    "    \n",
    "    # Try exact match first\n",
    "    for full_form in full_forms:\n",
    "        if acronym_lower == full_form.lower():\n",
    "            return full_form, 1.0\n",
    "    \n",
    "    # Try prefix matches\n",
    "    for i in range(1, len(acronym) + 1):\n",
    "        prefix = acronym[:i].lower()\n",
    "        \n",
    "        # Find all full forms that start with this prefix\n",
    "        matches = []\n",
    "        for full_form in full_forms:\n",
    "            if full_form.lower().startswith(prefix):\n",
    "                matches.append((full_form, i / len(acronym)))\n",
    "        \n",
    "        if matches:\n",
    "            # Find the best match by length of matching prefix\n",
    "            best_prefix_match = max(matches, key=lambda x: x[1])\n",
    "            \n",
    "            if best_prefix_match[1] > best_score:\n",
    "                best_match = best_prefix_match[0]\n",
    "                best_score = best_prefix_match[1]\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "def embedding_similarity_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    Match an acronym using embedding-based semantic similarity.\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    # Use sentence transformers for embeddings\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Generate embeddings\n",
    "    acronym_embedding = model.encode([acronym])[0].reshape(1, -1)\n",
    "    full_form_embeddings = model.encode(full_forms)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarities = cosine_similarity(acronym_embedding, full_form_embeddings).flatten()\n",
    "    \n",
    "    # Find the best match\n",
    "    best_idx = np.argmax(similarities)\n",
    "    best_score = similarities[best_idx]\n",
    "    best_match = full_forms[best_idx]\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "def aho_corasick_match(acronym, full_forms):\n",
    "    \"\"\"\n",
    "    A simplified version of Aho-Corasick matching that uses word-level matching.\n",
    "    \n",
    "    Args:\n",
    "        acronym (str): The acronym to match.\n",
    "        full_forms (list): List of full forms to match against.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (best_match, best_score)\n",
    "    \"\"\"\n",
    "    best_match = None\n",
    "    best_score = 0\n",
    "    \n",
    "    # Split acronym into words and lowercase\n",
    "    acronym_words = set(acronym.lower().split())\n",
    "    \n",
    "    # Count word matches for each full form\n",
    "    match_counts = []\n",
    "    \n",
    "    for full_form in full_forms:\n",
    "        # Split full form into words and lowercase\n",
    "        full_form_words = set(full_form.lower().split())\n",
    "        \n",
    "        # Count matching words\n",
    "        matches = len(acronym_words.intersection(full_form_words))\n",
    "        total_words = len(acronym_words)\n",
    "        \n",
    "        if total_words > 0:\n",
    "            score = matches / total_words\n",
    "            match_counts.append((full_form, score))\n",
    "    \n",
    "    # Find the full form with the highest score\n",
    "    if match_counts:\n",
    "        match_counts.sort(key=lambda x: x[1], reverse=True)\n",
    "        best_match, best_score = match_counts[0]\n",
    "    \n",
    "    return best_match, best_score\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# EVALUATION FUNCTIONS\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def evaluate_algorithms(test_data, full_forms):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of all algorithms on the test data.\n",
    "    \n",
    "    Args:\n",
    "        test_data (list): List of tuples (acronym, correct_full_form, context).\n",
    "        full_forms (list): List of all possible full forms.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of algorithm names and their performance metrics.\n",
    "    \"\"\"\n",
    "    algorithms = {\n",
    "        \"Hybrid\": None,  # We'll initialize the hybrid matcher separately\n",
    "        \"Jaro-Winkler\": jaro_winkler_similarity_match,\n",
    "        \"Damerau-Levenshtein\": damerau_levenshtein_similarity_match,\n",
    "        \"TF-IDF Cosine\": tfidf_cosine_similarity_match,\n",
    "        \"Jaccard Bigram\": jaccard_bigram_similarity_match,\n",
    "        \"Soundex\": soundex_match,\n",
    "        \"Token Sort Ratio\": token_sort_ratio_match,\n",
    "        \"Contains Ratio\": contains_ratio_match,\n",
    "        \"Fuzzy Levenshtein\": fuzzy_levenshtein_match,\n",
    "        \"Trie Approximate\": trie_approximate_match,\n",
    "        \"Embedding Similarity\": embedding_similarity_match,\n",
    "        \"Aho-Corasick\": aho_corasick_match\n",
    "    }\n",
    "    \n",
    "    # Context examples for the embedding matcher\n",
    "    context_examples = defaultdict(list)\n",
    "    for acronym, full_form, context in test_data:\n",
    "        if context:\n",
    "            context_examples[context].append(full_form)\n",
    "    \n",
    "    # Initialize the hybrid matcher\n",
    "    hybrid_matcher = HybridAcronymMatcher(full_forms, context_examples)\n",
    "    \n",
    "    # Prepare results dictionary\n",
    "    results = {name: {\"correct\": 0, \"total\": 0, \"predictions\": []} for name in algorithms}\n",
    "    \n",
    "    # Evaluate each algorithm\n",
    "    print(f\"Evaluating {len(algorithms)} algorithms on {len(test_data)} test cases...\")\n",
    "    \n",
    "    for i, (acronym, correct_full_form, context) in enumerate(test_data):\n",
    "        if i % 20 == 0 and i > 0:\n",
    "            print(f\"Processed {i}/{len(test_data)} test cases...\")\n",
    "            \n",
    "        # Evaluate hybrid matcher\n",
    "        hybrid_match, hybrid_score, method, decision = hybrid_matcher.match(acronym, context)\n",
    "        results[\"Hybrid\"][\"predictions\"].append((acronym, correct_full_form, hybrid_match, hybrid_score))\n",
    "        if hybrid_match == correct_full_form:\n",
    "            results[\"Hybrid\"][\"correct\"] += 1\n",
    "        results[\"Hybrid\"][\"total\"] += 1\n",
    "        \n",
    "        # Evaluate other algorithms\n",
    "        for name, algorithm in algorithms.items():\n",
    "            if name == \"Hybrid\":\n",
    "                continue\n",
    "                \n",
    "            match, score = algorithm(acronym, full_forms)\n",
    "            results[name][\"predictions\"].append((acronym, correct_full_form, match, score))\n",
    "            if match == correct_full_form:\n",
    "                results[name][\"correct\"] += 1\n",
    "            results[name][\"total\"] += 1\n",
    "    \n",
    "    # Calculate accuracy, precision, recall, and F1 scores\n",
    "    for name in algorithms:\n",
    "        correct = results[name][\"correct\"]\n",
    "        total = results[name][\"total\"]\n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        results[name][\"accuracy\"] = accuracy\n",
    "        \n",
    "        # Calculate additional metrics if needed\n",
    "        predictions = [(p[2] == p[1]) for p in results[name][\"predictions\"]]\n",
    "        true_labels = [True] * len(predictions)  # All should be True for perfect matching\n",
    "        \n",
    "        # Calculate precision, recall, and F1 score\n",
    "        if sum(predictions) > 0:  # Avoid division by zero\n",
    "            precision = precision_score(true_labels, predictions, zero_division=0)\n",
    "            recall = recall_score(true_labels, predictions, zero_division=0)\n",
    "            f1 = f1_score(true_labels, predictions, zero_division=0)\n",
    "        else:\n",
    "            precision = recall = f1 = 0\n",
    "            \n",
    "        results[name][\"precision\"] = precision\n",
    "        results[name][\"recall\"] = recall\n",
    "        results[name][\"f1\"] = f1\n",
    "    \n",
    "    return results\n",
    "\n",
    "def write_results_to_csv(results, output_file):\n",
    "    \"\"\"\n",
    "    Write the evaluation results to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Dictionary of algorithm names and their performance metrics.\n",
    "        output_file (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    # Prepare CSV header\n",
    "    header = [\"Algorithm\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Correct\", \"Total\"]\n",
    "    \n",
    "    # Write results to CSV\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # Sort algorithms by accuracy (descending)\n",
    "        sorted_algorithms = sorted(results.keys(), key=lambda x: results[x][\"accuracy\"], reverse=True)\n",
    "        \n",
    "        # Write results for each algorithm\n",
    "        for algorithm in sorted_algorithms:\n",
    "            writer.writerow([\n",
    "                algorithm,\n",
    "                f\"{results[algorithm]['accuracy']:.4f}\",\n",
    "                f\"{results[algorithm]['precision']:.4f}\",\n",
    "                f\"{results[algorithm]['recall']:.4f}\",\n",
    "                f\"{results[algorithm]['f1']:.4f}\",\n",
    "                results[algorithm][\"correct\"],\n",
    "                results[algorithm][\"total\"]\n",
    "            ])\n",
    "        \n",
    "    print(f\"Results written to {output_file}\")\n",
    "\n",
    "def write_predictions_to_csv(results, output_file):\n",
    "    \"\"\"\n",
    "    Write the algorithm predictions to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Dictionary of algorithm names and their performance metrics.\n",
    "        output_file (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    # Get all unique acronyms from the first algorithm's predictions\n",
    "    algorithm = list(results.keys())[0]\n",
    "    acronyms = [p[0] for p in results[algorithm][\"predictions\"]]\n",
    "    correct_forms = [p[1] for p in results[algorithm][\"predictions\"]]\n",
    "    \n",
    "    # Prepare CSV header\n",
    "    header = [\"Acronym\", \"Correct Full Form\"] + [f\"{algo}_Match\" for algo in results] + [f\"{algo}_Score\" for algo in results]\n",
    "    \n",
    "    # Write predictions to CSV\n",
    "    with open(output_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # Write predictions for each acronym\n",
    "        for i, acronym in enumerate(acronyms):\n",
    "            row = [acronym, correct_forms[i]]\n",
    "            \n",
    "            # Add predictions from each algorithm\n",
    "            for algorithm in results:\n",
    "                prediction = results[algorithm][\"predictions\"][i]\n",
    "                row.append(prediction[2])  # Match\n",
    "            \n",
    "            # Add scores from each algorithm\n",
    "            for algorithm in results:\n",
    "                prediction = results[algorithm][\"predictions\"][i]\n",
    "                row.append(f\"{prediction[3]:.4f}\")  # Score\n",
    "            \n",
    "            writer.writerow(row)\n",
    "        \n",
    "    print(f\"Predictions written to {output_file}\")\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# THRESHOLD OPTIMIZATION\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def optimize_thresholds(test_data, full_forms):\n",
    "    \"\"\"\n",
    "    Optimize the thresholds for the hybrid approach to maximize accuracy.\n",
    "    \n",
    "    Args:\n",
    "        test_data (list): List of tuples (acronym, correct_full_form, context).\n",
    "        full_forms (list): List of all possible full forms.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Optimized thresholds (fuzzy_high, fuzzy_low, embedding_high, embedding_low).\n",
    "    \"\"\"\n",
    "    print(\"Starting threshold optimization...\")\n",
    "    \n",
    "    # Context examples for the embedding matcher\n",
    "    context_examples = defaultdict(list)\n",
    "    for acronym, full_form, context in test_data:\n",
    "        if context:\n",
    "            context_examples[context].append(full_form)\n",
    "    \n",
    "    # Define threshold ranges to search (using fewer values for faster optimization)\n",
    "    fuzzy_high_range = [0.75, 0.8, 0.85, 0.9]\n",
    "    fuzzy_low_range = [0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "    embedding_high_range = [0.75, 0.8, 0.85, 0.9]\n",
    "    embedding_low_range = [0.5, 0.55, 0.6, 0.65, 0.7]\n",
    "    \n",
    "    best_accuracy = 0\n",
    "    best_thresholds = (0.85, 0.6, 0.9, 0.6)  # Default values in case optimization fails\n",
    "    \n",
    "    # For faster optimization, limit the number of combinations tested\n",
    "    max_combinations = 25\n",
    "    tested = 0\n",
    "    \n",
    "    print(f\"Testing up to {max_combinations} threshold combinations...\")\n",
    "    \n",
    "    try:\n",
    "        for fuzzy_high in fuzzy_high_range:\n",
    "            if tested >= max_combinations:\n",
    "                break\n",
    "                \n",
    "            for fuzzy_low in fuzzy_low_range:\n",
    "                if fuzzy_low >= fuzzy_high or tested >= max_combinations:\n",
    "                    continue\n",
    "                    \n",
    "                for embedding_high in embedding_high_range:\n",
    "                    if tested >= max_combinations:\n",
    "                        break\n",
    "                        \n",
    "                    for embedding_low in embedding_low_range:\n",
    "                        if embedding_low >= embedding_high:\n",
    "                            continue\n",
    "                            \n",
    "                        tested += 1\n",
    "                        if tested > max_combinations:\n",
    "                            break\n",
    "                        \n",
    "                        print(f\"Testing combination {tested}: [{fuzzy_high}, {fuzzy_low}, {embedding_high}, {embedding_low}]\", end=\"\\r\")\n",
    "                        \n",
    "                        # Initialize the hybrid matcher with the current thresholds\n",
    "                        hybrid_matcher = HybridAcronymMatcher(full_forms, context_examples)\n",
    "                        \n",
    "                        # Override the default thresholds for testing\n",
    "                        hybrid_matcher.fuzzy.threshold_high = fuzzy_high\n",
    "                        hybrid_matcher.fuzzy.threshold_low = fuzzy_low\n",
    "                        hybrid_matcher.embedding.threshold_high = embedding_high\n",
    "                        hybrid_matcher.embedding.threshold_low = embedding_low\n",
    "                        \n",
    "                        # Evaluate the matcher on the test data\n",
    "                        correct = 0\n",
    "                        total = len(test_data)\n",
    "                        \n",
    "                        for acronym, correct_full_form, context in test_data:\n",
    "                            match, _, _, _ = hybrid_matcher.match(acronym, context)\n",
    "                            if match == correct_full_form:\n",
    "                                correct += 1\n",
    "                        \n",
    "                        # Calculate accuracy\n",
    "                        accuracy = correct / total\n",
    "                        \n",
    "                        # Update best thresholds if accuracy improves\n",
    "                        if accuracy > best_accuracy:\n",
    "                            best_accuracy = accuracy\n",
    "                            best_thresholds = (fuzzy_high, fuzzy_low, embedding_high, embedding_low)\n",
    "                            \n",
    "                            print(f\"\\nFound better thresholds: {best_thresholds} with accuracy: {best_accuracy:.4f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during threshold optimization: {str(e)}\")\n",
    "        print(\"Using default thresholds instead.\")\n",
    "    \n",
    "    print(f\"\\nFinal best thresholds: {best_thresholds} with accuracy: {best_accuracy:.4f}\")\n",
    "    return best_thresholds\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# MAIN EXECUTION\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def run_prototype(excel_file_path=\"Acronym.xlsx\"):\n",
    "    \"\"\"\n",
    "    Run the complete prototype implementation using data from an Excel file.\n",
    "    \n",
    "    Args:\n",
    "        excel_file_path (str): Path to the Excel file containing acronym data.\n",
    "        \n",
    "    Returns:\n",
    "        HybridAcronymMatcher: The optimized hybrid matcher.\n",
    "    \"\"\"\n",
    "    # Load data from Excel file\n",
    "    full_forms, test_data = load_data_from_excel(excel_file_path)\n",
    "    \n",
    "    # Check if data was loaded successfully\n",
    "    if not full_forms or not test_data:\n",
    "        print(\"No data loaded from Excel. Using example data instead.\")\n",
    "        full_forms, test_data = create_example_data()\n",
    "    \n",
    "    # Optimize thresholds for the hybrid approach\n",
    "    print(\"Optimizing thresholds for the hybrid approach...\")\n",
    "    best_thresholds = optimize_thresholds(test_data, full_forms)\n",
    "    \n",
    "    # Context examples for the embedding matcher\n",
    "    context_examples = defaultdict(list)\n",
    "    for acronym, full_form, context in test_data:\n",
    "        if context:\n",
    "            context_examples[context].append(full_form)\n",
    "    \n",
    "    # Initialize the hybrid matcher with optimized thresholds\n",
    "    print(\"Initializing hybrid matcher with optimized thresholds...\")\n",
    "    hybrid_matcher = HybridAcronymMatcher(full_forms, context_examples)\n",
    "    \n",
    "    # Override the default thresholds with the optimized ones\n",
    "    fuzzy_high, fuzzy_low, embedding_high, embedding_low = best_thresholds\n",
    "    hybrid_matcher.fuzzy.threshold_high = fuzzy_high\n",
    "    hybrid_matcher.fuzzy.threshold_low = fuzzy_low\n",
    "    hybrid_matcher.embedding.threshold_high = embedding_high\n",
    "    hybrid_matcher.embedding.threshold_low = embedding_low\n",
    "    \n",
    "    # Evaluate all algorithms including the optimized hybrid approach\n",
    "    print(\"\\nEvaluating all algorithms...\")\n",
    "    results = evaluate_algorithms(test_data, full_forms)\n",
    "    \n",
    "    # Print accuracy scores\n",
    "    print(\"\\nAccuracy Scores:\")\n",
    "    for algorithm, metrics in sorted(results.items(), key=lambda x: x[1][\"accuracy\"], reverse=True):\n",
    "        print(f\"{algorithm}: {metrics['accuracy']:.4f}, F1: {metrics['f1']:.4f}\")\n",
    "    \n",
    "    # Write results to CSV\n",
    "    write_results_to_csv(results, \"acronym_matching_results.csv\")\n",
    "    write_predictions_to_csv(results, \"acronym_matching_predictions.csv\")\n",
    "    \n",
    "    print(\"\\nResults have been written to CSV files.\")\n",
    "    \n",
    "    # Return the hybrid matcher for potential use\n",
    "    return hybrid_matcher\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Hybrid Acronym Matcher prototype with data from Acronym.xlsx...\")\n",
    "    hybrid_matcher = run_prototype(\"Acronym.xlsx\")\n",
    "    \n",
    "    print(\"\\nExample matches using the optimized hybrid matcher:\")\n",
    "    test_acronyms = [\"BofA\", \"7-11\", \"StarBucks\", \"MCD\", \"WLMRT\", \"CBA\", \"IBM\", \"ACCC\"]\n",
    "    \n",
    "    for acronym in test_acronyms:\n",
    "        match, score, method, decision = hybrid_matcher.match(acronym)\n",
    "        print(f\"Acronym: {acronym}\")\n",
    "        print(f\"Matched to: {match}\")\n",
    "        print(f\"Confidence: {score:.4f}\")\n",
    "        print(f\"Method used: {method}\")\n",
    "        print(f\"Decision: {decision}\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    print(\"Prototype execution completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c970524-a34c-405b-8fbd-2035a68e34c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
